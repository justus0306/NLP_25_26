{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e50a659",
   "metadata": {},
   "source": [
    "# Lab 5: Neural Network Classification with scikit-learn\n",
    "\n",
    "---\n",
    "## 1. Notebook Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "- Re-use the most frequent words (optional: per class) you found for\n",
    "your Naive Bayes classifier last week.\n",
    "\n",
    "- Construct binary vectors for your whole dataset. Each dimension states\n",
    "whether the word is part of the sample or not.\n",
    "\n",
    "- Create a small neural network using scikit-learn: https://scikit-learn.org/\n",
    "stable/modules/neural_networks_supervised.html. Start with three\n",
    "hidden layers of 128/64/128 neurons. Consider what your input and\n",
    "output layers should look like.\n",
    "\n",
    "- Train your network on your training set and test it on your test set.\n",
    "Calculate evaluation measures and compare with your previous\n",
    "classifier.\n",
    "\n",
    "- Optional: Experiment with different network sizes.\n",
    "\n",
    "### 1.2 Prerequisites\n",
    "This notebook assumes you have already executed:\n",
    "- **Lab 2**: Data preprocessing → `../Data/tweets_preprocessed_train.parquet`, `../Data/tweets_preprocessed_test.parquet`, `../Data/tweets_preprocessed_validation.parquet`\n",
    "- **Lab 3**: Language modeling\n",
    "- **Lab 4**: Feature extraction → `../Data/top_1000_vocabulary.json`\n",
    "\n",
    "### 1.3 Architecture\n",
    "We implement neural networks with:\n",
    "- **Input layer**: 1000 features (Top 1000 vocabulary from Lab 4)\n",
    "- **Hidden layers**: 128 → 64 → 128 neurons (as specified)\n",
    "- **Output layer**: \n",
    "  - Multi-label: 19 binary classifiers (one per topic class, using OneVsRestClassifier)\n",
    "  - Single-label: 19 classes with Softmax activation\n",
    "\n",
    "### 1.4 Neural Network Fundamentals (From Lecture)\n",
    "- A single neuron computes: ŷ = g(w₀ + Σ xᵢwᵢ) where g is a non-linear activation function\n",
    "- **Activation functions are critical** - they introduce non-linearities that make multi-layer networks powerful (universal approximators)\n",
    "- Common activations: ReLU (g(z) = max(0,z)), Sigmoid, Tanh\n",
    "- For multi-class (single-label): use **Softmax** to convert outputs to probabilities\n",
    "- For multi-label: use **Sigmoid** per class via OneVsRestClassifier\n",
    "- **Loss function for classification**: Cross-entropy loss\n",
    "- Weights should NOT be initialized to all zeros (breaks symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Task 1: Establish Context\n",
    "\n",
    "### 2.1 Review Preprocessing from Lab 2\n",
    "In Lab 2, we preprocessed tweets with the following pipeline:\n",
    "- Remove RT indicators, URLs, usernames, and mentions\n",
    "- Convert emojis to text descriptions\n",
    "- Extract hashtag text and segment CamelCase words\n",
    "- Normalize whitespace and lowercase\n",
    "- Tokenize with SpaCy and filter/lemmatize tokens\n",
    "\n",
    "The output is stored in parquet files with columns: `text`, `label_name`, `label`\n",
    "\n",
    "Two approaches for label handling are supported:\n",
    "- Parse `label_name` (string list format) into Python lists\n",
    "- Use `label` column directly (pre-computed binary vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import ast\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    hamming_loss,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Constants\n",
    "TRAIN_DATA_PATH = \"../Data/tweets_preprocessed_train.parquet\"\n",
    "TEST_DATA_PATH = \"../Data/tweets_preprocessed_test.parquet\"\n",
    "VALIDATION_DATA_PATH = \"../Data/tweets_preprocessed_validation.parquet\"\n",
    "VOCABULARY_PATH = \"../Data/top_1000_vocabulary.json\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_vocab_section",
   "metadata": {},
   "source": [
    "### 2.2 Load and Verify Vocabulary from Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the top 1000 vocabulary from Lab 4\n",
    "with open(VOCABULARY_PATH, 'r', encoding='utf-8') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "VOCABULARY = vocab_data['tokens']\n",
    "vocab_set = set(VOCABULARY)\n",
    "\n",
    "print(f\"✓ Loaded vocabulary from: {VOCABULARY_PATH}\")\n",
    "print(f\"✓ Description: {vocab_data['description']}\")\n",
    "print(f\"✓ Vocabulary size: {len(VOCABULARY)}\")\n",
    "print(f\"✓ First 20 tokens: {VOCABULARY[:20]}\")\n",
    "print(f\"✓ Last 10 tokens: {VOCABULARY[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_section",
   "metadata": {},
   "source": [
    "### 2.3 Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(value) -> List[str]:\n",
    "    \"\"\"Parse label_name column into consistent Python lists.\"\"\"\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, tuple):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        if value.startswith('[') and value.endswith(']'):\n",
    "            # Remove brackets\n",
    "            inner = value[1:-1].strip()\n",
    "            if not inner:\n",
    "                return []\n",
    "            # Remove quotes and split by whitespace (handles both formats)\n",
    "            inner = inner.replace(\"'\", \"\").replace('\"', '')\n",
    "            labels = [l.strip() for l in inner.split() if l.strip()]\n",
    "            return labels\n",
    "        try:\n",
    "            parsed = ast.literal_eval(value)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                return [str(v) for v in parsed]\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "        return [value] if value else []\n",
    "    return [str(value)] if value else []\n",
    "\n",
    "def parse_binary_label(value) -> np.ndarray:\n",
    "    \"\"\"Parse binary label array from string representation.\"\"\"\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        # Parse \"[0 0 1 0 ...]\" format\n",
    "        inner = value.strip()[1:-1]\n",
    "        return np.array([int(x) for x in inner.split()])\n",
    "    return np.array(value)\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load tweets from parquet and normalize the label columns.\"\"\"\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.copy()\n",
    "    df[\"labels\"] = df[\"label_name\"].apply(parse_labels)\n",
    "    df[\"label_binary\"] = df[\"label\"].apply(parse_binary_label)\n",
    "    return df\n",
    "\n",
    "# Load all datasets\n",
    "df_train = load_dataset(TRAIN_DATA_PATH)\n",
    "df_test = load_dataset(TEST_DATA_PATH)\n",
    "df_validation = load_dataset(VALIDATION_DATA_PATH)\n",
    "\n",
    "print(f\"✓ Training set: {len(df_train):,} samples\")\n",
    "print(f\"✓ Test set: {len(df_test):,} samples\")\n",
    "print(f\"✓ Validation set: {len(df_validation):,} samples\")\n",
    "print(f\"\\nSample preprocessed text:\")\n",
    "print(f\"  {df_train['text'].iloc[0][:80]}...\")\n",
    "print(f\"  Labels: {df_train['labels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_conversion_section",
   "metadata": {},
   "source": [
    "### 2.4 Convert Multi-Label to Single-Label\n",
    "\n",
    "For comparison with a single-label classifier, we convert multi-label samples to single-label by keeping only the primary (first) label. This transformation is applied to both the `label_name` and `label` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single_label_conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 19 topic classes (from the original dataset)\n",
    "TOPIC_CLASSES = [\n",
    "    'arts_&_culture', 'business_&_entrepreneurs', 'celebrity_&_pop_culture',\n",
    "    'diaries_&_daily_life', 'family', 'fashion_&_style', 'film_tv_&_video',\n",
    "    'fitness_&_health', 'food_&_dining', 'gaming', 'learning_&_educational',\n",
    "    'music', 'news_&_social_concern', 'other_hobbies', 'relationships',\n",
    "    'science_&_technology', 'sports', 'travel_&_adventure', 'youth_&_student_life'\n",
    "]\n",
    "\n",
    "def convert_to_single_label(df: pd.DataFrame, topic_classes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert multi-label dataset to single-label by keeping only the primary (first) label.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with 'labels' (list of label names) and 'label_binary' (binary vector) columns\n",
    "    topic_classes : List[str]\n",
    "        List of all possible class names in order\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with added 'single_label' (string) and 'single_label_binary' (binary vector) columns\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract primary (first) label from the labels list\n",
    "    df['single_label'] = df['labels'].apply(lambda x: x[0] if x else 'unknown')\n",
    "    \n",
    "    # Create single-label binary vector (one-hot encoding)\n",
    "    def create_single_label_binary(label: str) -> np.ndarray:\n",
    "        binary = np.zeros(len(topic_classes), dtype=int)\n",
    "        if label in topic_classes:\n",
    "            binary[topic_classes.index(label)] = 1\n",
    "        return binary\n",
    "    \n",
    "    df['single_label_binary'] = df['single_label'].apply(create_single_label_binary)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Convert all datasets to single-label\n",
    "df_train = convert_to_single_label(df_train, TOPIC_CLASSES)\n",
    "df_test = convert_to_single_label(df_test, TOPIC_CLASSES)\n",
    "df_validation = convert_to_single_label(df_validation, TOPIC_CLASSES)\n",
    "\n",
    "# Show conversion statistics\n",
    "multi_label_count = (df_train['labels'].apply(len) > 1).sum()\n",
    "print(f\"✓ Converted datasets to single-label format\")\n",
    "print(f\"\\nMulti-label statistics (training set):\")\n",
    "print(f\"  Samples with multiple labels: {multi_label_count:,} ({100*multi_label_count/len(df_train):.1f}%)\")\n",
    "print(f\"  Samples with single label: {len(df_train) - multi_label_count:,} ({100*(len(df_train) - multi_label_count)/len(df_train):.1f}%)\")\n",
    "\n",
    "print(f\"\\nSingle-label distribution (training set):\")\n",
    "print(df_train['single_label'].value_counts())\n",
    "\n",
    "print(f\"\\nExample conversion:\")\n",
    "print(f\"  Original labels: {df_train['labels'].iloc[0]}\")\n",
    "print(f\"  Single label: {df_train['single_label'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plan_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Task 2: Implementation Plan\n",
    "\n",
    "### 3.1 Binary Feature Vector Construction\n",
    "For each sample, we create a binary vector of size 1000 (vocabulary size):\n",
    "- For each word in the vocabulary, set dimension to 1 if word is present in sample, 0 otherwise\n",
    "- This is a Bag-of-Words style encoding (word order is lost)\n",
    "\n",
    "### 3.2 MLPClassifier Configuration\n",
    "- **hidden_layer_sizes**: (128, 64, 128) - three hidden layers as specified\n",
    "- **activation**: 'relu' - ReLU activation (most commonly used)\n",
    "- **solver**: 'adam' - Adam optimizer (handles mini-batch gradient descent)\n",
    "- **max_iter**: 300 - sufficient iterations for convergence\n",
    "- **random_state**: 42 - for reproducibility\n",
    "- **early_stopping**: Disabled for multi-label (some classes have few samples), enabled for single-label\n",
    "\n",
    "### 3.3 Evaluation Metrics\n",
    "For multi-label classification:\n",
    "- Subset Accuracy (exact match)\n",
    "- Hamming Loss\n",
    "- Micro/Macro F1-Score\n",
    "\n",
    "For single-label classification:\n",
    "- Accuracy\n",
    "- Macro/Weighted F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementation_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Task 3: Multi-Label Classification\n",
    "\n",
    "### 4.1 Feature Engineering: Binary Vector Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_features(texts: pd.Series, vocabulary: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create binary feature vectors for text samples.\n",
    "    \n",
    "    Each dimension represents whether a word from the vocabulary\n",
    "    is present (1) or absent (0) in the sample.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    texts : pd.Series\n",
    "        Series of preprocessed text strings (whitespace-tokenized)\n",
    "    vocabulary : List[str]\n",
    "        List of vocabulary words (top 1000 from Lab 4)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Binary feature matrix of shape (n_samples, vocab_size)\n",
    "    \"\"\"\n",
    "    vocab_set = set(vocabulary)\n",
    "    vocab_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "    \n",
    "    n_samples = len(texts)\n",
    "    n_features = len(vocabulary)\n",
    "    \n",
    "    # Initialize feature matrix with zeros\n",
    "    features = np.zeros((n_samples, n_features), dtype=np.int8)\n",
    "    \n",
    "    # Fill in binary features\n",
    "    for i, text in enumerate(texts):\n",
    "        if isinstance(text, str):\n",
    "            words = set(text.split())\n",
    "            for word in words:\n",
    "                if word in vocab_to_idx:\n",
    "                    features[i, vocab_to_idx[word]] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create binary feature vectors for all datasets\n",
    "print(\"Creating binary feature vectors...\")\n",
    "X_train = create_binary_features(df_train['text'], VOCABULARY)\n",
    "X_test = create_binary_features(df_test['text'], VOCABULARY)\n",
    "X_validation = create_binary_features(df_validation['text'], VOCABULARY)\n",
    "\n",
    "print(f\"\\n✓ Feature matrix shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  X_validation: {X_validation.shape}\")\n",
    "\n",
    "# Show sample feature statistics\n",
    "print(f\"\\nFeature statistics (training set):\")\n",
    "print(f\"  Average features per sample: {X_train.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Max features in a sample: {X_train.sum(axis=1).max()}\")\n",
    "print(f\"  Min features in a sample: {X_train.sum(axis=1).min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "label_encoding_section",
   "metadata": {},
   "source": [
    "### 4.2 Label Encoding (Multi-Label Binarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "label_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pre-parsed binary labels directly from the label column\n",
    "y_train_multi = np.vstack(df_train['label_binary'].values)\n",
    "y_test_multi = np.vstack(df_test['label_binary'].values)\n",
    "y_validation_multi = np.vstack(df_validation['label_binary'].values)\n",
    "\n",
    "# Create MultiLabelBinarizer for inverse_transform (label names)\n",
    "mlb = MultiLabelBinarizer(classes=TOPIC_CLASSES)\n",
    "mlb.fit([TOPIC_CLASSES])  # Fit with all classes\n",
    "\n",
    "print(f\"✓ Number of classes: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"✓ Classes: {TOPIC_CLASSES}\")\n",
    "print(f\"\\n✓ Multi-label matrix shapes:\")\n",
    "print(f\"  y_train_multi: {y_train_multi.shape}\")\n",
    "print(f\"  y_test_multi: {y_test_multi.shape}\")\n",
    "print(f\"  y_validation_multi: {y_validation_multi.shape}\")\n",
    "\n",
    "# Verify label distribution\n",
    "print(f\"\\n✓ Label distribution (training set):\")\n",
    "print(f\"  Average labels per sample: {y_train_multi.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Samples per class: {y_train_multi.sum(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_training_section",
   "metadata": {},
   "source": [
    "### 4.3 Multi-Label Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_neural_network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLPClassifier with specified architecture\n",
    "# Using OneVsRestClassifier for multi-label classification\n",
    "# Note: early_stopping is disabled because some classes have very few samples\n",
    "# which causes issues with the validation split in OneVsRest multi-label setting\n",
    "mlp_base = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Three hidden layers as specified\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer (mini-batch gradient descent)\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=False,                # Disabled for multi-label compatibility\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "# Wrap with OneVsRestClassifier for multi-label support\n",
    "mlp_clf_multi = OneVsRestClassifier(mlp_base, n_jobs=-1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-LABEL NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(TOPIC_CLASSES)} neurons (19 binary classifiers)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining Multi-Label Neural Network...\")\n",
    "mlp_clf_multi.fit(X_train, y_train_multi)\n",
    "print(\"\\n✓ Multi-Label Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 4.4 Multi-Label Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_neural_network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_nn_multi = mlp_clf_multi.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_multi_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_nn_multi),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_nn_multi),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_nn_multi, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-LABEL NEURAL NETWORK EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_multi_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nn_sample_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "y_pred_labels = mlb.inverse_transform(y_pred_nn_multi)\n",
    "y_true_labels = mlb.inverse_transform(y_test_multi)\n",
    "\n",
    "print(\"\\nSample Multi-Label Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test['text'].iloc[i][:60]\n",
    "    true = y_true_labels[i] if y_true_labels[i] else ('none',)\n",
    "    pred = y_pred_labels[i] if y_pred_labels[i] else ('none',)\n",
    "    match = \"✓\" if set(true) == set(pred) else \"✗\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   True: {true}\")\n",
    "    print(f\"   Pred: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb_training_section",
   "metadata": {},
   "source": [
    "### 4.5 Naive Bayes Classifier (for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_naive_bayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes classifier with same features\n",
    "nb_clf = OneVsRestClassifier(MultinomialNB(alpha=1.0))\n",
    "nb_clf.fit(X_train, y_train_multi)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nb_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_nb),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_nb),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_nb, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_nb, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAIVE BAYES EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Task 4: Single-Label Classification\n",
    "\n",
    "For comparison, we train a neural network using single-label classification. Each tweet is assigned only its primary (first) label, converting the multi-label problem to a standard multi-class classification problem.\n",
    "\n",
    "### 5.1 Single-Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single_label_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label encoder for single-label classification\n",
    "le = LabelEncoder()\n",
    "le.fit(TOPIC_CLASSES)\n",
    "\n",
    "# Encode single labels as integers\n",
    "y_train_single = le.transform(df_train['single_label'])\n",
    "y_test_single = le.transform(df_test['single_label'])\n",
    "y_validation_single = le.transform(df_validation['single_label'])\n",
    "\n",
    "print(f\"✓ Single-label encoding complete\")\n",
    "print(f\"\\n✓ Label shapes:\")\n",
    "print(f\"  y_train_single: {y_train_single.shape}\")\n",
    "print(f\"  y_test_single: {y_test_single.shape}\")\n",
    "print(f\"  y_validation_single: {y_validation_single.shape}\")\n",
    "\n",
    "print(f\"\\n✓ Class mapping:\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    count = (y_train_single == i).sum()\n",
    "    print(f\"  {i}: {cls} ({count} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_nn_training_section",
   "metadata": {},
   "source": [
    "### 5.2 Single-Label Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_single_label_nn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLPClassifier for single-label classification\n",
    "# For single-label, MLPClassifier uses softmax output automatically\n",
    "mlp_clf_single = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Same architecture as multi-label\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=True,                 # Enable early stopping for single-label\n",
    "    validation_fraction=0.1,             # Use 10% for validation\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(TOPIC_CLASSES)} neurons (Softmax activation)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining Single-Label Neural Network...\")\n",
    "mlp_clf_single.fit(X_train, y_train_single)\n",
    "print(\"\\n✓ Single-Label Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 5.3 Single-Label Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_single_label_nn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_nn_single = mlp_clf_single.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_single_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_single, y_pred_nn_single),\n",
    "    'Macro F1': f1_score(y_test_single, y_pred_nn_single, average='macro', zero_division=0),\n",
    "    'Weighted F1': f1_score(y_test_single, y_pred_nn_single, average='weighted', zero_division=0),\n",
    "    'Macro Precision': precision_score(y_test_single, y_pred_nn_single, average='macro', zero_division=0),\n",
    "    'Macro Recall': recall_score(y_test_single, y_pred_nn_single, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL NEURAL NETWORK EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_single_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single_label_sample_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions for single-label\n",
    "print(\"\\nSample Single-Label Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test['text'].iloc[i][:60]\n",
    "    true_label = le.inverse_transform([y_test_single[i]])[0]\n",
    "    pred_label = le.inverse_transform([y_pred_nn_single[i]])[0]\n",
    "    original_labels = df_test['labels'].iloc[i]\n",
    "    match = \"✓\" if true_label == pred_label else \"✗\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   Original labels: {original_labels}\")\n",
    "    print(f\"   Single label (true): {true_label}\")\n",
    "    print(f\"   Single label (pred): {pred_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Comparison\n",
    "\n",
    "### 6.1 Multi-Label Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table for multi-label models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(nn_multi_metrics.keys()),\n",
    "    'Neural Network (Multi-Label)': list(nn_multi_metrics.values()),\n",
    "    'Naive Bayes (Multi-Label)': list(nb_metrics.values())\n",
    "})\n",
    "\n",
    "# Calculate improvement\n",
    "comparison_df['Difference'] = comparison_df['Neural Network (Multi-Label)'] - comparison_df['Naive Bayes (Multi-Label)']\n",
    "comparison_df['Better Model'] = comparison_df.apply(\n",
    "    lambda row: 'Neural Network' if (row['Difference'] > 0 and row['Metric'] != 'Hamming Loss') \n",
    "                or (row['Difference'] < 0 and row['Metric'] == 'Hamming Loss')\n",
    "                else 'Naive Bayes' if row['Difference'] != 0 else 'Tie',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-LABEL MODEL COMPARISON: Neural Network vs Naive Bayes\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: For Hamming Loss, lower is better. For all other metrics, higher is better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_vs_multi_section",
   "metadata": {},
   "source": [
    "### 6.2 Single-Label vs Multi-Label Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single_vs_multi_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare single-label NN predictions against multi-label ground truth\n",
    "# Convert single-label predictions to multi-label format for comparison\n",
    "y_pred_single_as_multi = np.zeros((len(y_pred_nn_single), len(TOPIC_CLASSES)), dtype=int)\n",
    "for i, pred in enumerate(y_pred_nn_single):\n",
    "    y_pred_single_as_multi[i, pred] = 1\n",
    "\n",
    "# Calculate metrics for single-label NN on multi-label test set\n",
    "single_on_multi_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_single_as_multi),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_single_as_multi),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_single_as_multi, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_single_as_multi, average='macro', zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SINGLE-LABEL VS MULTI-LABEL NEURAL NETWORK COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Metric':<20} {'Multi-Label NN':<18} {'Single-Label NN':<18} {'Difference':<12}\")\n",
    "print(\"-\"*70)\n",
    "for metric in ['Subset Accuracy', 'Hamming Loss', 'Micro F1', 'Macro F1']:\n",
    "    multi = nn_multi_metrics[metric]\n",
    "    single = single_on_multi_metrics[metric]\n",
    "    diff = multi - single\n",
    "    print(f\"{metric:<20} {multi:<18.4f} {single:<18.4f} {diff:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nNote: Single-label NN can only predict one class per sample.\")\n",
    "print(\"Comparison is made against the original multi-label ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "all_models_summary_section",
   "metadata": {},
   "source": [
    "### 6.3 All Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "all_models_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary table\n",
    "print(\"=\"*90)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"MULTI-LABEL CLASSIFICATION RESULTS (evaluated on multi-label test set)\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Model':<35} {'Accuracy':<12} {'Micro F1':<12} {'Macro F1':<12} {'Hamming Loss':<12}\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Multi-Label Neural Network':<35} {nn_multi_metrics['Subset Accuracy']:<12.4f} {nn_multi_metrics['Micro F1']:<12.4f} {nn_multi_metrics['Macro F1']:<12.4f} {nn_multi_metrics['Hamming Loss']:<12.4f}\")\n",
    "print(f\"{'Naive Bayes (Multi-Label)':<35} {nb_metrics['Subset Accuracy']:<12.4f} {nb_metrics['Micro F1']:<12.4f} {nb_metrics['Macro F1']:<12.4f} {nb_metrics['Hamming Loss']:<12.4f}\")\n",
    "print(f\"{'Single-Label NN (on multi-label)':<35} {single_on_multi_metrics['Subset Accuracy']:<12.4f} {single_on_multi_metrics['Micro F1']:<12.4f} {single_on_multi_metrics['Macro F1']:<12.4f} {single_on_multi_metrics['Hamming Loss']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"SINGLE-LABEL CLASSIFICATION RESULTS (evaluated on single-label test set)\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Model':<35} {'Accuracy':<12} {'Weighted F1':<12} {'Macro F1':<12}\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Single-Label Neural Network':<35} {nn_single_metrics['Accuracy']:<12.4f} {nn_single_metrics['Weighted F1']:<12.4f} {nn_single_metrics['Macro F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Optional: Experiment with Different Network Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experiment_architectures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different architectures to test\n",
    "architectures = {\n",
    "    'Small (64-32-64)': (64, 32, 64),\n",
    "    'Medium (128-64-128)': (128, 64, 128),  # Original\n",
    "    'Large (256-128-256)': (256, 128, 256),\n",
    "    'Deep (128-128-64-64-128-128)': (128, 128, 64, 64, 128, 128),\n",
    "    'Wide (512-256-512)': (512, 256, 512)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Experimenting with different network architectures (Multi-Label)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, layers in architectures.items():\n",
    "    print(f\"\\nTraining: {name}...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=layers,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=200,\n",
    "        random_state=RANDOM_STATE,\n",
    "        early_stopping=False,  # Disabled for multi-label compatibility\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    clf = OneVsRestClassifier(mlp, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train_multi)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        'Architecture': name,\n",
    "        'Layers': str(layers),\n",
    "        'Accuracy': accuracy_score(y_test_multi, y_pred),\n",
    "        'Micro F1': f1_score(y_test_multi, y_pred, average='micro', zero_division=0),\n",
    "        'Macro F1': f1_score(y_test_multi, y_pred, average='macro', zero_division=0)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {results[-1]['Accuracy']:.4f}, Micro F1: {results[-1]['Micro F1']:.4f}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHITECTURE COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary\n",
    "\n",
    "### What was accomplished\n",
    "1. Loaded preprocessed data from Lab 2 and vocabulary from Lab 4\n",
    "2. Created binary feature vectors (Bag-of-Words encoding) for all samples\n",
    "3. Trained a Multi-Label Neural Network with 128→64→128 hidden layers using MLPClassifier and OneVsRestClassifier\n",
    "4. Converted multi-label data to single-label by keeping only the primary label\n",
    "5. Trained a Single-Label Neural Network with the same architecture\n",
    "6. Compared Multi-Label NN, Single-Label NN, and Naive Bayes classifiers\n",
    "7. Experimented with different network architectures\n",
    "\n",
    "### Key Findings\n",
    "- Multi-label classification allows predicting multiple topics per tweet\n",
    "- Single-label classification simplifies the problem but loses information about secondary topics\n",
    "- Neural networks can capture non-linear relationships in text classification\n",
    "- The MLPClassifier with ReLU activation and Adam optimizer provides good results\n",
    "- For multi-label tasks, OneVsRestClassifier trains separate binary classifiers per class\n",
    "- For single-label tasks, MLPClassifier uses softmax output for probability distribution\n",
    "- Network architecture affects performance, but larger isn't always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LAB 5 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input vocabulary: {VOCABULARY_PATH}\")\n",
    "print(f\"Training samples: {len(df_train):,}\")\n",
    "print(f\"Test samples: {len(df_test):,}\")\n",
    "print(f\"Feature vector size: {X_train.shape[1]}\")\n",
    "print(f\"Number of classes: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"\\nMulti-Label Neural Network Metrics:\")\n",
    "print(f\"  Subset Accuracy: {nn_multi_metrics['Subset Accuracy']:.4f}\")\n",
    "print(f\"  Micro F1: {nn_multi_metrics['Micro F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_multi_metrics['Macro F1']:.4f}\")\n",
    "print(f\"\\nSingle-Label Neural Network Metrics:\")\n",
    "print(f\"  Accuracy: {nn_single_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Weighted F1: {nn_single_metrics['Weighted F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_single_metrics['Macro F1']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}