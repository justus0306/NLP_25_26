{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e50a659",
   "metadata": {},
   "source": [
    "# Lab 5: Neural Network Classification with scikit-learn\n",
    "\n",
    "---\n",
    "## 1. Notebook Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "- Re-use the most frequent words (optional: per class) you found for\n",
    "your Naive Bayes classifier last week.\n",
    "\n",
    "- Construct binary vectors for your whole dataset. Each dimension states\n",
    "whether the word is part of the sample or not.\n",
    "\n",
    "- Create a small neural network using scikit-learn: https://scikit-learn.org/\n",
    "stable/modules/neural_networks_supervised.html. Start with three\n",
    "hidden layers of 128/64/128 neurons. Consider what your input and\n",
    "output layers should look like.\n",
    "\n",
    "- Train your network on your training set and test it on your test set.\n",
    "Calculate evaluation measures and compare with your previous\n",
    "classifier.\n",
    "\n",
    "- Optional: Experiment with different network sizes.\n",
    "\n",
    "### 1.2 Prerequisites\n",
    "This notebook assumes you have already executed:\n",
    "- **Lab 2**: Data preprocessing ‚Üí `../Data/multi_label/tweets_preprocessed_*.parquet`\n",
    "- **Lab 3**: Language modeling\n",
    "- **Lab 4**: Feature extraction ‚Üí `../Data/top_1000_vocabulary.json`\n",
    "- **Single-Label**: `../Data/single_label/tweets_single_label_*.parquet`\n",
    "\n",
    "### 1.3 Architecture\n",
    "We implement neural networks with:\n",
    "- **Input layer**: 1000 features (Top 1000 vocabulary from Lab 4)\n",
    "- **Hidden layers**: 128 ‚Üí 64 ‚Üí 128 neurons (as specified)\n",
    "- **Output layer**: \n",
    "  - Multi-label: 14 binary classifiers (one per topic class, using OneVsRestClassifier)\n",
    "  - Single-label: 14 classes with Softmax activation\n",
    "\n",
    "### 1.4 Neural Network Fundamentals (From Lecture)\n",
    "- A single neuron computes: ≈∑ = g(w‚ÇÄ + Œ£ x·µ¢w·µ¢) where g is a non-linear activation function\n",
    "- **Activation functions are critical** - they introduce non-linearities that make multi-layer networks powerful (universal approximators)\n",
    "- Common activations: ReLU (g(z) = max(0,z)), Sigmoid, Tanh\n",
    "- For multi-class (single-label): use **Softmax** to convert outputs to probabilities\n",
    "- For multi-label: use **Sigmoid** per class via OneVsRestClassifier\n",
    "- **Loss function for classification**: Cross-entropy loss\n",
    "- Weights should NOT be initialized to all zeros (breaks symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Task 1: Establish Context\n",
    "\n",
    "### 2.1 Review Preprocessing from Lab 2\n",
    "In Lab 2, we preprocessed tweets with the following pipeline:\n",
    "- Remove RT indicators, URLs, usernames, and mentions\n",
    "- Convert emojis to text descriptions\n",
    "- Extract hashtag text and segment CamelCase words\n",
    "- Normalize whitespace and lowercase\n",
    "- Tokenize with SpaCy and filter/lemmatize tokens\n",
    "\n",
    "The output is stored in parquet files with columns: `text`, `label_name`, `label`\n",
    "\n",
    "Two approaches for label handling are supported:\n",
    "- Parse `label_name` (string list format) into Python lists\n",
    "- Use `label` column directly (pre-computed binary vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import hashlib\n",
    "import time\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    hamming_loss,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants - Updated paths to new folder structure\n",
    "TRAIN_DATA_PATH = \"../Data/multi_label/tweets_preprocessed_train.parquet\"\n",
    "TEST_DATA_PATH = \"../Data/multi_label/tweets_preprocessed_test.parquet\"\n",
    "VALIDATION_DATA_PATH = \"../Data/multi_label/tweets_preprocessed_validation.parquet\"\n",
    "VOCABULARY_PATH = \"../Data/top_1000_vocabulary.json\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_vocab_section",
   "metadata": {},
   "source": [
    "### 2.2 Load and Verify Vocabulary from Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "load_vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded vocabulary from: ../Data/top_1000_vocabulary.json\n",
      "‚úì Description: Top 1000 most frequent tokens from preprocessed tweets (Lab 4)\n",
      "‚úì Vocabulary size: 1000\n",
      "‚úì First 20 tokens: ['new', 'game', 'day', 'good', 'year', 'love', 'time', 'win', 'come', 'happy', 'like', 'watch', 'go', 'world', 'live', 'today', 'red', 'team', 'great', 'heart']\n",
      "‚úì Last 10 tokens: ['straight', 'google', 'december', 'thankful', 'oklahoma', 'donald', 'army', 'beverage', 'education', 'titan']\n"
     ]
    }
   ],
   "source": [
    "# Load the top 1000 vocabulary from Lab 4\n",
    "with open(VOCABULARY_PATH, 'r', encoding='utf-8') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "VOCABULARY = vocab_data['tokens']\n",
    "vocab_set = set(VOCABULARY)\n",
    "\n",
    "print(f\"‚úì Loaded vocabulary from: {VOCABULARY_PATH}\")\n",
    "print(f\"‚úì Description: {vocab_data['description']}\")\n",
    "print(f\"‚úì Vocabulary size: {len(VOCABULARY)}\")\n",
    "print(f\"‚úì First 20 tokens: {VOCABULARY[:20]}\")\n",
    "print(f\"‚úì Last 10 tokens: {VOCABULARY[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_section",
   "metadata": {},
   "source": [
    "### 2.3 Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "load_datasets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training set: 5,465 samples\n",
      "‚úì Test set: 1,511 samples\n",
      "‚úì Validation set: 178 samples\n",
      "\n",
      "Sample preprocessed text:\n",
      "  lumber beat rapid game western division final evan edwards hit hr wp josh robers...\n",
      "  Labels: ['sports']\n"
     ]
    }
   ],
   "source": [
    "def parse_labels(value) -> List[str]:\n",
    "    \"\"\"Parse label_name column into consistent Python lists.\"\"\"\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, tuple):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        if value.startswith('[') and value.endswith(']'):\n",
    "            # Remove brackets\n",
    "            inner = value[1:-1].strip()\n",
    "            if not inner:\n",
    "                return []\n",
    "            # Remove quotes and split by whitespace (handles both formats)\n",
    "            inner = inner.replace(\"'\", \"\").replace('\"', '')\n",
    "            labels = [l.strip() for l in inner.split() if l.strip()]\n",
    "            return labels\n",
    "        try:\n",
    "            parsed = ast.literal_eval(value)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                return [str(v) for v in parsed]\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "        return [value] if value else []\n",
    "    return [str(value)] if value else []\n",
    "\n",
    "def parse_binary_label(value) -> np.ndarray:\n",
    "    \"\"\"Parse binary label array from string representation.\"\"\"\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        # Parse \"[0 0 1 0 ...]\" format\n",
    "        inner = value.strip()[1:-1]\n",
    "        return np.array([int(x) for x in inner.split()])\n",
    "    return np.array(value)\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load tweets from parquet and normalize the label columns.\"\"\"\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.copy()\n",
    "    df[\"labels\"] = df[\"label_name\"].apply(parse_labels)\n",
    "    df[\"label_binary\"] = df[\"label\"].apply(parse_binary_label)\n",
    "    return df\n",
    "\n",
    "# Load all datasets\n",
    "df_train = load_dataset(TRAIN_DATA_PATH)\n",
    "df_test = load_dataset(TEST_DATA_PATH)\n",
    "df_validation = load_dataset(VALIDATION_DATA_PATH)\n",
    "\n",
    "print(f\"‚úì Training set: {len(df_train):,} samples\")\n",
    "print(f\"‚úì Test set: {len(df_test):,} samples\")\n",
    "print(f\"‚úì Validation set: {len(df_validation):,} samples\")\n",
    "print(f\"\\nSample preprocessed text:\")\n",
    "print(f\"  {df_train['text'].iloc[0][:80]}...\")\n",
    "print(f\"  Labels: {df_train['labels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b3de7689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUTOMATISCHE KLASSEN-ERKENNUNG\n",
      "============================================================\n",
      "\n",
      "‚úì Anzahl Klassen (aus label_binary): 6\n",
      "‚úì Klassennamen aus Daten extrahiert: 6\n",
      "‚úì Klassen: ['celebrity_&_pop_culture', 'diaries_&_daily_life', 'film_tv_&_video', 'music', 'news_&_social_concern', 'sports']\n",
      "\n",
      "‚úì Beispiel-Daten:\n",
      "  Text: lumber beat rapid game western division final evan edwards h...\n",
      "  Labels (Namen): ['sports']\n",
      "  Labels (Bin√§r): [0 0 0 0 0 1]\n",
      "\n",
      "‚úì Dataset-Statistiken:\n",
      "  Training: 5,465 Samples\n",
      "  Test: 1,511 Samples\n",
      "  Validation: 178 Samples\n",
      "  Gesamt: 7,154 Samples\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DYNAMISCHE KLASSEN-ERKENNUNG AUS DEN DATEN\n",
    "# ============================================================\n",
    "# Diese Zelle passt sich automatisch an die Daten an, \n",
    "# unabh√§ngig davon wie viele Klassen nach dem Preprocessing √ºbrig sind.\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUTOMATISCHE KLASSEN-ERKENNUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Bestimme die Anzahl der Klassen aus den bin√§ren Label-Vektoren\n",
    "num_classes = len(df_train['label_binary'].iloc[0])\n",
    "print(f\"\\n‚úì Anzahl Klassen (aus label_binary): {num_classes}\")\n",
    "\n",
    "# 2. Extrahiere alle einzigartigen Klassennamen aus label_name\n",
    "all_class_names = set()\n",
    "for df in [df_train, df_test, df_validation]:\n",
    "    for labels in df['labels']:\n",
    "        all_class_names.update(labels)\n",
    "\n",
    "TOPIC_CLASSES = sorted(list(all_class_names))\n",
    "print(f\"‚úì Klassennamen aus Daten extrahiert: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"‚úì Klassen: {TOPIC_CLASSES}\")\n",
    "\n",
    "# 3. Verifiziere Konsistenz\n",
    "if len(TOPIC_CLASSES) != num_classes:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNUNG: Anzahl Klassennamen ({len(TOPIC_CLASSES)}) != Anzahl Spalten in label_binary ({num_classes})\")\n",
    "    print(\"   Das kann passieren wenn label_name und label nicht synchron sind.\")\n",
    "    print(\"   Verwende Anzahl aus label_binary als ma√ügeblich.\")\n",
    "    \n",
    "# 4. Zeige Beispiel-Daten\n",
    "print(f\"\\n‚úì Beispiel-Daten:\")\n",
    "print(f\"  Text: {df_train['text'].iloc[0][:60]}...\")\n",
    "print(f\"  Labels (Namen): {df_train['labels'].iloc[0]}\")\n",
    "print(f\"  Labels (Bin√§r): {df_train['label_binary'].iloc[0]}\")\n",
    "\n",
    "# 5. Statistiken\n",
    "print(f\"\\n‚úì Dataset-Statistiken:\")\n",
    "print(f\"  Training: {len(df_train):,} Samples\")\n",
    "print(f\"  Test: {len(df_test):,} Samples\")\n",
    "print(f\"  Validation: {len(df_validation):,} Samples\")\n",
    "print(f\"  Gesamt: {len(df_train) + len(df_test) + len(df_validation):,} Samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_conversion_section",
   "metadata": {},
   "source": [
    "### 2.4 Intelligent Single-Label Assignment with Claude Haiku\n",
    "\n",
    "For comparison with a single-label classifier, we convert multi-label samples to single-label. Instead of simply taking the first label, we use **Claude Haiku** to intelligently decide which label best represents the tweet's main topic.\n",
    "\n",
    "**Strategy:**\n",
    "1. **Single-label tweets**: Keep the label as-is\n",
    "2. **Multi-label tweets**: Use Claude Haiku to analyze the tweet and select the most appropriate single label\n",
    "3. **Caching**: Results are cached to avoid redundant API calls and reduce costs\n",
    "\n",
    "This approach addresses the problem of arbitrary label selection and leverages semantic understanding to pick the most relevant label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "single_label_conversion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è ANTHROPIC_API_KEY nicht gefunden!\n",
      "   Bitte setze die Umgebungsvariable oder gib den Key hier ein:\n",
      "   export ANTHROPIC_API_KEY='dein-api-key'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INTELLIGENTE SINGLE-LABEL ZUWEISUNG MIT CLAUDE HAIKU\n",
    "# ============================================================\n",
    "import anthropic\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Cache-Pfad f√ºr API-Ergebnisse (spart Kosten bei erneutem Ausf√ºhren)\n",
    "CACHE_PATH = Path(\"../Data/single_label/single_label_cache.json\")\n",
    "\n",
    "# Anthropic Client initialisieren\n",
    "# API Key aus Umgebungsvariable oder direkt setzen\n",
    "ANTHROPIC_API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", None)\n",
    "\n",
    "if ANTHROPIC_API_KEY is None:\n",
    "    print(\"‚ö†Ô∏è ANTHROPIC_API_KEY nicht gefunden!\")\n",
    "    print(\"   Bitte setze die Umgebungsvariable oder gib den Key hier ein:\")\n",
    "    print(\"   export ANTHROPIC_API_KEY='dein-api-key'\")\n",
    "    USE_LLM = False\n",
    "else:\n",
    "    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "    USE_LLM = True\n",
    "    print(\"‚úì Anthropic Client initialisiert\")\n",
    "\n",
    "def load_cache() -> dict:\n",
    "    \"\"\"Lade gecachte Single-Label Entscheidungen.\"\"\"\n",
    "    if CACHE_PATH.exists():\n",
    "        with open(CACHE_PATH, 'r', encoding='utf-8') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache: dict):\n",
    "    \"\"\"Speichere Cache auf Disk.\"\"\"\n",
    "    with open(CACHE_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cache, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_cache_key(text: str, labels: list) -> str:\n",
    "    \"\"\"Erstelle einen eindeutigen Cache-Key f√ºr Tweet + Labels.\"\"\"\n",
    "    content = f\"{text}|{','.join(sorted(labels))}\"\n",
    "    return hashlib.md5(content.encode()).hexdigest()\n",
    "\n",
    "def classify_with_haiku(text: str, labels: list, cache: dict) -> str:\n",
    "    \"\"\"\n",
    "    Verwende Claude Haiku um das passendste Label auszuw√§hlen.\n",
    "    Mit Caching um API-Kosten zu minimieren.\n",
    "    \"\"\"\n",
    "    cache_key = get_cache_key(text, labels)\n",
    "    \n",
    "    # Pr√ºfe Cache\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    # Falls LLM nicht verf√ºgbar, nimm erstes Label\n",
    "    if not USE_LLM:\n",
    "        return labels[0]\n",
    "    \n",
    "    # Erstelle Prompt\n",
    "    system_prompt = \"\"\"Du bist ein Experte f√ºr Tweet-Klassifizierung. \n",
    "Deine Aufgabe ist es, das EINE passendste Label f√ºr einen Tweet auszuw√§hlen.\n",
    "Antworte NUR mit dem gew√§hlten Label, nichts anderes.\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"Tweet: \"{text}\"\n",
    "\n",
    "M√∂gliche Labels: {', '.join(labels)}\n",
    "\n",
    "Welches Label passt am besten zu diesem Tweet? Antworte nur mit dem Label.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=50,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            system=system_prompt\n",
    "        )\n",
    "        \n",
    "        result = response.content[0].text.strip()\n",
    "        \n",
    "        # Validiere dass das Ergebnis ein g√ºltiges Label ist\n",
    "        if result in labels:\n",
    "            cache[cache_key] = result\n",
    "            return result\n",
    "        else:\n",
    "            # Falls LLM ung√ºltiges Label zur√ºckgibt, finde beste √úbereinstimmung\n",
    "            for label in labels:\n",
    "                if label.lower() in result.lower():\n",
    "                    cache[cache_key] = label\n",
    "                    return label\n",
    "            # Fallback: erstes Label\n",
    "            cache[cache_key] = labels[0]\n",
    "            return labels[0]\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"API Error: {e}\")\n",
    "        return labels[0]  # Fallback\n",
    "\n",
    "def assign_single_labels_smart(df, cache: dict, desc: str = \"Processing\") -> list:\n",
    "    \"\"\"\n",
    "    Weise jedem Sample das beste Single-Label zu.\n",
    "    Verwendet LLM nur f√ºr Samples mit mehreren Labels.\n",
    "    \"\"\"\n",
    "    single_labels = []\n",
    "    api_calls = 0\n",
    "    cache_hits = 0\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=desc):\n",
    "        labels = row['labels']\n",
    "        \n",
    "        if len(labels) == 1:\n",
    "            # Nur ein Label - keine Entscheidung n√∂tig\n",
    "            single_labels.append(labels[0])\n",
    "        else:\n",
    "            # Mehrere Labels - LLM entscheidet (oder Cache)\n",
    "            cache_key = get_cache_key(row['text'], labels)\n",
    "            if cache_key in cache:\n",
    "                cache_hits += 1\n",
    "            else:\n",
    "                api_calls += 1\n",
    "            \n",
    "            best_label = classify_with_haiku(row['text'], labels, cache)\n",
    "            single_labels.append(best_label)\n",
    "            \n",
    "            # Speichere Cache regelm√§√üig\n",
    "            if api_calls > 0 and api_calls % 100 == 0:\n",
    "                save_cache(cache)\n",
    "                print(f\"\\n  üíæ Cache gespeichert ({api_calls} API calls, {cache_hits} cache hits)\")\n",
    "    \n",
    "    print(f\"\\n  üìä Statistik: {api_calls} API calls, {cache_hits} cache hits, {len(df) - api_calls - cache_hits} single-label samples\")\n",
    "    return single_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c604b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SINGLE-LABEL DATEN\n",
      "======================================================================\n",
      "\n",
      "üìÇ Lade gespeicherte Single-Label Dateien...\n",
      "‚úì Training Set geladen: 5,465 Samples\n",
      "‚úì Test Set geladen: 1,511 Samples\n",
      "‚úì Validation Set geladen: 178 Samples\n",
      "\n",
      "‚úì Single-Label Verteilung (Training):\n",
      "single_label\n",
      "sports                     1617\n",
      "news_&_social_concern      1421\n",
      "music                      1046\n",
      "film_tv_&_video             618\n",
      "diaries_&_daily_life        561\n",
      "celebrity_&_pop_culture     202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üí° Tipp: Setze REGENERATE_SINGLE_LABELS = True um die Dateien zu aktualisieren\n",
      "\n",
      "======================================================================\n",
      "‚úì Single-Label Daten bereit!\n",
      "======================================================================\n",
      "\n",
      "üìä Zusammenfassung:\n",
      "  Training: 5,465 Samples\n",
      "  Test: 1,511 Samples\n",
      "  Validation: 178 Samples\n",
      "\n",
      "  Spalten: ['text', 'label_name', 'label', 'labels', 'label_binary', 'single_label', 'single_label_binary']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL DATEN LADEN ODER GENERIEREN\n",
    "# ============================================================\n",
    "# Setze REGENERATE_SINGLE_LABELS = True um die LLM-Klassifizierung \n",
    "# erneut durchzuf√ºhren und die Dateien zu aktualisieren.\n",
    "# Standardm√§√üig werden die gespeicherten Dateien geladen.\n",
    "\n",
    "REGENERATE_SINGLE_LABELS = False  # ‚Üê Auf True setzen um LLM-Klassifizierung zu starten\n",
    "\n",
    "# Definiere Pfade\n",
    "SINGLE_LABEL_TRAIN_PATH = \"../Data/single_label/tweets_single_label_train\"\n",
    "SINGLE_LABEL_TEST_PATH = \"../Data/single_label/tweets_single_label_test\"\n",
    "SINGLE_LABEL_VALIDATION_PATH = \"../Data/single_label/tweets_single_label_validation\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SINGLE-LABEL DATEN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pr√ºfe ob gespeicherte Dateien existieren\n",
    "train_exists = Path(f\"{SINGLE_LABEL_TRAIN_PATH}.parquet\").exists()\n",
    "test_exists = Path(f\"{SINGLE_LABEL_TEST_PATH}.parquet\").exists()\n",
    "val_exists = Path(f\"{SINGLE_LABEL_VALIDATION_PATH}.parquet\").exists()\n",
    "all_files_exist = train_exists and test_exists and val_exists\n",
    "\n",
    "if not REGENERATE_SINGLE_LABELS and all_files_exist:\n",
    "    # ============================================================\n",
    "    # OPTION 1: Lade gespeicherte Single-Label Dateien\n",
    "    # ============================================================\n",
    "    print(\"\\nüìÇ Lade gespeicherte Single-Label Dateien...\")\n",
    "    \n",
    "    df_train_single = pd.read_parquet(f\"{SINGLE_LABEL_TRAIN_PATH}.parquet\")\n",
    "    df_test_single = pd.read_parquet(f\"{SINGLE_LABEL_TEST_PATH}.parquet\")\n",
    "    df_validation_single = pd.read_parquet(f\"{SINGLE_LABEL_VALIDATION_PATH}.parquet\")\n",
    "    \n",
    "    # Parse labels falls n√∂tig (f√ºr Kompatibilit√§t)\n",
    "    for df in [df_train_single, df_test_single, df_validation_single]:\n",
    "        if 'labels' not in df.columns and 'label_name' in df.columns:\n",
    "            df['labels'] = df['label_name'].apply(parse_labels)\n",
    "    \n",
    "    print(f\"‚úì Training Set geladen: {len(df_train_single):,} Samples\")\n",
    "    print(f\"‚úì Test Set geladen: {len(df_test_single):,} Samples\")\n",
    "    print(f\"‚úì Validation Set geladen: {len(df_validation_single):,} Samples\")\n",
    "    \n",
    "    # √úberschreibe df_train/test/validation mit den Single-Label Versionen\n",
    "    df_train = df_train_single\n",
    "    df_test = df_test_single\n",
    "    df_validation = df_validation_single\n",
    "    \n",
    "    print(f\"\\n‚úì Single-Label Verteilung (Training):\")\n",
    "    print(df_train['single_label'].value_counts())\n",
    "    \n",
    "    print(\"\\nüí° Tipp: Setze REGENERATE_SINGLE_LABELS = True um die Dateien zu aktualisieren\")\n",
    "\n",
    "else:\n",
    "    # ============================================================\n",
    "    # OPTION 2: Generiere Single-Labels mit LLM\n",
    "    # ============================================================\n",
    "    if not all_files_exist:\n",
    "        print(\"\\n‚ö†Ô∏è Single-Label Dateien nicht gefunden - generiere mit LLM...\")\n",
    "    else:\n",
    "        print(\"\\nüîÑ REGENERATE_SINGLE_LABELS = True - generiere Single-Labels mit LLM...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"INTELLIGENTE SINGLE-LABEL ZUWEISUNG MIT CLAUDE HAIKU\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Konvertiere alle Datasets\n",
    "    print(\"\\nüìå Training Set:\")\n",
    "    df_train = assign_single_label_intelligent(df_train, TOPIC_CLASSES, use_llm=USE_LLM)\n",
    "    \n",
    "    print(\"\\nüìå Test Set:\")\n",
    "    df_test = assign_single_label_intelligent(df_test, TOPIC_CLASSES, use_llm=USE_LLM)\n",
    "    \n",
    "    print(\"\\nüìå Validation Set:\")\n",
    "    df_validation = assign_single_label_intelligent(df_validation, TOPIC_CLASSES, use_llm=USE_LLM)\n",
    "    \n",
    "    # Statistiken anzeigen\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SINGLE-LABEL VERTEILUNG (Training Set)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(df_train['single_label'].value_counts())\n",
    "    \n",
    "    # Vergleich: Original erstes Label vs. LLM-Auswahl\n",
    "    if USE_LLM:\n",
    "        original_first = df_train['labels'].apply(lambda x: x[0])\n",
    "        llm_selected = df_train['single_label']\n",
    "        changed = (original_first != llm_selected).sum()\n",
    "        print(f\"\\n‚úì LLM hat {changed:,} Labels anders gew√§hlt als 'erstes Label' ({100*changed/len(df_train):.1f}%)\")\n",
    "        \n",
    "        # Beispiele zeigen wo LLM anders entschieden hat\n",
    "        changed_mask = original_first != llm_selected\n",
    "        if changed_mask.any():\n",
    "            print(\"\\nüìå Beispiele wo LLM anders entschieden hat:\")\n",
    "            examples = df_train[changed_mask].head(5)\n",
    "            for idx, row in examples.iterrows():\n",
    "                print(f\"\\n  Text: {row['text'][:80]}...\")\n",
    "                print(f\"  Original Labels: {row['labels']}\")\n",
    "                print(f\"  Erstes Label w√§re: {row['labels'][0]}\")\n",
    "                print(f\"  LLM w√§hlte: {row['single_label']}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # SPEICHERE SINGLE-LABEL DATEN (nur Parquet)\n",
    "    # ============================================================\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SPEICHERE SINGLE-LABEL DATASETS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Speichere Training Set\n",
    "    df_train.to_parquet(f\"{SINGLE_LABEL_TRAIN_PATH}.parquet\", index=False)\n",
    "    print(f\"‚úì Training Set gespeichert: {SINGLE_LABEL_TRAIN_PATH}.parquet\")\n",
    "    \n",
    "    # Speichere Test Set\n",
    "    df_test.to_parquet(f\"{SINGLE_LABEL_TEST_PATH}.parquet\", index=False)\n",
    "    print(f\"‚úì Test Set gespeichert: {SINGLE_LABEL_TEST_PATH}.parquet\")\n",
    "    \n",
    "    # Speichere Validation Set\n",
    "    df_validation.to_parquet(f\"{SINGLE_LABEL_VALIDATION_PATH}.parquet\", index=False)\n",
    "    print(f\"‚úì Validation Set gespeichert: {SINGLE_LABEL_VALIDATION_PATH}.parquet\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úì Single-Label Daten bereit!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Zusammenfassung:\")\n",
    "print(f\"  Training: {len(df_train):,} Samples\")\n",
    "print(f\"  Test: {len(df_test):,} Samples\")  \n",
    "print(f\"  Validation: {len(df_validation):,} Samples\")\n",
    "print(f\"\\n  Spalten: {list(df_train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plan_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Task 2: Implementation Plan\n",
    "\n",
    "### 3.1 Binary Feature Vector Construction\n",
    "For each sample, we create a binary vector of size 1000 (vocabulary size):\n",
    "- For each word in the vocabulary, set dimension to 1 if word is present in sample, 0 otherwise\n",
    "- This is a Bag-of-Words style encoding (word order is lost)\n",
    "\n",
    "### 3.2 MLPClassifier Configuration\n",
    "- **hidden_layer_sizes**: (128, 64, 128) - three hidden layers as specified\n",
    "- **activation**: 'relu' - ReLU activation (most commonly used)\n",
    "- **solver**: 'adam' - Adam optimizer (handles mini-batch gradient descent)\n",
    "- **max_iter**: 300 - sufficient iterations for convergence\n",
    "- **random_state**: 42 - for reproducibility\n",
    "- **early_stopping**: Disabled for multi-label (some classes have few samples), enabled for single-label\n",
    "\n",
    "### 3.3 Evaluation Metrics\n",
    "For multi-label classification:\n",
    "- Subset Accuracy (exact match)\n",
    "- Hamming Loss\n",
    "- Micro/Macro F1-Score\n",
    "\n",
    "For single-label classification:\n",
    "- Accuracy\n",
    "- Macro/Weighted F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementation_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Task 3: Multi-Label Classification\n",
    "\n",
    "### 4.1 Feature Engineering: Binary Vector Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating binary feature vectors...\n",
      "\n",
      "‚úì Feature matrix shapes:\n",
      "  X_train: (5465, 1000)\n",
      "  X_test: (1511, 1000)\n",
      "  X_validation: (178, 1000)\n",
      "\n",
      "Feature statistics (training set):\n",
      "  Average features per sample: 7.71\n",
      "  Max features in a sample: 22\n",
      "  Min features in a sample: 0\n"
     ]
    }
   ],
   "source": [
    "def create_binary_features(texts: pd.Series, vocabulary: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create binary feature vectors for text samples.\n",
    "    \n",
    "    Each dimension represents whether a word from the vocabulary\n",
    "    is present (1) or absent (0) in the sample.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    texts : pd.Series\n",
    "        Series of preprocessed text strings (whitespace-tokenized)\n",
    "    vocabulary : List[str]\n",
    "        List of vocabulary words (top 1000 from Lab 4)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Binary feature matrix of shape (n_samples, vocab_size)\n",
    "    \"\"\"\n",
    "    vocab_set = set(vocabulary)\n",
    "    vocab_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "    \n",
    "    n_samples = len(texts)\n",
    "    n_features = len(vocabulary)\n",
    "    \n",
    "    # Initialize feature matrix with zeros\n",
    "    features = np.zeros((n_samples, n_features), dtype=np.int8)\n",
    "    \n",
    "    # Fill in binary features\n",
    "    for i, text in enumerate(texts):\n",
    "        if isinstance(text, str):\n",
    "            words = set(text.split())\n",
    "            for word in words:\n",
    "                if word in vocab_to_idx:\n",
    "                    features[i, vocab_to_idx[word]] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create binary feature vectors for all datasets\n",
    "print(\"Creating binary feature vectors...\")\n",
    "X_train = create_binary_features(df_train['text'], VOCABULARY)\n",
    "X_test = create_binary_features(df_test['text'], VOCABULARY)\n",
    "X_validation = create_binary_features(df_validation['text'], VOCABULARY)\n",
    "\n",
    "print(f\"\\n‚úì Feature matrix shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  X_validation: {X_validation.shape}\")\n",
    "\n",
    "# Show sample feature statistics\n",
    "print(f\"\\nFeature statistics (training set):\")\n",
    "print(f\"  Average features per sample: {X_train.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Max features in a sample: {X_train.sum(axis=1).max()}\")\n",
    "print(f\"  Min features in a sample: {X_train.sum(axis=1).min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "label_encoding_section",
   "metadata": {},
   "source": [
    "### 4.2 Label Encoding (Multi-Label Binarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "label_encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Anzahl Klassen: 6\n",
      "‚úì Klassennamen: ['celebrity_&_pop_culture', 'diaries_&_daily_life', 'film_tv_&_video', 'music', 'news_&_social_concern', 'sports']\n",
      "\n",
      "‚úì Multi-Label Matrix Shapes:\n",
      "  y_train_multi: (5465, 6)\n",
      "  y_test_multi: (1511, 6)\n",
      "  y_validation_multi: (178, 6)\n",
      "\n",
      "‚úì Label-Verteilung (Training):\n",
      "  Durchschnitt Labels pro Sample: 1.34\n",
      "  Samples pro Klasse:\n",
      "    celebrity_&_pop_culture: 924\n",
      "    diaries_&_daily_life: 866\n",
      "    film_tv_&_video: 953\n",
      "    music: 1131\n",
      "    news_&_social_concern: 1782\n",
      "    sports: 1683\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MULTI-LABEL ENCODING (DYNAMISCH)\n",
    "# ============================================================\n",
    "\n",
    "# Verwende die vorbereiteten bin√§ren Labels direkt\n",
    "y_train_multi = np.vstack(df_train['label_binary'].values)\n",
    "y_test_multi = np.vstack(df_test['label_binary'].values)\n",
    "y_validation_multi = np.vstack(df_validation['label_binary'].values)\n",
    "\n",
    "# Bestimme die tats√§chliche Anzahl der Klassen aus den Daten\n",
    "NUM_CLASSES = y_train_multi.shape[1]\n",
    "\n",
    "# Erstelle MultiLabelBinarizer f√ºr inverse_transform\n",
    "# Wenn TOPIC_CLASSES nicht die richtige L√§nge hat, erstelle generische Namen\n",
    "if len(TOPIC_CLASSES) != NUM_CLASSES:\n",
    "    print(f\"‚ö†Ô∏è TOPIC_CLASSES hat {len(TOPIC_CLASSES)} Eintr√§ge, aber Daten haben {NUM_CLASSES} Klassen\")\n",
    "    print(\"   Erstelle generische Klassennamen...\")\n",
    "    TOPIC_CLASSES = [f\"class_{i}\" for i in range(NUM_CLASSES)]\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=TOPIC_CLASSES)\n",
    "mlb.fit([TOPIC_CLASSES])\n",
    "\n",
    "print(f\"‚úì Anzahl Klassen: {NUM_CLASSES}\")\n",
    "print(f\"‚úì Klassennamen: {TOPIC_CLASSES}\")\n",
    "print(f\"\\n‚úì Multi-Label Matrix Shapes:\")\n",
    "print(f\"  y_train_multi: {y_train_multi.shape}\")\n",
    "print(f\"  y_test_multi: {y_test_multi.shape}\")\n",
    "print(f\"  y_validation_multi: {y_validation_multi.shape}\")\n",
    "\n",
    "# Label-Verteilung\n",
    "print(f\"\\n‚úì Label-Verteilung (Training):\")\n",
    "print(f\"  Durchschnitt Labels pro Sample: {y_train_multi.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Samples pro Klasse:\")\n",
    "for i, class_name in enumerate(TOPIC_CLASSES):\n",
    "    count = y_train_multi[:, i].sum()\n",
    "    print(f\"    {class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92f1e1",
   "metadata": {},
   "source": [
    "### 4.2.1 Single-Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b8e05ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Single-label shapes:\n",
      "  y_train_single: (5465,)\n",
      "  y_test_single: (1511,)\n",
      "  y_validation_single: (178,)\n",
      "\n",
      "‚úì Label distribution (single-label training set):\n",
      "  celebrity_&_pop_culture: 924\n",
      "  diaries_&_daily_life: 807\n",
      "  film_tv_&_video: 603\n",
      "  music: 514\n",
      "  news_&_social_concern: 1284\n",
      "  sports: 1333\n",
      "\n",
      "‚úì Single-label encoding complete\n"
     ]
    }
   ],
   "source": [
    "# Create single-label encoding using the primary label (first label) from each sample\n",
    "# Extract primary labels from the binary vectors\n",
    "\n",
    "def extract_primary_label(binary_vector):\n",
    "    \"\"\"Extract the first active class from a binary vector\"\"\"\n",
    "    for i, val in enumerate(binary_vector):\n",
    "        if val == 1:  # First active class\n",
    "            return i\n",
    "    return 0  # Default to first class if no labels found\n",
    "\n",
    "# Extract primary labels for single-label classification\n",
    "primary_train_labels = [extract_primary_label(row) for row in y_train_multi]\n",
    "primary_test_labels = [extract_primary_label(row) for row in y_test_multi]\n",
    "primary_validation_labels = [extract_primary_label(row) for row in y_validation_multi]\n",
    "\n",
    "# Convert to numpy arrays  \n",
    "y_train_single = np.array(primary_train_labels)\n",
    "y_test_single = np.array(primary_test_labels)\n",
    "y_validation_single = np.array(primary_validation_labels)\n",
    "\n",
    "print(f\"‚úì Single-label shapes:\")\n",
    "print(f\"  y_train_single: {y_train_single.shape}\")\n",
    "print(f\"  y_test_single: {y_test_single.shape}\")\n",
    "print(f\"  y_validation_single: {y_validation_single.shape}\")\n",
    "\n",
    "print(f\"\\n‚úì Label distribution (single-label training set):\")\n",
    "for i, class_name in enumerate(TOPIC_CLASSES):\n",
    "    count = (y_train_single == i).sum()\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "print(f\"\\n‚úì Single-label encoding complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_training_section",
   "metadata": {},
   "source": [
    "### 4.3 Multi-Label Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "train_neural_network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MULTI-LABEL NEURAL NETWORK ARCHITECTURE\n",
      "============================================================\n",
      "Input layer:  1000 neurons (vocabulary size)\n",
      "Hidden layer 1: 128 neurons (ReLU activation)\n",
      "Hidden layer 2: 64 neurons (ReLU activation)\n",
      "Hidden layer 3: 128 neurons (ReLU activation)\n",
      "Output layer: 6 neurons (6 binary classifiers)\n",
      "============================================================\n",
      "\n",
      "Training Multi-Label Neural Network...\n",
      "Iteration 1, loss = 0.63143498\n",
      "Iteration 1, loss = 0.55208228\n",
      "Iteration 1, loss = 0.54292549\n",
      "Iteration 1, loss = 0.53747628\n",
      "Iteration 1, loss = 0.53642916\n",
      "Iteration 1, loss = 0.60748537\n",
      "Iteration 2, loss = 0.35055481\n",
      "Iteration 2, loss = 0.42907287\n",
      "Iteration 2, loss = 0.40901103\n",
      "Iteration 2, loss = 0.32566156\n",
      "Iteration 2, loss = 0.38432390\n",
      "Iteration 2, loss = 0.38086755\n",
      "Iteration 3, loss = 0.21221044\n",
      "Iteration 3, loss = 0.25179557\n",
      "Iteration 3, loss = 0.30495521\n",
      "Iteration 3, loss = 0.13805326\n",
      "Iteration 3, loss = 0.35494303\n",
      "Iteration 3, loss = 0.29974619\n",
      "Iteration 4, loss = 0.12212557\n",
      "Iteration 4, loss = 0.07519624\n",
      "Iteration 4, loss = 0.16645057\n",
      "Iteration 4, loss = 0.29963092\n",
      "Iteration 4, loss = 0.23111976\n",
      "Iteration 4, loss = 0.23095439\n",
      "Iteration 5, loss = 0.07153667\n",
      "Iteration 5, loss = 0.04401920\n",
      "Iteration 5, loss = 0.23361070\n",
      "Iteration 5, loss = 0.10835669\n",
      "Iteration 5, loss = 0.15707695\n",
      "Iteration 5, loss = 0.15612054\n",
      "Iteration 6, loss = 0.04000113\n",
      "Iteration 6, loss = 0.02293293\n",
      "Iteration 6, loss = 0.15794983\n",
      "Iteration 6, loss = 0.06124100\n",
      "Iteration 6, loss = 0.09902838\n",
      "Iteration 6, loss = 0.08963353\n",
      "Iteration 7, loss = 0.01257358\n",
      "Iteration 7, loss = 0.02254005\n",
      "Iteration 7, loss = 0.09121425\n",
      "Iteration 7, loss = 0.03283718\n",
      "Iteration 7, loss = 0.05678483\n",
      "Iteration 7, loss = 0.04301037\n",
      "Iteration 8, loss = 0.00713051\n",
      "Iteration 8, loss = 0.01421779\n",
      "Iteration 8, loss = 0.04873702\n",
      "Iteration 8, loss = 0.01999757\n",
      "Iteration 8, loss = 0.03213472\n",
      "Iteration 8, loss = 0.02134561\n",
      "Iteration 9, loss = 0.00433006\n",
      "Iteration 9, loss = 0.01003356\n",
      "Iteration 9, loss = 0.02530764\n",
      "Iteration 9, loss = 0.01283946\n",
      "Iteration 9, loss = 0.02019666\n",
      "Iteration 9, loss = 0.01205974\n",
      "Iteration 10, loss = 0.00304410\n",
      "Iteration 10, loss = 0.00767154\n",
      "Iteration 10, loss = 0.01534809\n",
      "Iteration 10, loss = 0.00981629\n",
      "Iteration 10, loss = 0.01444450\n",
      "Iteration 10, loss = 0.00674643\n",
      "Iteration 11, loss = 0.00618656\n",
      "Iteration 11, loss = 0.00273568\n",
      "Iteration 11, loss = 0.01213663\n",
      "Iteration 11, loss = 0.00697522\n",
      "Iteration 11, loss = 0.01112167\n",
      "Iteration 11, loss = 0.00527866\n",
      "Iteration 12, loss = 0.00272165\n",
      "Iteration 12, loss = 0.00553972\n",
      "Iteration 12, loss = 0.00996435\n",
      "Iteration 12, loss = 0.00623889\n",
      "Iteration 12, loss = 0.00716521\n",
      "Iteration 12, loss = 0.00437313\n",
      "Iteration 13, loss = 0.00215508\n",
      "Iteration 13, loss = 0.00504773\n",
      "Iteration 13, loss = 0.00838808\n",
      "Iteration 13, loss = 0.00505192\n",
      "Iteration 13, loss = 0.00558577\n",
      "Iteration 13, loss = 0.00361515\n",
      "Iteration 14, loss = 0.00235846\n",
      "Iteration 14, loss = 0.00461463\n",
      "Iteration 14, loss = 0.00690570\n",
      "Iteration 14, loss = 0.00549540\n",
      "Iteration 14, loss = 0.00622238\n",
      "Iteration 14, loss = 0.00412744\n",
      "Iteration 15, loss = 0.00222703\n",
      "Iteration 15, loss = 0.00401524\n",
      "Iteration 15, loss = 0.00642331\n",
      "Iteration 15, loss = 0.00478205\n",
      "Iteration 15, loss = 0.00507896\n",
      "Iteration 15, loss = 0.00402061\n",
      "Iteration 16, loss = 0.00346733\n",
      "Iteration 16, loss = 0.00374594\n",
      "Iteration 16, loss = 0.00774320\n",
      "Iteration 16, loss = 0.00451816\n",
      "Iteration 16, loss = 0.00488023\n",
      "Iteration 16, loss = 0.00304105\n",
      "Iteration 17, loss = 0.00227428\n",
      "Iteration 17, loss = 0.00407038\n",
      "Iteration 17, loss = 0.00672782\n",
      "Iteration 17, loss = 0.00461762\n",
      "Iteration 17, loss = 0.00432574\n",
      "Iteration 17, loss = 0.00327073\n",
      "Iteration 18, loss = 0.00164601\n",
      "Iteration 18, loss = 0.00334601\n",
      "Iteration 18, loss = 0.00671027\n",
      "Iteration 18, loss = 0.00722505\n",
      "Iteration 18, loss = 0.00384680\n",
      "Iteration 18, loss = 0.00500191\n",
      "Iteration 19, loss = 0.00170124\n",
      "Iteration 19, loss = 0.00321880\n",
      "Iteration 19, loss = 0.00688004\n",
      "Iteration 19, loss = 0.00804374\n",
      "Iteration 19, loss = 0.00451384\n",
      "Iteration 19, loss = 0.00283068\n",
      "Iteration 20, loss = 0.00131627\n",
      "Iteration 20, loss = 0.00294591\n",
      "Iteration 20, loss = 0.00377803\n",
      "Iteration 20, loss = 0.00675413\n",
      "Iteration 20, loss = 0.00448957\n",
      "Iteration 20, loss = 0.00247722\n",
      "Iteration 21, loss = 0.00165368\n",
      "Iteration 21, loss = 0.00284044\n",
      "Iteration 21, loss = 0.00584027\n",
      "Iteration 21, loss = 0.00374427\n",
      "Iteration 21, loss = 0.00414857\n",
      "Iteration 21, loss = 0.00371400\n",
      "Iteration 22, loss = 0.00176804\n",
      "Iteration 22, loss = 0.00276537\n",
      "Iteration 22, loss = 0.00399317\n",
      "Iteration 22, loss = 0.00595366\n",
      "Iteration 22, loss = 0.00235396\n",
      "Iteration 22, loss = 0.00518579\n",
      "Iteration 23, loss = 0.00161525\n",
      "Iteration 23, loss = 0.00333662\n",
      "Iteration 23, loss = 0.00618279\n",
      "Iteration 23, loss = 0.00415808\n",
      "Iteration 23, loss = 0.00311468\n",
      "Iteration 23, loss = 0.00391060\n",
      "Iteration 24, loss = 0.00171476\n",
      "Iteration 24, loss = 0.00271485\n",
      "Iteration 24, loss = 0.00550094\n",
      "Iteration 24, loss = 0.00338793\n",
      "Iteration 24, loss = 0.00272232\n",
      "Iteration 24, loss = 0.00403553\n",
      "Iteration 25, loss = 0.00254704\n",
      "Iteration 25, loss = 0.00141692\n",
      "Iteration 25, loss = 0.00560953\n",
      "Iteration 25, loss = 0.00345691\n",
      "Iteration 25, loss = 0.00273257\n",
      "Iteration 25, loss = 0.00385277\n",
      "Iteration 26, loss = 0.00293632\n",
      "Iteration 26, loss = 0.00171114\n",
      "Iteration 26, loss = 0.00511996\n",
      "Iteration 26, loss = 0.00343781\n",
      "Iteration 26, loss = 0.00300513\n",
      "Iteration 26, loss = 0.00463537\n",
      "Iteration 27, loss = 0.00250766\n",
      "Iteration 27, loss = 0.00253852\n",
      "Iteration 27, loss = 0.00559249\n",
      "Iteration 27, loss = 0.00347227\n",
      "Iteration 27, loss = 0.00256463\n",
      "Iteration 27, loss = 0.00436733\n",
      "Iteration 28, loss = 0.00246955\n",
      "Iteration 28, loss = 0.00180554\n",
      "Iteration 28, loss = 0.00523395\n",
      "Iteration 28, loss = 0.00426518\n",
      "Iteration 28, loss = 0.00244334\n",
      "Iteration 28, loss = 0.00414929\n",
      "Iteration 29, loss = 0.00247912\n",
      "Iteration 29, loss = 0.00187316\n",
      "Iteration 29, loss = 0.00548025\n",
      "Iteration 29, loss = 0.00373935\n",
      "Iteration 29, loss = 0.00306535\n",
      "Iteration 29, loss = 0.00314835\n",
      "Iteration 30, loss = 0.00260255\n",
      "Iteration 30, loss = 0.00139226\n",
      "Iteration 30, loss = 0.00580614\n",
      "Iteration 30, loss = 0.00328527\n",
      "Iteration 30, loss = 0.00268535\n",
      "Iteration 30, loss = 0.00389394\n",
      "Iteration 31, loss = 0.00386290\n",
      "Iteration 31, loss = 0.00301500\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 31, loss = 0.00542726\n",
      "Iteration 31, loss = 0.00350200\n",
      "Iteration 31, loss = 0.00384630\n",
      "Iteration 31, loss = 0.00332489\n",
      "Iteration 32, loss = 0.00322583\n",
      "Iteration 32, loss = 0.00534412\n",
      "Iteration 32, loss = 0.00344849\n",
      "Iteration 32, loss = 0.00290457\n",
      "Iteration 32, loss = 0.00384031\n",
      "Iteration 33, loss = 0.00345351\n",
      "Iteration 33, loss = 0.00545369\n",
      "Iteration 33, loss = 0.00335986\n",
      "Iteration 33, loss = 0.00240511\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.00318710\n",
      "Iteration 34, loss = 0.00250423\n",
      "Iteration 34, loss = 0.00743361\n",
      "Iteration 34, loss = 0.00350832\n",
      "Iteration 34, loss = 0.00342495\n",
      "Iteration 35, loss = 0.00279819\n",
      "Iteration 35, loss = 0.00651106\n",
      "Iteration 35, loss = 0.00503783\n",
      "Iteration 35, loss = 0.00429154\n",
      "Iteration 36, loss = 0.00256209\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 0.00439501\n",
      "Iteration 36, loss = 0.00540154\n",
      "Iteration 36, loss = 0.00288635\n",
      "Iteration 37, loss = 0.00540280\n",
      "Iteration 37, loss = 0.00327304\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 37, loss = 0.00313203\n",
      "Iteration 38, loss = 0.00348347\n",
      "Iteration 38, loss = 0.00352250\n",
      "Iteration 39, loss = 0.00314348\n",
      "Iteration 39, loss = 0.00316409\n",
      "Iteration 40, loss = 0.00357167\n",
      "Iteration 40, loss = 0.00321525\n",
      "Iteration 41, loss = 0.00359264\n",
      "Iteration 41, loss = 0.00353764\n",
      "Iteration 42, loss = 0.00345707\n",
      "Iteration 42, loss = 0.00358867\n",
      "Iteration 43, loss = 0.00351306\n",
      "Iteration 43, loss = 0.00366560\n",
      "Iteration 44, loss = 0.00344155\n",
      "Iteration 44, loss = 0.00301244\n",
      "Iteration 45, loss = 0.00324470\n",
      "Iteration 45, loss = 0.00342613\n",
      "Iteration 46, loss = 0.00301216\n",
      "Iteration 46, loss = 0.00305668\n",
      "Iteration 47, loss = 0.00325541\n",
      "Iteration 47, loss = 0.00315788\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 48, loss = 0.00326947\n",
      "Iteration 49, loss = 0.00338554\n",
      "Iteration 50, loss = 0.00305819\n",
      "Iteration 51, loss = 0.00354807\n",
      "Iteration 52, loss = 0.00294543\n",
      "Iteration 53, loss = 0.00281890\n",
      "Iteration 54, loss = 0.00283660\n",
      "Iteration 55, loss = 0.00295871\n",
      "Iteration 56, loss = 0.00317178\n",
      "Iteration 57, loss = 0.00302263\n",
      "Iteration 58, loss = 0.00305698\n",
      "Iteration 59, loss = 0.00286024\n",
      "Iteration 60, loss = 0.00306107\n",
      "Iteration 61, loss = 0.00276303\n",
      "Iteration 62, loss = 0.00306738\n",
      "Iteration 63, loss = 0.00283186\n",
      "Iteration 64, loss = 0.00277652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "‚úì Multi-Label Neural Network training complete!\n"
     ]
    }
   ],
   "source": [
    "# Create MLPClassifier with specified architecture\n",
    "# Using OneVsRestClassifier for multi-label classification\n",
    "# Note: early_stopping is disabled because some classes have very few samples\n",
    "# which causes issues with the validation split in OneVsRest multi-label setting\n",
    "mlp_base = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Three hidden layers as specified\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer (mini-batch gradient descent)\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=False,                # Disabled for multi-label compatibility\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "# Wrap with OneVsRestClassifier for multi-label support\n",
    "mlp_clf_multi = OneVsRestClassifier(mlp_base, n_jobs=-1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-LABEL NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(TOPIC_CLASSES)} neurons ({len(TOPIC_CLASSES)} binary classifiers)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining Multi-Label Neural Network...\")\n",
    "mlp_clf_multi.fit(X_train, y_train_multi)\n",
    "print(\"\\n‚úì Multi-Label Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 4.4 Multi-Label Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "evaluate_neural_network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MULTI-LABEL NEURAL NETWORK EVALUATION (Test Set)\n",
      "============================================================\n",
      "Subset Accuracy     : 0.4527\n",
      "Hamming Loss        : 0.1442\n",
      "Micro F1            : 0.6447\n",
      "Macro F1            : 0.5636\n",
      "Micro Precision     : 0.6985\n",
      "Micro Recall        : 0.5987\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_nn_multi = mlp_clf_multi.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_multi_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_nn_multi),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_nn_multi),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_nn_multi, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-LABEL NEURAL NETWORK EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_multi_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "nn_sample_predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Multi-Label Neural Network Predictions:\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úó Sample 1:\n",
      "   Text: philadelphia clearly page game playbook fire net oppose goal...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n",
      "\n",
      "‚úó Sample 2:\n",
      "   Text: sure bay face flyer man experience versus blue jacket year h...\n",
      "   True: ('sports',)\n",
      "   Pred: ('none',)\n",
      "\n",
      "‚úó Sample 3:\n",
      "   Text: tizamagician put cherry kentucky derby day winner pie take d...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n",
      "\n",
      "‚úó Sample 4:\n",
      "   Text: flyer give false hope absolutely destroy islander go to dest...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n",
      "\n",
      "‚úó Sample 5:\n",
      "   Text: flyer tremendous season face excited season go to well thank...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions\n",
    "y_pred_labels = mlb.inverse_transform(y_pred_nn_multi)\n",
    "y_true_labels = mlb.inverse_transform(y_test_multi)\n",
    "\n",
    "print(\"\\nSample Multi-Label Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test['text'].iloc[i][:60]\n",
    "    true = y_true_labels[i] if y_true_labels[i] else ('none',)\n",
    "    pred = y_pred_labels[i] if y_pred_labels[i] else ('none',)\n",
    "    match = \"‚úì\" if set(true) == set(pred) else \"‚úó\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   True: {true}\")\n",
    "    print(f\"   Pred: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb_training_section",
   "metadata": {},
   "source": [
    "### 4.5 Naive Bayes Classifier (for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "train_naive_bayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NAIVE BAYES EVALUATION (Test Set)\n",
      "============================================================\n",
      "Subset Accuracy     : 0.4917\n",
      "Hamming Loss        : 0.1337\n",
      "Micro F1            : 0.6811\n",
      "Macro F1            : 0.6210\n",
      "Micro Precision     : 0.7114\n",
      "Micro Recall        : 0.6532\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes classifier with same features\n",
    "nb_clf = OneVsRestClassifier(MultinomialNB(alpha=1.0))\n",
    "nb_clf.fit(X_train, y_train_multi)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nb_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_nb),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_nb),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_nb, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_nb, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAIVE BAYES EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Task 4: Single-Label Classification\n",
    "\n",
    "For comparison, we train a neural network using single-label classification. Each tweet is assigned only its primary (first) label, converting the multi-label problem to a standard multi-class classification problem.\n",
    "\n",
    "### 5.1 Single-Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "single_label_encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Single-label encoding complete\n",
      "\n",
      "‚úì Label shapes:\n",
      "  y_train_single: (5465,)\n",
      "  y_test_single: (1511,)\n",
      "  y_validation_single: (178,)\n",
      "\n",
      "‚úì Class mapping (dynamisch erkannt):\n",
      "  0: celebrity_&_pop_culture (202 samples)\n",
      "  1: diaries_&_daily_life (561 samples)\n",
      "  2: film_tv_&_video (618 samples)\n",
      "  3: music (1046 samples)\n",
      "  4: news_&_social_concern (1421 samples)\n",
      "  5: sports (1617 samples)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL ENCODING (DYNAMISCH)\n",
    "# ============================================================\n",
    "\n",
    "# Verwende die dynamisch erkannten TOPIC_CLASSES\n",
    "# Stelle sicher, dass alle Labels in TOPIC_CLASSES vorkommen\n",
    "unique_single_labels = set(df_train['single_label'].unique()) | \\\n",
    "                       set(df_test['single_label'].unique()) | \\\n",
    "                       set(df_validation['single_label'].unique())\n",
    "\n",
    "# Pr√ºfe ob alle Labels bekannt sind\n",
    "unknown_labels = unique_single_labels - set(TOPIC_CLASSES)\n",
    "if unknown_labels:\n",
    "    print(f\"‚ö†Ô∏è Unbekannte Labels gefunden: {unknown_labels}\")\n",
    "    print(f\"   F√ºge sie zu TOPIC_CLASSES hinzu...\")\n",
    "    TOPIC_CLASSES = sorted(list(set(TOPIC_CLASSES) | unknown_labels))\n",
    "\n",
    "# Create label encoder for single-label classification\n",
    "le = LabelEncoder()\n",
    "le.fit(TOPIC_CLASSES)\n",
    "\n",
    "# Encode single labels as integers\n",
    "y_train_single = le.transform(df_train['single_label'])\n",
    "y_test_single = le.transform(df_test['single_label'])\n",
    "y_validation_single = le.transform(df_validation['single_label'])\n",
    "\n",
    "print(f\"‚úì Single-label encoding complete\")\n",
    "print(f\"\\n‚úì Label shapes:\")\n",
    "print(f\"  y_train_single: {y_train_single.shape}\")\n",
    "print(f\"  y_test_single: {y_test_single.shape}\")\n",
    "print(f\"  y_validation_single: {y_validation_single.shape}\")\n",
    "\n",
    "print(f\"\\n‚úì Class mapping (dynamisch erkannt):\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    count = (y_train_single == i).sum()\n",
    "    print(f\"  {i}: {cls} ({count} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_nn_training_section",
   "metadata": {},
   "source": [
    "### 5.2 Single-Label Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "train_single_label_nn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SINGLE-LABEL NEURAL NETWORK ARCHITECTURE\n",
      "============================================================\n",
      "Input layer:  1000 neurons (vocabulary size)\n",
      "Hidden layer 1: 128 neurons (ReLU activation)\n",
      "Hidden layer 2: 64 neurons (ReLU activation)\n",
      "Hidden layer 3: 128 neurons (ReLU activation)\n",
      "Output layer: 6 neurons (Softmax activation)\n",
      "============================================================\n",
      "\n",
      "Training Single-Label Neural Network...\n",
      "Iteration 1, loss = 1.64859046\n",
      "Validation score: 0.477148\n",
      "Iteration 2, loss = 1.20520977\n",
      "Validation score: 0.636197\n",
      "Iteration 3, loss = 0.74446490\n",
      "Validation score: 0.733090\n",
      "Iteration 4, loss = 0.49954898\n",
      "Validation score: 0.738574\n",
      "Iteration 5, loss = 0.36394867\n",
      "Validation score: 0.747715\n",
      "Iteration 6, loss = 0.27613723\n",
      "Validation score: 0.745887\n",
      "Iteration 7, loss = 0.20510681\n",
      "Validation score: 0.747715\n",
      "Iteration 8, loss = 0.15276296\n",
      "Validation score: 0.734918\n",
      "Iteration 9, loss = 0.11145349\n",
      "Validation score: 0.727605\n",
      "Iteration 10, loss = 0.08296176\n",
      "Validation score: 0.723949\n",
      "Iteration 11, loss = 0.06146216\n",
      "Validation score: 0.731261\n",
      "Iteration 12, loss = 0.04664484\n",
      "Validation score: 0.727605\n",
      "Iteration 13, loss = 0.03438219\n",
      "Validation score: 0.722121\n",
      "Iteration 14, loss = 0.02759671\n",
      "Validation score: 0.722121\n",
      "Iteration 15, loss = 0.02205957\n",
      "Validation score: 0.725777\n",
      "Iteration 16, loss = 0.01811604\n",
      "Validation score: 0.720293\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "‚úì Single-Label Neural Network training complete!\n"
     ]
    }
   ],
   "source": [
    "# Create MLPClassifier for single-label classification\n",
    "# For single-label, MLPClassifier uses softmax output automatically\n",
    "mlp_clf_single = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Same architecture as multi-label\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=True,                 # Enable early stopping for single-label\n",
    "    validation_fraction=0.1,             # Use 10% for validation\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(TOPIC_CLASSES)} neurons (Softmax activation)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining Single-Label Neural Network...\")\n",
    "mlp_clf_single.fit(X_train, y_train_single)\n",
    "print(\"\\n‚úì Single-Label Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 5.3 Single-Label Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "evaluate_single_label_nn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SINGLE-LABEL NEURAL NETWORK EVALUATION (Test Set)\n",
      "============================================================\n",
      "Accuracy            : 0.7207\n",
      "Macro F1            : 0.5483\n",
      "Weighted F1         : 0.7027\n",
      "Macro Precision     : 0.5440\n",
      "Macro Recall        : 0.5561\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_nn_single = mlp_clf_single.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_single_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_single, y_pred_nn_single),\n",
    "    'Macro F1': f1_score(y_test_single, y_pred_nn_single, average='macro', zero_division=0),\n",
    "    'Weighted F1': f1_score(y_test_single, y_pred_nn_single, average='weighted', zero_division=0),\n",
    "    'Macro Precision': precision_score(y_test_single, y_pred_nn_single, average='macro', zero_division=0),\n",
    "    'Macro Recall': recall_score(y_test_single, y_pred_nn_single, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL NEURAL NETWORK EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_single_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4412a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PARTIAL MATCH EVALUATION:  Single-Label NN vs Original Multi-Labels\n",
      "======================================================================\n",
      "\n",
      "A 'hit' occurs when the predicted single label matches ANY of the\n",
      "original multi-labels (not just the first/primary label).\n",
      "----------------------------------------------------------------------\n",
      "Total test samples:          1,511\n",
      "Hits (partial matches):    1,144\n",
      "Misses:                     367\n",
      "\n",
      "Partial Match Accuracy:    0.7571 (75.71%)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Comparison:\n",
      "  Exact Single-Label Accuracy:     0.7207\n",
      "  Partial Match Accuracy:         0.7571\n",
      "  Improvement:                    +0.0364\n",
      "======================================================================\n",
      "\n",
      "Examples of Partial Matches (pred matches non-primary label):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚úì Sample 54:\n",
      "   Text: flaw simple agenda leadership example talk example...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Primary label: news_&_social_concern\n",
      "   Predicted:  sports (matches secondary label! )\n",
      "\n",
      "‚úì Sample 85:\n",
      "   Text: luvs help social reply fanchant separately...\n",
      "   Original labels: ['celebrity_&_pop_culture' 'film_tv_&_video' 'news_&_social_concern']\n",
      "   Primary label: film_tv_&_video\n",
      "   Predicted:  news_&_social_concern (matches secondary label! )\n",
      "\n",
      "‚úì Sample 86:\n",
      "   Text: hii new stan twitter help find mutual curse kardas...\n",
      "   Original labels: ['celebrity_&_pop_culture' 'film_tv_&_video' 'music'\n",
      " 'news_&_social_concern']\n",
      "   Primary label: celebrity_&_pop_culture\n",
      "   Predicted:  news_&_social_concern (matches secondary label! )\n",
      "\n",
      "‚úì Sample 90:\n",
      "   Text: freestyle favorite tune moment help like repost ta...\n",
      "   Original labels: ['film_tv_&_video' 'music']\n",
      "   Primary label: music\n",
      "   Predicted:  film_tv_&_video (matches secondary label! )\n",
      "\n",
      "‚úì Sample 106:\n",
      "   Text: look like twitter wake sorry mr drunk ramble don s...\n",
      "   Original labels: ['diaries_&_daily_life' 'news_&_social_concern']\n",
      "   Primary label: diaries_&_daily_life\n",
      "   Predicted:  news_&_social_concern (matches secondary label! )\n",
      "\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "-\n",
      "Total samples where prediction matched a secondary label: 55\n"
     ]
    }
   ],
   "source": [
    "# Check if predicted single label matches ANY of the original multi-labels\n",
    "\n",
    "def calculate_partial_match_accuracy(y_pred_single:  np.ndarray, \n",
    "                                      original_labels_list: pd.Series,\n",
    "                                      label_encoder: LabelEncoder) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate partial match accuracy for single-label predictions.\n",
    "    \n",
    "    A prediction is considered a 'hit' if the predicted label matches\n",
    "    at least one of the original multi-labels.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_pred_single : np.ndarray\n",
    "        Single-label predictions (encoded as integers)\n",
    "    original_labels_list : pd.Series\n",
    "        Series of lists containing the original multi-labels (as strings)\n",
    "    label_encoder :  LabelEncoder\n",
    "        Fitted label encoder to convert predictions back to strings\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing partial match metrics\n",
    "    \"\"\"\n",
    "    # Convert predictions to label names\n",
    "    pred_labels = label_encoder.inverse_transform(y_pred_single)\n",
    "    \n",
    "    # Count matches\n",
    "    total = len(pred_labels)\n",
    "    hits = 0\n",
    "    \n",
    "    for pred, original_labels in zip(pred_labels, original_labels_list):\n",
    "        # Check if prediction matches ANY of the original labels\n",
    "        if pred in original_labels:\n",
    "            hits += 1\n",
    "    \n",
    "    partial_match_accuracy = hits / total if total > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': total,\n",
    "        'hits':  hits,\n",
    "        'misses': total - hits,\n",
    "        'partial_match_accuracy': partial_match_accuracy\n",
    "    }\n",
    "\n",
    "# Calculate partial match accuracy for Single-Label NN\n",
    "partial_match_results = calculate_partial_match_accuracy(\n",
    "    y_pred_nn_single, \n",
    "    df_test['labels'],  # Original multi-labels\n",
    "    le\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PARTIAL MATCH EVALUATION:  Single-Label NN vs Original Multi-Labels\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nA 'hit' occurs when the predicted single label matches ANY of the\")\n",
    "print(f\"original multi-labels (not just the first/primary label).\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Total test samples:         {partial_match_results['total_samples']: ,}\")\n",
    "print(f\"Hits (partial matches):    {partial_match_results['hits']:,}\")\n",
    "print(f\"Misses:                     {partial_match_results['misses']:,}\")\n",
    "print(f\"\\nPartial Match Accuracy:    {partial_match_results['partial_match_accuracy']:.4f} ({partial_match_results['partial_match_accuracy']*100:.2f}%)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Compare with exact single-label accuracy\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Exact Single-Label Accuracy:     {nn_single_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Partial Match Accuracy:         {partial_match_results['partial_match_accuracy']:.4f}\")\n",
    "print(f\"  Improvement:                    +{(partial_match_results['partial_match_accuracy'] - nn_single_metrics['Accuracy']):.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show examples of partial matches (predictions that match a secondary label)\n",
    "print(\"\\nExamples of Partial Matches (pred matches non-primary label):\")\n",
    "print(\"-\" * 70)\n",
    "example_count = 0\n",
    "for i in range(len(y_pred_nn_single)):\n",
    "    pred_label = le.inverse_transform([y_pred_nn_single[i]])[0]\n",
    "    true_primary = df_test['single_label'].iloc[i]\n",
    "    original_labels = df_test['labels'].iloc[i]\n",
    "    \n",
    "    # Show cases where prediction doesn't match primary but matches another label\n",
    "    if pred_label != true_primary and pred_label in original_labels:\n",
    "        example_count += 1\n",
    "        if example_count <= 5: \n",
    "            text = df_test['text'].iloc[i][: 50]\n",
    "            print(f\"\\n‚úì Sample {i+1}:\")\n",
    "            print(f\"   Text: {text}...\")\n",
    "            print(f\"   Original labels: {original_labels}\")\n",
    "            print(f\"   Primary label: {true_primary}\")\n",
    "            print(f\"   Predicted:  {pred_label} (matches secondary label! )\")\n",
    "\n",
    "print(f\"\\n-\" * 70)\n",
    "print(f\"Total samples where prediction matched a secondary label: {example_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "single_label_sample_predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Single-Label Neural Network Predictions:\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úì Sample 1:\n",
      "   Text: philadelphia clearly page game playbook fire net oppose goal...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 2:\n",
      "   Text: sure bay face flyer man experience versus blue jacket year h...\n",
      "   Original labels: ['sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 3:\n",
      "   Text: tizamagician put cherry kentucky derby day winner pie take d...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 4:\n",
      "   Text: flyer give false hope absolutely destroy islander go to dest...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 5:\n",
      "   Text: flyer tremendous season face excited season go to well thank...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions for single-label\n",
    "print(\"\\nSample Single-Label Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test['text'].iloc[i][:60]\n",
    "    true_label = le.inverse_transform([y_test_single[i]])[0]\n",
    "    pred_label = le.inverse_transform([y_pred_nn_single[i]])[0]\n",
    "    original_labels = df_test['labels'].iloc[i]\n",
    "    match = \"‚úì\" if true_label == pred_label else \"‚úó\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   Original labels: {original_labels}\")\n",
    "    print(f\"   Single label (true): {true_label}\")\n",
    "    print(f\"   Single label (pred): {pred_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Comparison\n",
    "\n",
    "### 6.1 Multi-Label Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-LABEL MODEL COMPARISON: Neural Network vs Naive Bayes\n",
      "================================================================================\n",
      "         Metric  Neural Network (Multi-Label)  Naive Bayes (Multi-Label)  Difference Better Model\n",
      "Subset Accuracy                      0.452680                   0.491727   -0.039047  Naive Bayes\n",
      "   Hamming Loss                      0.144165                   0.133686    0.010479  Naive Bayes\n",
      "       Micro F1                      0.644740                   0.681053   -0.036312  Naive Bayes\n",
      "       Macro F1                      0.563573                   0.620975   -0.057402  Naive Bayes\n",
      "Micro Precision                      0.698469                   0.711380   -0.012911  Naive Bayes\n",
      "   Micro Recall                      0.598688                   0.653205   -0.054518  Naive Bayes\n",
      "================================================================================\n",
      "\n",
      "Note: For Hamming Loss, lower is better. For all other metrics, higher is better.\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table for multi-label models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(nn_multi_metrics.keys()),\n",
    "    'Neural Network (Multi-Label)': list(nn_multi_metrics.values()),\n",
    "    'Naive Bayes (Multi-Label)': list(nb_metrics.values())\n",
    "})\n",
    "\n",
    "# Calculate improvement\n",
    "comparison_df['Difference'] = comparison_df['Neural Network (Multi-Label)'] - comparison_df['Naive Bayes (Multi-Label)']\n",
    "comparison_df['Better Model'] = comparison_df.apply(\n",
    "    lambda row: 'Neural Network' if (row['Difference'] > 0 and row['Metric'] != 'Hamming Loss') \n",
    "                or (row['Difference'] < 0 and row['Metric'] == 'Hamming Loss')\n",
    "                else 'Naive Bayes' if row['Difference'] != 0 else 'Tie',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-LABEL MODEL COMPARISON: Neural Network vs Naive Bayes\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: For Hamming Loss, lower is better. For all other metrics, higher is better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_vs_multi_section",
   "metadata": {},
   "source": [
    "### 6.2 Single-Label vs Multi-Label Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "single_vs_multi_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SINGLE-LABEL VS MULTI-LABEL NEURAL NETWORK COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Metric               Multi-Label NN     Single-Label NN    Difference  \n",
      "----------------------------------------------------------------------\n",
      "Subset Accuracy      0.4527             0.5473             -0.0946\n",
      "Hamming Loss         0.1442             0.1328             +0.0114\n",
      "Micro F1             0.6447             0.6552             -0.0105\n",
      "Macro F1             0.5636             0.5243             +0.0393\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Note: Single-label NN can only predict one class per sample.\n",
      "Comparison is made against the original multi-label ground truth.\n"
     ]
    }
   ],
   "source": [
    "# Compare single-label NN predictions against multi-label ground truth\n",
    "# Convert single-label predictions to multi-label format for comparison\n",
    "y_pred_single_as_multi = np.zeros((len(y_pred_nn_single), len(TOPIC_CLASSES)), dtype=int)\n",
    "for i, pred in enumerate(y_pred_nn_single):\n",
    "    y_pred_single_as_multi[i, pred] = 1\n",
    "\n",
    "# Calculate metrics for single-label NN on multi-label test set\n",
    "single_on_multi_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_single_as_multi),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_single_as_multi),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_single_as_multi, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_single_as_multi, average='macro', zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SINGLE-LABEL VS MULTI-LABEL NEURAL NETWORK COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Metric':<20} {'Multi-Label NN':<18} {'Single-Label NN':<18} {'Difference':<12}\")\n",
    "print(\"-\"*70)\n",
    "for metric in ['Subset Accuracy', 'Hamming Loss', 'Micro F1', 'Macro F1']:\n",
    "    multi = nn_multi_metrics[metric]\n",
    "    single = single_on_multi_metrics[metric]\n",
    "    diff = multi - single\n",
    "    print(f\"{metric:<20} {multi:<18.4f} {single:<18.4f} {diff:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nNote: Single-label NN can only predict one class per sample.\")\n",
    "print(\"Comparison is made against the original multi-label ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "all_models_summary_section",
   "metadata": {},
   "source": [
    "### 6.3 All Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "all_models_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON SUMMARY\n",
      "==========================================================================================\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "MULTI-LABEL CLASSIFICATION RESULTS (evaluated on multi-label test set)\n",
      "------------------------------------------------------------------------------------------\n",
      "Model                               Accuracy     Micro F1     Macro F1     Hamming Loss\n",
      "------------------------------------------------------------------------------------------\n",
      "Multi-Label Neural Network          0.4527       0.6447       0.5636       0.1442      \n",
      "Naive Bayes (Multi-Label)           0.4917       0.6811       0.6210       0.1337      \n",
      "Single-Label NN (on multi-label)    0.5473       0.6552       0.5243       0.1328      \n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "SINGLE-LABEL CLASSIFICATION RESULTS (evaluated on single-label test set)\n",
      "------------------------------------------------------------------------------------------\n",
      "Model                               Accuracy     Weighted F1  Macro F1    \n",
      "------------------------------------------------------------------------------------------\n",
      "Single-Label Neural Network         0.7207       0.7027       0.5483      \n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary table\n",
    "print(\"=\"*90)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"MULTI-LABEL CLASSIFICATION RESULTS (evaluated on multi-label test set)\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Model':<35} {'Accuracy':<12} {'Micro F1':<12} {'Macro F1':<12} {'Hamming Loss':<12}\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Multi-Label Neural Network':<35} {nn_multi_metrics['Subset Accuracy']:<12.4f} {nn_multi_metrics['Micro F1']:<12.4f} {nn_multi_metrics['Macro F1']:<12.4f} {nn_multi_metrics['Hamming Loss']:<12.4f}\")\n",
    "print(f\"{'Naive Bayes (Multi-Label)':<35} {nb_metrics['Subset Accuracy']:<12.4f} {nb_metrics['Micro F1']:<12.4f} {nb_metrics['Macro F1']:<12.4f} {nb_metrics['Hamming Loss']:<12.4f}\")\n",
    "print(f\"{'Single-Label NN (on multi-label)':<35} {single_on_multi_metrics['Subset Accuracy']:<12.4f} {single_on_multi_metrics['Micro F1']:<12.4f} {single_on_multi_metrics['Macro F1']:<12.4f} {single_on_multi_metrics['Hamming Loss']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*90)\n",
    "print(\"SINGLE-LABEL CLASSIFICATION RESULTS (evaluated on single-label test set)\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Model':<35} {'Accuracy':<12} {'Weighted F1':<12} {'Macro F1':<12}\")\n",
    "print(\"-\"*90)\n",
    "print(f\"{'Single-Label Neural Network':<35} {nn_single_metrics['Accuracy']:<12.4f} {nn_single_metrics['Weighted F1']:<12.4f} {nn_single_metrics['Macro F1']:<12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Optional: Experiment with Different Network Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "experiment_architectures",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with different network architectures (Multi-Label)...\n",
      "============================================================\n",
      "\n",
      "Training: Small (64-32-64)...\n",
      "  Accuracy: 0.4520, Micro F1: 0.6409\n",
      "\n",
      "Training: Medium (128-64-128)...\n",
      "  Accuracy: 0.4527, Micro F1: 0.6447\n",
      "\n",
      "Training: Large (256-128-256)...\n",
      "  Accuracy: 0.4573, Micro F1: 0.6455\n",
      "\n",
      "Training: Deep (128-128-64-64-128-128)...\n",
      "  Accuracy: 0.4725, Micro F1: 0.6535\n",
      "\n",
      "Training: Wide (512-256-512)...\n",
      "  Accuracy: 0.4626, Micro F1: 0.6485\n",
      "\n",
      "================================================================================\n",
      "ARCHITECTURE COMPARISON RESULTS\n",
      "================================================================================\n",
      "                Architecture                       Layers  Accuracy  Micro F1  Macro F1\n",
      "            Small (64-32-64)                 (64, 32, 64)  0.452019  0.640916  0.569563\n",
      "         Medium (128-64-128)               (128, 64, 128)  0.452680  0.644740  0.563573\n",
      "         Large (256-128-256)              (256, 128, 256)  0.457313  0.645541  0.567340\n",
      "Deep (128-128-64-64-128-128) (128, 128, 64, 64, 128, 128)  0.472535  0.653532  0.573370\n",
      "          Wide (512-256-512)              (512, 256, 512)  0.462608  0.648470  0.567219\n"
     ]
    }
   ],
   "source": [
    "# Define different architectures to test\n",
    "architectures = {\n",
    "    'Small (64-32-64)': (64, 32, 64),\n",
    "    'Medium (128-64-128)': (128, 64, 128),  # Original\n",
    "    'Large (256-128-256)': (256, 128, 256),\n",
    "    'Deep (128-128-64-64-128-128)': (128, 128, 64, 64, 128, 128),\n",
    "    'Wide (512-256-512)': (512, 256, 512)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Experimenting with different network architectures (Multi-Label)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, layers in architectures.items():\n",
    "    print(f\"\\nTraining: {name}...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=layers,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=200,\n",
    "        random_state=RANDOM_STATE,\n",
    "        early_stopping=False,  # Disabled for multi-label compatibility\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    clf = OneVsRestClassifier(mlp, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train_multi)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        'Architecture': name,\n",
    "        'Layers': str(layers),\n",
    "        'Accuracy': accuracy_score(y_test_multi, y_pred),\n",
    "        'Micro F1': f1_score(y_test_multi, y_pred, average='micro', zero_division=0),\n",
    "        'Macro F1': f1_score(y_test_multi, y_pred, average='macro', zero_division=0)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {results[-1]['Accuracy']:.4f}, Micro F1: {results[-1]['Micro F1']:.4f}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHITECTURE COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary\n",
    "\n",
    "### What was accomplished\n",
    "1. Loaded preprocessed data from Lab 2 and vocabulary from Lab 4\n",
    "2. Created binary feature vectors (Bag-of-Words encoding) for all samples\n",
    "3. Trained a Multi-Label Neural Network with 128‚Üí64‚Üí128 hidden layers using MLPClassifier and OneVsRestClassifier\n",
    "4. Converted multi-label data to single-label by keeping only the primary label\n",
    "5. Trained a Single-Label Neural Network with the same architecture\n",
    "6. Compared Multi-Label NN, Single-Label NN, and Naive Bayes classifiers\n",
    "7. Experimented with different network architectures\n",
    "\n",
    "### Key Findings\n",
    "- Multi-label classification allows predicting multiple topics per tweet\n",
    "- Single-label classification simplifies the problem but loses information about secondary topics\n",
    "- Neural networks can capture non-linear relationships in text classification\n",
    "- The MLPClassifier with ReLU activation and Adam optimizer provides good results\n",
    "- For multi-label tasks, OneVsRestClassifier trains separate binary classifiers per class\n",
    "- For single-label tasks, MLPClassifier uses softmax output for probability distribution\n",
    "- Network architecture affects performance, but larger isn't always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LAB 5 SUMMARY\n",
      "============================================================\n",
      "Input vocabulary: ../Data/top_1000_vocabulary.json\n",
      "Training samples: 5,465\n",
      "Test samples: 1,511\n",
      "Feature vector size: 1000\n",
      "Number of classes: 6\n",
      "\n",
      "Multi-Label Neural Network Metrics:\n",
      "  Subset Accuracy: 0.4527\n",
      "  Micro F1: 0.6447\n",
      "  Macro F1: 0.5636\n",
      "\n",
      "Single-Label Neural Network Metrics:\n",
      "  Accuracy: 0.7207\n",
      "  Weighted F1: 0.7027\n",
      "  Macro F1: 0.5483\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x107df18a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1070ad8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103f458a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10a96d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104fd98a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10700d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10b5f18a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10706d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1087a98a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1061418a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110cb58a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10506d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LAB 5 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input vocabulary: {VOCABULARY_PATH}\")\n",
    "print(f\"Training samples: {len(df_train):,}\")\n",
    "print(f\"Test samples: {len(df_test):,}\")\n",
    "print(f\"Feature vector size: {X_train.shape[1]}\")\n",
    "print(f\"Number of classes: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"\\nMulti-Label Neural Network Metrics:\")\n",
    "print(f\"  Subset Accuracy: {nn_multi_metrics['Subset Accuracy']:.4f}\")\n",
    "print(f\"  Micro F1: {nn_multi_metrics['Micro F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_multi_metrics['Macro F1']:.4f}\")\n",
    "print(f\"\\nSingle-Label Neural Network Metrics:\")\n",
    "print(f\"  Accuracy: {nn_single_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Weighted F1: {nn_single_metrics['Weighted F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_single_metrics['Macro F1']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
