{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7385872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arbeitsverzeichnis: /Users/hikmetacig/grundlagen-des-nlp-ws25_26/Abgabe/Notebooks\n",
      "Datei existiert? True\n",
      "✅ Datensatz geladen!\n",
      "Größe: (6090, 3)\n",
      "Spalten: ['text', 'label_name', 'label']\n",
      "                                                text  label_name  \\\n",
      "0  lumber beat rapid game western division final ...  ['sports']   \n",
      "1         hear eli gold announce auburn game dumbass  ['sports']   \n",
      "2       phone away try look home game ticket october  ['sports']   \n",
      "3  year ago louisville struggle beat fcs opponent...  ['sports']   \n",
      "4  know dodger oriole game thursday fox arguably ...  ['sports']   \n",
      "\n",
      "                                               label  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "✅ TOP_VOCABULARY geladen (1000 Wörter)\n",
      "✅ Binary Feature-Matrix erstellt!\n",
      "Matrix-Form: (6090, 1000)\n",
      "Vorschau der Binary Feature-Matrix:\n",
      "   new  day  love  good  game  year  time  watch  happy  music  ...  \\\n",
      "0    0    0     0     0     1     0     0      0      0      0  ...   \n",
      "1    0    0     0     0     1     0     0      0      0      0  ...   \n",
      "2    0    0     0     0     1     0     0      0      0      0  ...   \n",
      "3    0    0     0     0     1     1     0      0      0      0  ...   \n",
      "4    0    0     0     0     1     0     0      0      0      0  ...   \n",
      "\n",
      "   favourite  process  supporter  training  actor  sale  wrap  usman  donald  \\\n",
      "0          0        0          0         0      0     0     0      0       0   \n",
      "1          0        0          0         0      0     0     0      0       0   \n",
      "2          0        0          0         0      0     0     0      0       0   \n",
      "3          0        0          0         0      0     0     0      0       0   \n",
      "4          0        0          0         0      0     0     0      0       0   \n",
      "\n",
      "   mexico  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "[5 rows x 1000 columns]\n",
      "✅ Binary Feature-Matrix gespeichert unter: ../Data/binary_vectors.parquet\n"
     ]
    }
   ],
   "source": [
    "# === 1️⃣ Bibliotheken importieren ===\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# === 2️⃣ Datensatz laden ===\n",
    "DATA_PATH = \"../Data/tweets_preprocessed_train.parquet\" \n",
    "\n",
    "import os\n",
    "\n",
    "print(\"Arbeitsverzeichnis:\", os.getcwd())\n",
    "print(\"Datei existiert?\", os.path.exists(DATA_PATH))\n",
    "\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "print(\"✅ Datensatz geladen!\")\n",
    "print(\"Größe:\", df.shape)\n",
    "print(\"Spalten:\", df.columns.tolist())\n",
    "print(df.head())\n",
    "\n",
    "# === 3️⃣ Vokabular laden ===\n",
    "# Falls du dein TOP_VOCABULARY bereits gespeichert hast:\n",
    "TOP_VOCAB_PATH = \"../Data/top_1000_words.csv\"\n",
    "TOP_VOCABULARY = pd.read_csv(TOP_VOCAB_PATH)[\"word\"].tolist()\n",
    "print(f\"✅ TOP_VOCABULARY geladen ({len(TOP_VOCABULARY)} Wörter)\")\n",
    "\n",
    "# === 4️⃣ Binary Bag-of-Words mit CountVectorizer ===\n",
    "vectorizer = CountVectorizer(\n",
    "    vocabulary=TOP_VOCABULARY,   # 1000 meistverwendete Wörter\n",
    "    lowercase=True,\n",
    "    binary=True,                 # 0/1 statt Häufigkeiten\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\"\n",
    ")\n",
    "\n",
    "# Alle Texte in 0/1-Vektoren umwandeln\n",
    "X_bin = vectorizer.transform(df[\"text\"])\n",
    "print(\"✅ Binary Feature-Matrix erstellt!\")\n",
    "print(\"Matrix-Form:\", X_bin.shape)  # z. B. (6090, 1000)\n",
    "\n",
    "# === 5️⃣ Binary Feature-Matrix als DataFrame anzeigen ===\n",
    "binary_df = pd.DataFrame(\n",
    "    X_bin.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(\"Vorschau der Binary Feature-Matrix:\")\n",
    "print(binary_df.head())\n",
    "\n",
    "# === 6️⃣ Optional: Matrix speichern ===\n",
    "SAVE_PATH = \"../Data/binary_vectors.parquet\"\n",
    "binary_df.to_parquet(SAVE_PATH)\n",
    "print(f\"✅ Binary Feature-Matrix gespeichert unter: {SAVE_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
