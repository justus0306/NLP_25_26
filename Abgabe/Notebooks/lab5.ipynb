{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e50a659",
   "metadata": {},
   "source": [
    "# Lab 5: Neural Network Classification with scikit-learn\n",
    "\n",
    "---\n",
    "## 1. Notebook Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "- Re-use the most frequent words (optional: per class) you found for\n",
    "your Naive Bayes classifier last week.\n",
    "\n",
    "- Construct binary vectors for your whole dataset. Each dimension states\n",
    "whether the word is part of the sample or not.\n",
    "\n",
    "- Create a small neural network using scikit-learn: https://scikit-learn.org/\n",
    "stable/modules/neural_networks_supervised.html. Start with three\n",
    "hidden layers of 128/64/128 neurons. Consider what your input and\n",
    "output layers should look like.\n",
    "\n",
    "- Train your network on your training set and test it on your test set.\n",
    "Calculate evaluation measures and compare with your previous\n",
    "classifier.\n",
    "\n",
    "- Optional: Experiment with different network sizes.\n",
    "\n",
    "### 1.2 Prerequisites\n",
    "This notebook assumes you have already executed:\n",
    "- **Lab 2**: Data preprocessing → `../Data/tweets_preprocessed_train.parquet`, `../Data/tweets_preprocessed_test.parquet`, `../Data/tweets_preprocessed_validation.parquet`\n",
    "- **Lab 3**: Language modeling\n",
    "- **Lab 4**: Feature extraction → `../Data/top_1000_vocabulary.json`\n",
    "\n",
    "### 1.3 Architecture\n",
    "We implement a neural network with:\n",
    "- **Input layer**: 1000 features (Top 1000 vocabulary from Lab 4)\n",
    "- **Hidden layers**: 128 → 64 → 128 neurons (as specified)\n",
    "- **Output layer**: 19 binary classifiers (one per topic class, using OneVsRestClassifier)\n",
    "\n",
    "### 1.4 Neural Network Fundamentals (From Lecture)\n",
    "- A single neuron computes: ŷ = g(w₀ + Σ xᵢwᵢ) where g is a non-linear activation function\n",
    "- **Activation functions are critical** - they introduce non-linearities that make multi-layer networks powerful (universal approximators)\n",
    "- Common activations: ReLU (g(z) = max(0,z)), Sigmoid, Tanh\n",
    "- For multi-class (single-label): use **Softmax** to convert outputs to probabilities\n",
    "- For multi-label (our case): use **Sigmoid** per class via OneVsRestClassifier\n",
    "- **Loss function for classification**: Cross-entropy loss\n",
    "- Weights should NOT be initialized to all zeros (breaks symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Task 1: Establish Context\n",
    "\n",
    "### 2.1 Review Preprocessing from Lab 2\n",
    "In Lab 2, we preprocessed tweets with the following pipeline:\n",
    "- Remove RT indicators, URLs, usernames, and mentions\n",
    "- Convert emojis to text descriptions\n",
    "- Extract hashtag text and segment CamelCase words\n",
    "- Normalize whitespace and lowercase\n",
    "- Tokenize with SpaCy and filter/lemmatize tokens\n",
    "\n",
    "The output is stored in parquet files with columns: `text`, `label_name`, `label`\n",
    "\n",
    "Two approaches for label handling are supported:\n",
    "- Parse `label_name` (string list format) into Python lists\n",
    "- Use `label` column directly (pre-computed binary vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import ast\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    hamming_loss,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Constants\n",
    "TRAIN_DATA_PATH = \"../Data/tweets_preprocessed_train.parquet\"\n",
    "TEST_DATA_PATH = \"../Data/tweets_preprocessed_test.parquet\"\n",
    "VALIDATION_DATA_PATH = \"../Data/tweets_preprocessed_validation.parquet\"\n",
    "VOCABULARY_PATH = \"../Data/top_1000_vocabulary.json\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_vocab_section",
   "metadata": {},
   "source": [
    "### 2.2 Load and Verify Vocabulary from Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the top 1000 vocabulary from Lab 4\n",
    "with open(VOCABULARY_PATH, 'r', encoding='utf-8') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "VOCABULARY = vocab_data['tokens']\n",
    "vocab_set = set(VOCABULARY)\n",
    "\n",
    "print(f\"✓ Loaded vocabulary from: {VOCABULARY_PATH}\")\n",
    "print(f\"✓ Description: {vocab_data['description']}\")\n",
    "print(f\"✓ Vocabulary size: {len(VOCABULARY)}\")\n",
    "print(f\"✓ First 20 tokens: {VOCABULARY[:20]}\")\n",
    "print(f\"✓ Last 10 tokens: {VOCABULARY[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_section",
   "metadata": {},
   "source": [
    "### 2.3 Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_datasets",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(value) -> List[str]:\n",
    "    \"\"\"Parse label_name column into consistent Python lists.\"\"\"\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, tuple):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        if value.startswith('[') and value.endswith(']'):\n",
    "            # Remove brackets\n",
    "            inner = value[1:-1].strip()\n",
    "            if not inner:\n",
    "                return []\n",
    "            # Remove quotes and split by whitespace (handles both formats)\n",
    "            inner = inner.replace(\"'\", \"\").replace('\"', '')\n",
    "            labels = [l.strip() for l in inner.split() if l.strip()]\n",
    "            return labels\n",
    "        try:\n",
    "            parsed = ast.literal_eval(value)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                return [str(v) for v in parsed]\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "        return [value] if value else []\n",
    "    return [str(value)] if value else []\n",
    "\n",
    "def parse_binary_label(value) -> np.ndarray:\n",
    "    \"\"\"Parse binary label array from string representation.\"\"\"\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        # Parse \"[0 0 1 0 ...]\" format\n",
    "        inner = value.strip()[1:-1]\n",
    "        return np.array([int(x) for x in inner.split()])\n",
    "    return np.array(value)\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load tweets from parquet and normalize the label columns.\"\"\"\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.copy()\n",
    "    df[\"labels\"] = df[\"label_name\"].apply(parse_labels)\n",
    "    df[\"label_binary\"] = df[\"label\"].apply(parse_binary_label)\n",
    "    return df\n",
    "\n",
    "# Load all datasets\n",
    "df_train = load_dataset(TRAIN_DATA_PATH)\n",
    "df_test = load_dataset(TEST_DATA_PATH)\n",
    "df_validation = load_dataset(VALIDATION_DATA_PATH)\n",
    "\n",
    "print(f\"✓ Training set: {len(df_train):,} samples\")\n",
    "print(f\"✓ Test set: {len(df_test):,} samples\")\n",
    "print(f\"✓ Validation set: {len(df_validation):,} samples\")\n",
    "print(f\"\\nSample preprocessed text:\")\n",
    "print(f\"  {df_train['text'].iloc[0][:80]}...\")\n",
    "print(f\"  Labels: {df_train['labels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plan_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Task 2: Implementation Plan\n",
    "\n",
    "### 3.1 Binary Feature Vector Construction\n",
    "For each sample, we create a binary vector of size 1000 (vocabulary size):\n",
    "- For each word in the vocabulary, set dimension to 1 if word is present in sample, 0 otherwise\n",
    "- This is a Bag-of-Words style encoding (word order is lost)\n",
    "\n",
    "### 3.2 MLPClassifier Configuration\n",
    "- **hidden_layer_sizes**: (128, 64, 128) - three hidden layers as specified\n",
    "- **activation**: 'relu' - ReLU activation (most commonly used)\n",
    "- **solver**: 'adam' - Adam optimizer (handles mini-batch gradient descent)\n",
    "- **max_iter**: 300 - sufficient iterations for convergence\n",
    "- **random_state**: 42 - for reproducibility\n",
    "- **early_stopping**: Disabled (some classes have few samples in multi-label setting)\n",
    "\n",
    "### 3.3 Evaluation Metrics\n",
    "For comparison with Naive Bayes from Lab 4:\n",
    "- Subset Accuracy (exact match)\n",
    "- Hamming Loss\n",
    "- Micro/Macro F1-Score\n",
    "- Micro Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementation_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Task 3: Implementation\n",
    "\n",
    "### 4.1 Feature Engineering: Binary Vector Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_features(texts: pd.Series, vocabulary: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create binary feature vectors for text samples.\n",
    "    \n",
    "    Each dimension represents whether a word from the vocabulary\n",
    "    is present (1) or absent (0) in the sample.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    texts : pd.Series\n",
    "        Series of preprocessed text strings (whitespace-tokenized)\n",
    "    vocabulary : List[str]\n",
    "        List of vocabulary words (top 1000 from Lab 4)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Binary feature matrix of shape (n_samples, vocab_size)\n",
    "    \"\"\"\n",
    "    vocab_set = set(vocabulary)\n",
    "    vocab_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "    \n",
    "    n_samples = len(texts)\n",
    "    n_features = len(vocabulary)\n",
    "    \n",
    "    # Initialize feature matrix with zeros\n",
    "    features = np.zeros((n_samples, n_features), dtype=np.int8)\n",
    "    \n",
    "    # Fill in binary features\n",
    "    for i, text in enumerate(texts):\n",
    "        if isinstance(text, str):\n",
    "            words = set(text.split())\n",
    "            for word in words:\n",
    "                if word in vocab_to_idx:\n",
    "                    features[i, vocab_to_idx[word]] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create binary feature vectors for all datasets\n",
    "print(\"Creating binary feature vectors...\")\n",
    "X_train = create_binary_features(df_train['text'], VOCABULARY)\n",
    "X_test = create_binary_features(df_test['text'], VOCABULARY)\n",
    "X_validation = create_binary_features(df_validation['text'], VOCABULARY)\n",
    "\n",
    "print(f\"\\n✓ Feature matrix shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  X_validation: {X_validation.shape}\")\n",
    "\n",
    "# Show sample feature statistics\n",
    "print(f\"\\nFeature statistics (training set):\")\n",
    "print(f\"  Average features per sample: {X_train.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Max features in a sample: {X_train.sum(axis=1).max()}\")\n",
    "print(f\"  Min features in a sample: {X_train.sum(axis=1).min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "label_encoding_section",
   "metadata": {},
   "source": [
    "### 4.2 Label Encoding (Multi-Label Binarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "label_encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 19 topic classes (from the original dataset)\n",
    "TOPIC_CLASSES = [\n",
    "    'arts_&_culture', 'business_&_entrepreneurs', 'celebrity_&_pop_culture',\n",
    "    'diaries_&_daily_life', 'family', 'fashion_&_style', 'film_tv_&_video',\n",
    "    'fitness_&_health', 'food_&_dining', 'gaming', 'learning_&_educational',\n",
    "    'music', 'news_&_social_concern', 'other_hobbies', 'relationships',\n",
    "    'science_&_technology', 'sports', 'travel_&_adventure', 'youth_&_student_life'\n",
    "]\n",
    "\n",
    "# Use the pre-parsed binary labels directly from the label column\n",
    "y_train = np.vstack(df_train['label_binary'].values)\n",
    "y_test = np.vstack(df_test['label_binary'].values)\n",
    "y_validation = np.vstack(df_validation['label_binary'].values)\n",
    "\n",
    "# Create MultiLabelBinarizer for inverse_transform (label names)\n",
    "mlb = MultiLabelBinarizer(classes=TOPIC_CLASSES)\n",
    "mlb.fit([TOPIC_CLASSES])  # Fit with all classes\n",
    "\n",
    "print(f\"✓ Number of classes: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"✓ Classes: {TOPIC_CLASSES}\")\n",
    "print(f\"\\n✓ Label matrix shapes:\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"  y_validation: {y_validation.shape}\")\n",
    "\n",
    "# Verify label distribution\n",
    "print(f\"\\n✓ Label distribution (training set):\")\n",
    "print(f\"  Average labels per sample: {y_train.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Samples per class: {y_train.sum(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_training_section",
   "metadata": {},
   "source": [
    "### 4.3 Neural Network Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_neural_network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MLPClassifier with specified architecture\n",
    "# Using OneVsRestClassifier for multi-label classification\n",
    "# Note: early_stopping is disabled because some classes have very few samples\n",
    "# which causes issues with the validation split in OneVsRest multi-label setting\n",
    "mlp_base = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Three hidden layers as specified\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer (mini-batch gradient descent)\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=False,                # Disabled for multi-label compatibility\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "# Wrap with OneVsRestClassifier for multi-label support\n",
    "mlp_clf = OneVsRestClassifier(mlp_base, n_jobs=-1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(TOPIC_CLASSES)} neurons (19 topic classes)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining Neural Network...\")\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "print(\"\\n✓ Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 4.4 Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate_neural_network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_nn = mlp_clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test, y_pred_nn),\n",
    "    'Hamming Loss': hamming_loss(y_test, y_pred_nn),\n",
    "    'Micro F1': f1_score(y_test, y_pred_nn, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test, y_pred_nn, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test, y_pred_nn, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test, y_pred_nn, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NEURAL NETWORK EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nn_sample_predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "y_pred_labels = mlb.inverse_transform(y_pred_nn)\n",
    "y_true_labels = mlb.inverse_transform(y_test)\n",
    "\n",
    "print(\"\\nSample Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test['text'].iloc[i][:60]\n",
    "    true = y_true_labels[i] if y_true_labels[i] else ('none',)\n",
    "    pred = y_pred_labels[i] if y_pred_labels[i] else ('none',)\n",
    "    match = \"✓\" if set(true) == set(pred) else \"✗\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   True: {true}\")\n",
    "    print(f\"   Pred: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb_training_section",
   "metadata": {},
   "source": [
    "### 4.5 Naive Bayes Classifier (for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_naive_bayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Naive Bayes classifier with same features\n",
    "nb_clf = OneVsRestClassifier(MultinomialNB(alpha=1.0))\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "nb_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test, y_pred_nb),\n",
    "    'Hamming Loss': hamming_loss(y_test, y_pred_nb),\n",
    "    'Micro F1': f1_score(y_test, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test, y_pred_nb, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test, y_pred_nb, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAIVE BAYES EVALUATION (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_section",
   "metadata": {},
   "source": [
    "### 4.6 Model Comparison: Neural Network vs Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(nn_metrics.keys()),\n",
    "    'Neural Network': list(nn_metrics.values()),\n",
    "    'Naive Bayes': list(nb_metrics.values())\n",
    "})\n",
    "\n",
    "# Calculate improvement\n",
    "comparison_df['Difference'] = comparison_df['Neural Network'] - comparison_df['Naive Bayes']\n",
    "comparison_df['Better Model'] = comparison_df.apply(\n",
    "    lambda row: 'Neural Network' if (row['Difference'] > 0 and row['Metric'] != 'Hamming Loss') \n",
    "                or (row['Difference'] < 0 and row['Metric'] == 'Hamming Loss')\n",
    "                else 'Naive Bayes' if row['Difference'] != 0 else 'Tie',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL COMPARISON: Neural Network vs Naive Bayes\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: For Hamming Loss, lower is better. For all other metrics, higher is better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Optional: Experiment with Different Network Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experiment_architectures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different architectures to test\n",
    "architectures = {\n",
    "    'Small (64-32-64)': (64, 32, 64),\n",
    "    'Medium (128-64-128)': (128, 64, 128),  # Original\n",
    "    'Large (256-128-256)': (256, 128, 256),\n",
    "    'Deep (128-128-64-64-128-128)': (128, 128, 64, 64, 128, 128),\n",
    "    'Wide (512-256-512)': (512, 256, 512)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Experimenting with different network architectures...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, layers in architectures.items():\n",
    "    print(f\"\\nTraining: {name}...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=layers,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=200,\n",
    "        random_state=RANDOM_STATE,\n",
    "        early_stopping=False,  # Disabled for multi-label compatibility\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    clf = OneVsRestClassifier(mlp, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    results.append({\n",
    "        'Architecture': name,\n",
    "        'Layers': str(layers),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Micro F1': f1_score(y_test, y_pred, average='micro', zero_division=0),\n",
    "        'Macro F1': f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {results[-1]['Accuracy']:.4f}, Micro F1: {results[-1]['Micro F1']:.4f}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHITECTURE COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Summary\n",
    "\n",
    "### What was accomplished\n",
    "1. Loaded preprocessed data from Lab 2 and vocabulary from Lab 4\n",
    "2. Created binary feature vectors (Bag-of-Words encoding) for all samples\n",
    "3. Trained a Neural Network with 128→64→128 hidden layers using MLPClassifier\n",
    "4. Evaluated performance on test set\n",
    "5. Compared Neural Network with Naive Bayes classifier\n",
    "6. Experimented with different network architectures\n",
    "\n",
    "### Key Findings\n",
    "- Neural networks can capture non-linear relationships in text classification\n",
    "- The MLPClassifier with ReLU activation and Adam optimizer provides good results\n",
    "- For multi-label tasks, OneVsRestClassifier trains separate binary classifiers per class\n",
    "- Network architecture affects performance, but larger isn't always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LAB 5 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input vocabulary: {VOCABULARY_PATH}\")\n",
    "print(f\"Training samples: {len(df_train):,}\")\n",
    "print(f\"Test samples: {len(df_test):,}\")\n",
    "print(f\"Feature vector size: {X_train.shape[1]}\")\n",
    "print(f\"Number of classes: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"\\nBest Neural Network Metrics:\")\n",
    "print(f\"  Subset Accuracy: {nn_metrics['Subset Accuracy']:.4f}\")\n",
    "print(f\"  Micro F1: {nn_metrics['Micro F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_metrics['Macro F1']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}