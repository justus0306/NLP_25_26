{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Neural Network Classification with scikit-learn\n",
    "\n",
    "---\n",
    "## 1. Notebook Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "Build a Multi-Layer Perceptron (MLP) neural network for multi-label tweet topic classification using scikit-learn's `MLPClassifier`.\n",
    "\n",
    "### 1.2 Prerequisites\n",
    "This notebook assumes you have already executed:\n",
    "- **Lab 2**: Data preprocessing → `../Data/tweets_preprocessed_train.parquet`, `../Data/tweets_preprocessed_test.parquet`, `../Data/tweets_preprocessed_validation.parquet`\n",
    "- **Lab 3**: Language modeling\n",
    "- **Lab 4**: Feature extraction → `../Data/top_1000_vocabulary.json`\n",
    "\n",
    "### 1.3 Architecture\n",
    "We implement a neural network with:\n",
    "- **Input layer**: 1000 features (Top 1000 vocabulary from Lab 4)\n",
    "- **Hidden layers**: 128 → 64 → 128 neurons (as specified)\n",
    "- **Output layer**: 19 neurons (one per topic class)\n",
    "\n",
    "### 1.4 Data Splits\n",
    "- **Training**: `../Data/tweets_preprocessed_train.parquet` (from Lab 2)\n",
    "- **Validation**: `../Data/tweets_preprocessed_validation.parquet` (from Lab 2)\n",
    "- **Test**: `../Data/tweets_preprocessed_test.parquet` (from Lab 2)\n",
    "\n",
    "### 1.5 Section Roadmap\n",
    "1. `Section 2`: Load data and vocabulary\n",
    "2. `Section 3`: Feature extraction using Top 1000 vocabulary from Lab 4\n",
    "3. `Section 4`: Build and train the MLP neural network\n",
    "4. `Section 5`: Evaluate on validation and test sets\n",
    "5. `Section 6`: Architecture comparison and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.  Data Loading\n",
    "\n",
    "Load preprocessed training data from Lab 2, the vocabulary from Lab 4, and preprocessed test/validation splits from Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn pandas numpy datasets matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topic classes: 19\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from typing import List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants - paths to Lab 2 and Lab 4 outputs\n",
    "TRAIN_DATA_PATH = \"../Data/tweets_preprocessed_train.parquet\"\n",
    "TEST_DATA_PATH = \"../Data/tweets_preprocessed_test.parquet\"\n",
    "VALIDATION_DATA_PATH = \"../Data/tweets_preprocessed_validation.parquet\"\n",
    "VOCABULARY_PATH = \"../Data/top_1000_vocabulary.json\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# The 19 topic labels in the dataset\n",
    "TOPIC_LABELS = [\n",
    "    'arts_&_culture', 'business_&_entrepreneurs', 'celebrity_&_pop_culture',\n",
    "    'diaries_&_daily_life', 'family', 'fashion_&_style', 'film_tv_&_video',\n",
    "    'fitness_&_health', 'food_&_dining', 'gaming', 'learning_&_educational',\n",
    "    'music', 'news_&_social_concern', 'other_hobbies', 'relationships',\n",
    "    'science_&_technology', 'sports', 'travel_&_adventure', 'youth_&_student_life'\n",
    "]\n",
    "NUM_CLASSES = len(TOPIC_LABELS)\n",
    "\n",
    "print(f\"Number of topic classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocabulary from Lab 4...\n",
      "✓ Loaded vocabulary from: ../Data/top_1000_vocabulary.json\n",
      "✓ Vocabulary size: 1000\n",
      "✓ First 10 tokens: ['new', 'day', 'love', 'good', 'game', 'year', 'time', 'watch', 'happy', 'music']\n",
      "✓ Description: Top 1000 most frequent tokens from preprocessed tweets (Lab 4)\n"
     ]
    }
   ],
   "source": [
    "# Load the Top 1000 vocabulary from Lab 4\n",
    "print(\"Loading vocabulary from Lab 4...\")\n",
    "with open(VOCABULARY_PATH, 'r', encoding='utf-8') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "TOP_VOCABULARY = vocab_data['tokens']\n",
    "\n",
    "print(f\"✓ Loaded vocabulary from: {VOCABULARY_PATH}\")\n",
    "print(f\"✓ Vocabulary size: {len(TOP_VOCABULARY)}\")\n",
    "print(f\"✓ First 10 tokens: {TOP_VOCABULARY[:10]}\")\n",
    "print(f\"✓ Description: {vocab_data. get('description', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading preprocessed training data from Lab 2...\n",
      "Training samples: 6,090\n",
      "Columns: ['text', 'label_name', 'label']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "d6436443-f106-4228-85a6-dae706819552",
       "rows": [
        [
         "0",
         "lumber beat rapid game western division final evan edwards hit hr wp josh roberson ip bb mw lplayoffs mw lscoreboard",
         "['sports']",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]"
        ],
        [
         "1",
         "hear eli gold announce auburn game dumbass",
         "['sports']",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]"
        ],
        [
         "2",
         "phone away try look home game ticket october",
         "['sports']",
         "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lumber beat rapid game western division final ...</td>\n",
       "      <td>['sports']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hear eli gold announce auburn game dumbass</td>\n",
       "      <td>['sports']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phone away try look home game ticket october</td>\n",
       "      <td>['sports']</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_name  \\\n",
       "0  lumber beat rapid game western division final ...  ['sports']   \n",
       "1         hear eli gold announce auburn game dumbass  ['sports']   \n",
       "2       phone away try look home game ticket october  ['sports']   \n",
       "\n",
       "                                               label  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_label_vector(value) -> np.ndarray:\n",
    "    \"\"\"Parse the label column (binary vector) to numpy array.\"\"\"\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value. astype(np. float32)\n",
    "    if isinstance(value, list):\n",
    "        return np.array(value, dtype=np.float32)\n",
    "    if isinstance(value, str):\n",
    "        # Handle string representation like '[0 0 0 1 0 ...]'\n",
    "        cleaned = value.strip('[]'). split()\n",
    "        return np.array([float(x) for x in cleaned], dtype=np.float32)\n",
    "    return np.zeros(NUM_CLASSES, dtype=np. float32)\n",
    "\n",
    "\n",
    "# Load preprocessed training data from Lab 2\n",
    "print(\"\\nLoading preprocessed training data from Lab 2...\")\n",
    "df_train = pd. read_parquet(TRAIN_DATA_PATH)\n",
    "print(f\"Training samples: {len(df_train):,}\")\n",
    "print(f\"Columns: {df_train.columns.tolist()}\")\n",
    "df_train. head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed test and validation data from Lab 2\n",
    "print(\"Loading preprocessed test and validation data...\")\n",
    "\n",
    "df_test = pd.read_parquet(TEST_DATA_PATH)\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_PATH)\n",
    "\n",
    "print(f\"Test samples: {len(df_test):,}\")\n",
    "print(f\"Validation samples: {len(df_val):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label matrix shapes:\n",
      "  y_train: (6090, 19)\n",
      "  y_test: (1679, 19)\n",
      "  y_val: (188, 19)\n",
      "\n",
      "Training set label distribution:\n",
      "  arts_&_culture: 298 (4.9%)\n",
      "  business_&_entrepreneurs: 288 (4.7%)\n",
      "  celebrity_&_pop_culture: 924 (15.2%)\n",
      "  diaries_&_daily_life: 866 (14.2%)\n",
      "  family: 252 (4.1%)\n",
      "  ...  (showing 5 of 19 classes)\n"
     ]
    }
   ],
   "source": [
    "# Extract labels - use the 'label' column which contains binary vectors\n",
    "y_train = np.array([parse_label_vector(lbl) for lbl in df_train['label']])\n",
    "y_test = np.array([parse_label_vector(lbl) for lbl in df_test['label']])\n",
    "y_val = np.array([parse_label_vector(lbl) for lbl in df_val['label']])\n",
    "\n",
    "print(f\"\\nLabel matrix shapes:\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"  y_val: {y_val.shape}\")\n",
    "\n",
    "# Verify label distribution\n",
    "print(f\"\\nTraining set label distribution:\")\n",
    "for i, label in enumerate(TOPIC_LABELS[:5]):\n",
    "    count = int(y_train[:, i].sum())\n",
    "    print(f\"  {label}: {count} ({count/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  ...  (showing 5 of {NUM_CLASSES} classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Extraction\n",
    "\n",
    "### 3.1 Using the Top 1000 Vocabulary from Lab 4\n",
    "Instead of creating a new vocabulary, we reuse the top 1000 tokens extracted in Lab 4.  This ensures consistency across the pipeline and avoids redundant computation.\n",
    "\n",
    "### 3.2 TF-IDF Vectorization\n",
    "We use TF-IDF weighting with the predefined vocabulary to create feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text data using Lab 4 vocabulary...\n",
      "\n",
      "Feature matrix shapes:\n",
      "  X_train: (6090, 1000)\n",
      "  X_test: (1679, 1000)\n",
      "  X_val: (188, 1000)\n",
      "\n",
      "Vocabulary size: 1000 (from Lab 4)\n",
      "Sample features: ['new', 'day', 'love', 'good', 'game', 'year', 'time', 'watch', 'happy', 'music']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use the Top 1000 vocabulary from Lab 4\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    vocabulary=TOP_VOCABULARY,  # Predefined vocabulary from Lab 4\n",
    "    lowercase=True,\n",
    ")\n",
    "\n",
    "# Transform all splits using the predefined vocabulary\n",
    "print(\"Vectorizing text data using Lab 4 vocabulary...\")\n",
    "X_train = tfidf_vectorizer.fit_transform(df_train['text']. astype(str))\n",
    "X_test = tfidf_vectorizer.transform(df_test['text'].astype(str))\n",
    "X_val = tfidf_vectorizer.transform(df_val['text'].astype(str))\n",
    "\n",
    "print(f\"\\nFeature matrix shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_test: {X_test. shape}\")\n",
    "print(f\"  X_val: {X_val.shape}\")\n",
    "print(f\"\\nVocabulary size: {len(tfidf_vectorizer.get_feature_names_out())} (from Lab 4)\")\n",
    "print(f\"Sample features: {tfidf_vectorizer.get_feature_names_out()[:10]. tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4.  Neural Network Model\n",
    "\n",
    "### 4. 1 Architecture\n",
    "As specified in the lab requirements:\n",
    "- **Input layer**: 1000 features (Top 1000 vocabulary from Lab 4)\n",
    "- **Hidden layer 1**: 128 neurons\n",
    "- **Hidden layer 2**: 64 neurons\n",
    "- **Hidden layer 3**: 128 neurons\n",
    "- **Output layer**: 19 neurons (one per topic)\n",
    "\n",
    "### 4.2 Why no early_stopping?\n",
    "We have dedicated validation (`validation_2021`) and test (`test_2021`) splits from HuggingFace. There's no need for scikit-learn to internally split the training data for early stopping validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NEURAL NETWORK CONFIGURATION\n",
      "============================================================\n",
      "Input layer: 1000 features (Top 1000 from Lab 4)\n",
      "Hidden layers: (128, 64, 128)\n",
      "Output layer: 19 classes\n",
      "============================================================\n",
      "\n",
      "✓ Model created successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import time\n",
    "\n",
    "# Architecture as specified: 128 -> 64 -> 128\n",
    "HIDDEN_LAYERS = (128, 64, 128)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NEURAL NETWORK CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Input layer: {X_train.shape[1]} features (Top 1000 from Lab 4)\")\n",
    "print(f\"Hidden layers: {HIDDEN_LAYERS}\")\n",
    "print(f\"Output layer: {NUM_CLASSES} classes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create MLP classifier\n",
    "# No early_stopping - we use HuggingFace's validation_2021 for model selection\n",
    "mlp_base = MLPClassifier(\n",
    "    hidden_layer_sizes=HIDDEN_LAYERS,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Wrap for multi-label classification\n",
    "mlp_classifier = MultiOutputClassifier(mlp_base, n_jobs=-1)\n",
    "\n",
    "print(\"\\n✓ Model created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING\n",
      "============================================================\n",
      "Iteration 1, loss = 0.56177892\n",
      "Iteration 1, loss = 0.45832973\n",
      "Iteration 1, loss = 0.55313979\n",
      "Iteration 1, loss = 0.47879908\n",
      "Iteration 1, loss = 0.47442996\n",
      "Iteration 1, loss = 0.47106813\n",
      "Iteration 1, loss = 0.54621519\n",
      "Iteration 1, loss = 0.47446338\n",
      "Iteration 1, loss = 0.55207665\n",
      "Iteration 1, loss = 0.47159996\n",
      "Iteration 1, loss = 0.45349226\n",
      "Iteration 1, loss = 0.45971694\n",
      "Iteration 2, loss = 0.37984032\n",
      "Iteration 2, loss = 0.38582764\n",
      "Iteration 2, loss = 0.18058630\n",
      "Iteration 2, loss = 0.18552682\n",
      "Iteration 2, loss = 0.17736937\n",
      "Iteration 2, loss = 0.11872234\n",
      "Iteration 2, loss = 0.15451212\n",
      "Iteration 2, loss = 0.11759212\n",
      "Iteration 2, loss = 0.16080036\n",
      "Iteration 2, loss = 0.38015596\n",
      "Iteration 2, loss = 0.39539668\n",
      "Iteration 3, loss = 0.11788787\n",
      "Iteration 3, loss = 0.15834571\n",
      "Iteration 3, loss = 0.30370063\n",
      "Iteration 3, loss = 0.09650230\n",
      "Iteration 3, loss = 0.14470090\n",
      "Iteration 2, loss = 0.08015674\n",
      "Iteration 3, loss = 0.15051933\n",
      "Iteration 3, loss = 0.23329727\n",
      "Iteration 3, loss = 0.33979595\n",
      "Iteration 3, loss = 0.32103469\n",
      "Iteration 1, loss = 0.56177892\n",
      "Iteration 1, loss = 0.45832973\n",
      "Iteration 1, loss = 0.55313979\n",
      "Iteration 1, loss = 0.47879908\n",
      "Iteration 1, loss = 0.47442996\n",
      "Iteration 1, loss = 0.47106813\n",
      "Iteration 1, loss = 0.54621519\n",
      "Iteration 1, loss = 0.47446338\n",
      "Iteration 1, loss = 0.55207665\n",
      "Iteration 1, loss = 0.47159996\n",
      "Iteration 1, loss = 0.45349226\n",
      "Iteration 1, loss = 0.45971694\n",
      "Iteration 2, loss = 0.37984032\n",
      "Iteration 2, loss = 0.38582764\n",
      "Iteration 2, loss = 0.18058630\n",
      "Iteration 2, loss = 0.18552682\n",
      "Iteration 2, loss = 0.17736937\n",
      "Iteration 2, loss = 0.11872234\n",
      "Iteration 2, loss = 0.15451212\n",
      "Iteration 2, loss = 0.11759212\n",
      "Iteration 2, loss = 0.16080036\n",
      "Iteration 2, loss = 0.38015596\n",
      "Iteration 2, loss = 0.39539668\n",
      "Iteration 3, loss = 0.11788787\n",
      "Iteration 3, loss = 0.15834571\n",
      "Iteration 3, loss = 0.30370063\n",
      "Iteration 3, loss = 0.09650230\n",
      "Iteration 3, loss = 0.14470090\n",
      "Iteration 2, loss = 0.08015674\n",
      "Iteration 3, loss = 0.15051933\n",
      "Iteration 3, loss = 0.23329727\n",
      "Iteration 3, loss = 0.33979595\n",
      "Iteration 3, loss = 0.32103469\n",
      "Iteration 3, loss = 0.09073352\n",
      "Iteration 3, loss = 0.13138555\n",
      "Iteration 4, loss = 0.08835998\n",
      "Iteration 4, loss = 0.08194462\n",
      "Iteration 4, loss = 0.11980876\n",
      "Iteration 4, loss = 0.13669230\n",
      "Iteration 4, loss = 0.28380663\n",
      "Iteration 4, loss = 0.12319547\n",
      "Iteration 4, loss = 0.13567390\n",
      "Iteration 4, loss = 0.23436052\n",
      "Iteration 4, loss = 0.26465593\n",
      "Iteration 4, loss = 0.10409794\n",
      "Iteration 5, loss = 0.06466220\n",
      "Iteration 5, loss = 0.09185449\n",
      "Iteration 5, loss = 0.06638999Iteration 3, loss = 0.06197077\n",
      "\n",
      "Iteration 5, loss = 0.23666361\n",
      "Iteration 4, loss = 0.07546074\n",
      "Iteration 5, loss = 0.09445620\n",
      "Iteration 5, loss = 0.09743566\n",
      "Iteration 5, loss = 0.21647190\n",
      "Iteration 5, loss = 0.11298322\n",
      "Iteration 5, loss = 0.17319940\n",
      "Iteration 5, loss = 0.07953868\n",
      "Iteration 6, loss = 0.04376445\n",
      "Iteration 4, loss = 0.05183343\n",
      "Iteration 6, loss = 0.07531950\n",
      "Iteration 6, loss = 0.05242974\n",
      "Iteration 6, loss = 0.05939464\n",
      "Iteration 3, loss = 0.09073352\n",
      "Iteration 3, loss = 0.13138555\n",
      "Iteration 4, loss = 0.08835998\n",
      "Iteration 4, loss = 0.08194462\n",
      "Iteration 4, loss = 0.11980876\n",
      "Iteration 4, loss = 0.13669230\n",
      "Iteration 4, loss = 0.28380663\n",
      "Iteration 4, loss = 0.12319547\n",
      "Iteration 4, loss = 0.13567390\n",
      "Iteration 4, loss = 0.23436052\n",
      "Iteration 4, loss = 0.26465593\n",
      "Iteration 4, loss = 0.10409794\n",
      "Iteration 5, loss = 0.06466220\n",
      "Iteration 5, loss = 0.09185449\n",
      "Iteration 5, loss = 0.06638999Iteration 3, loss = 0.06197077\n",
      "\n",
      "Iteration 5, loss = 0.23666361\n",
      "Iteration 4, loss = 0.07546074\n",
      "Iteration 5, loss = 0.09445620\n",
      "Iteration 5, loss = 0.09743566\n",
      "Iteration 5, loss = 0.21647190\n",
      "Iteration 5, loss = 0.11298322\n",
      "Iteration 5, loss = 0.17319940\n",
      "Iteration 5, loss = 0.07953868\n",
      "Iteration 6, loss = 0.04376445\n",
      "Iteration 4, loss = 0.05183343\n",
      "Iteration 6, loss = 0.07531950\n",
      "Iteration 6, loss = 0.05242974\n",
      "Iteration 6, loss = 0.05939464\n",
      "Iteration 6, loss = 0.07357740\n",
      "Iteration 6, loss = 0.18482014\n",
      "Iteration 6, loss = 0.11909174\n",
      "Iteration 6, loss = 0.09084762\n",
      "Iteration 5, loss = 0.06009342\n",
      "Iteration 6, loss = 0.15978834\n",
      "Iteration 5, loss = 0.04167188\n",
      "Iteration 6, loss = 0.06027796\n",
      "Iteration 7, loss = 0.04096218\n",
      "Iteration 7, loss = 0.02368667\n",
      "Iteration 7, loss = 0.12203170\n",
      "Iteration 7, loss = 0.03702259\n",
      "Iteration 6, loss = 0.04578821\n",
      "Iteration 7, loss = 0.05443158\n",
      "Iteration 7, loss = 0.05584316\n",
      "Iteration 7, loss = 0.07460334\n",
      "Iteration 7, loss = 0.06816089\n",
      "Iteration 7, loss = 0.09500326\n",
      "Iteration 6, loss = 0.03248894\n",
      "Iteration 8, loss = 0.06876617\n",
      "Iteration 8, loss = 0.03068025\n",
      "Iteration 8, loss = 0.02108057\n",
      "Iteration 7, loss = 0.04482416\n",
      "Iteration 7, loss = 0.03377597\n",
      "Iteration 8, loss = 0.03465691\n",
      "Iteration 8, loss = 0.03856302\n",
      "Iteration 8, loss = 0.04205824\n",
      "Iteration 8, loss = 0.01241113\n",
      "Iteration 8, loss = 0.04993723\n",
      "Iteration 8, loss = 0.04333959\n",
      "Iteration 9, loss = 0.03402426\n",
      "Iteration 6, loss = 0.07357740\n",
      "Iteration 6, loss = 0.18482014\n",
      "Iteration 6, loss = 0.11909174\n",
      "Iteration 6, loss = 0.09084762\n",
      "Iteration 5, loss = 0.06009342\n",
      "Iteration 6, loss = 0.15978834\n",
      "Iteration 5, loss = 0.04167188\n",
      "Iteration 6, loss = 0.06027796\n",
      "Iteration 7, loss = 0.04096218\n",
      "Iteration 7, loss = 0.02368667\n",
      "Iteration 7, loss = 0.12203170\n",
      "Iteration 7, loss = 0.03702259\n",
      "Iteration 6, loss = 0.04578821\n",
      "Iteration 7, loss = 0.05443158\n",
      "Iteration 7, loss = 0.05584316\n",
      "Iteration 7, loss = 0.07460334\n",
      "Iteration 7, loss = 0.06816089\n",
      "Iteration 7, loss = 0.09500326\n",
      "Iteration 6, loss = 0.03248894\n",
      "Iteration 8, loss = 0.06876617\n",
      "Iteration 8, loss = 0.03068025\n",
      "Iteration 8, loss = 0.02108057\n",
      "Iteration 7, loss = 0.04482416\n",
      "Iteration 7, loss = 0.03377597\n",
      "Iteration 8, loss = 0.03465691\n",
      "Iteration 8, loss = 0.03856302\n",
      "Iteration 8, loss = 0.04205824\n",
      "Iteration 8, loss = 0.01241113\n",
      "Iteration 8, loss = 0.04993723\n",
      "Iteration 8, loss = 0.04333959\n",
      "Iteration 9, loss = 0.03402426\n",
      "Iteration 8, loss = 0.02910071\n",
      "Iteration 8, loss = 0.02287465\n",
      "Iteration 7, loss = 0.02570811\n",
      "Iteration 9, loss = 0.01930328\n",
      "Iteration 9, loss = 0.02108748\n",
      "Iteration 9, loss = 0.01283221\n",
      "Iteration 9, loss = 0.02371086\n",
      "Iteration 9, loss = 0.02332340\n",
      "Iteration 9, loss = 0.02402926\n",
      "Iteration 9, loss = 0.00676399\n",
      "Iteration 10, loss = 0.01719380\n",
      "Iteration 8, loss = 0.01990459\n",
      "Iteration 9, loss = 0.02384759\n",
      "Iteration 9, loss = 0.01684159\n",
      "Iteration 10, loss = 0.01422823\n",
      "Iteration 10, loss = 0.01127115\n",
      "Iteration 9, loss = 0.01286485\n",
      "Iteration 10, loss = 0.01384541\n",
      "Iteration 10, loss = 0.00834032\n",
      "Iteration 10, loss = 0.01213081\n",
      "Iteration 10, loss = 0.01426122\n",
      "Iteration 11, loss = 0.01134757\n",
      "Iteration 9, loss = 0.01378293\n",
      "Iteration 10, loss = 0.00981819\n",
      "Iteration 10, loss = 0.00665664\n",
      "Iteration 10, loss = 0.00352212\n",
      "Iteration 11, loss = 0.00771195\n",
      "Iteration 11, loss = 0.00653029\n",
      "Iteration 11, loss = 0.00917090\n",
      "Iteration 10, loss = 0.01294961\n",
      "Iteration 11, loss = 0.00648560\n",
      "Iteration 11, loss = 0.00624504\n",
      "Iteration 10, loss = 0.00846658\n",
      "Iteration 8, loss = 0.02910071\n",
      "Iteration 8, loss = 0.02287465\n",
      "Iteration 7, loss = 0.02570811\n",
      "Iteration 9, loss = 0.01930328\n",
      "Iteration 9, loss = 0.02108748\n",
      "Iteration 9, loss = 0.01283221\n",
      "Iteration 9, loss = 0.02371086\n",
      "Iteration 9, loss = 0.02332340\n",
      "Iteration 9, loss = 0.02402926\n",
      "Iteration 9, loss = 0.00676399\n",
      "Iteration 10, loss = 0.01719380\n",
      "Iteration 8, loss = 0.01990459\n",
      "Iteration 9, loss = 0.02384759\n",
      "Iteration 9, loss = 0.01684159\n",
      "Iteration 10, loss = 0.01422823\n",
      "Iteration 10, loss = 0.01127115\n",
      "Iteration 9, loss = 0.01286485\n",
      "Iteration 10, loss = 0.01384541\n",
      "Iteration 10, loss = 0.00834032\n",
      "Iteration 10, loss = 0.01213081\n",
      "Iteration 10, loss = 0.01426122\n",
      "Iteration 11, loss = 0.01134757\n",
      "Iteration 9, loss = 0.01378293\n",
      "Iteration 10, loss = 0.00981819\n",
      "Iteration 10, loss = 0.00665664\n",
      "Iteration 10, loss = 0.00352212\n",
      "Iteration 11, loss = 0.00771195\n",
      "Iteration 11, loss = 0.00653029\n",
      "Iteration 11, loss = 0.00917090\n",
      "Iteration 10, loss = 0.01294961\n",
      "Iteration 11, loss = 0.00648560\n",
      "Iteration 11, loss = 0.00624504\n",
      "Iteration 10, loss = 0.00846658\n",
      "Iteration 11, loss = 0.00565374\n",
      "Iteration 11, loss = 0.00924983\n",
      "Iteration 12, loss = 0.00432201\n",
      "Iteration 11, loss = 0.00514977\n",
      "Iteration 11, loss = 0.00344994\n",
      "Iteration 11, loss = 0.00837503\n",
      "Iteration 12, loss = 0.00943382\n",
      "Iteration 12, loss = 0.00575731\n",
      "Iteration 12, loss = 0.00389270\n",
      "Iteration 11, loss = 0.00222240\n",
      "Iteration 12, loss = 0.00491006\n",
      "Iteration 12, loss = 0.00524640\n",
      "Iteration 12, loss = 0.00381291\n",
      "Iteration 12, loss = 0.00196539\n",
      "Iteration 13, loss = 0.00679127\n",
      "Iteration 13, loss = 0.00342935\n",
      "Iteration 12, loss = 0.00668873\n",
      "Iteration 12, loss = 0.00380308\n",
      "Iteration 13, loss = 0.00297864\n",
      "Iteration 13, loss = 0.00232241\n",
      "Iteration 13, loss = 0.00429092\n",
      "Iteration 13, loss = 0.00345151\n",
      "Iteration 12, loss = 0.00657349\n",
      "Iteration 14, loss = 0.00605910\n",
      "Iteration 13, loss = 0.00225546\n",
      "Iteration 12, loss = 0.00203573\n",
      "Iteration 13, loss = 0.00137028\n",
      "Iteration 13, loss = 0.00459725\n",
      "Iteration 13, loss = 0.00256740\n",
      "Iteration 14, loss = 0.00193595\n",
      "Iteration 14, loss = 0.00289473\n",
      "Iteration 14, loss = 0.00228200\n",
      "Iteration 14, loss = 0.00386012\n",
      "Iteration 14, loss = 0.00201083\n",
      "Iteration 15, loss = 0.00572521\n",
      "Iteration 11, loss = 0.00565374\n",
      "Iteration 11, loss = 0.00924983\n",
      "Iteration 12, loss = 0.00432201\n",
      "Iteration 11, loss = 0.00514977\n",
      "Iteration 11, loss = 0.00344994\n",
      "Iteration 11, loss = 0.00837503\n",
      "Iteration 12, loss = 0.00943382\n",
      "Iteration 12, loss = 0.00575731\n",
      "Iteration 12, loss = 0.00389270\n",
      "Iteration 11, loss = 0.00222240\n",
      "Iteration 12, loss = 0.00491006\n",
      "Iteration 12, loss = 0.00524640\n",
      "Iteration 12, loss = 0.00381291\n",
      "Iteration 12, loss = 0.00196539\n",
      "Iteration 13, loss = 0.00679127\n",
      "Iteration 13, loss = 0.00342935\n",
      "Iteration 12, loss = 0.00668873\n",
      "Iteration 12, loss = 0.00380308\n",
      "Iteration 13, loss = 0.00297864\n",
      "Iteration 13, loss = 0.00232241\n",
      "Iteration 13, loss = 0.00429092\n",
      "Iteration 13, loss = 0.00345151\n",
      "Iteration 12, loss = 0.00657349\n",
      "Iteration 14, loss = 0.00605910\n",
      "Iteration 13, loss = 0.00225546\n",
      "Iteration 12, loss = 0.00203573\n",
      "Iteration 13, loss = 0.00137028\n",
      "Iteration 13, loss = 0.00459725\n",
      "Iteration 13, loss = 0.00256740\n",
      "Iteration 14, loss = 0.00193595\n",
      "Iteration 14, loss = 0.00289473\n",
      "Iteration 14, loss = 0.00228200\n",
      "Iteration 14, loss = 0.00386012\n",
      "Iteration 14, loss = 0.00201083\n",
      "Iteration 15, loss = 0.00572521\n",
      "Iteration 14, loss = 0.00147764\n",
      "Iteration 13, loss = 0.00495698\n",
      "Iteration 15, loss = 0.00122936\n",
      "Iteration 14, loss = 0.00116149\n",
      "Iteration 13, loss = 0.00197700\n",
      "Iteration 14, loss = 0.00342802\n",
      "Iteration 14, loss = 0.00203732\n",
      "Iteration 15, loss = 0.00271568\n",
      "Iteration 15, loss = 0.00098538\n",
      "Iteration 15, loss = 0.00179940\n",
      "Iteration 15, loss = 0.00258683\n",
      "Iteration 14, loss = 0.00407710\n",
      "Iteration 16, loss = 0.00537245\n",
      "Iteration 15, loss = 0.00330403\n",
      "Iteration 14, loss = 0.00157081\n",
      "Iteration 16, loss = 0.00173666\n",
      "Iteration 15, loss = 0.00100797\n",
      "Iteration 15, loss = 0.00180247\n",
      "Iteration 16, loss = 0.00075302\n",
      "Iteration 16, loss = 0.00174834\n",
      "Iteration 16, loss = 0.00174278\n",
      "Iteration 17, loss = 0.00439052\n",
      "Iteration 15, loss = 0.00409254\n",
      "Iteration 15, loss = 0.00318315\n",
      "Iteration 16, loss = 0.00099456\n",
      "Iteration 16, loss = 0.00177182\n",
      "Iteration 16, loss = 0.00284502\n",
      "Iteration 17, loss = 0.00163757\n",
      "Iteration 16, loss = 0.00091836\n",
      "Iteration 17, loss = 0.00138234\n",
      "Iteration 17, loss = 0.00055304\n",
      "Iteration 15, loss = 0.00133241\n",
      "Iteration 17, loss = 0.00147250\n",
      "Iteration 14, loss = 0.00147764\n",
      "Iteration 13, loss = 0.00495698\n",
      "Iteration 15, loss = 0.00122936\n",
      "Iteration 14, loss = 0.00116149\n",
      "Iteration 13, loss = 0.00197700\n",
      "Iteration 14, loss = 0.00342802\n",
      "Iteration 14, loss = 0.00203732\n",
      "Iteration 15, loss = 0.00271568\n",
      "Iteration 15, loss = 0.00098538\n",
      "Iteration 15, loss = 0.00179940\n",
      "Iteration 15, loss = 0.00258683\n",
      "Iteration 14, loss = 0.00407710\n",
      "Iteration 16, loss = 0.00537245\n",
      "Iteration 15, loss = 0.00330403\n",
      "Iteration 14, loss = 0.00157081\n",
      "Iteration 16, loss = 0.00173666\n",
      "Iteration 15, loss = 0.00100797\n",
      "Iteration 15, loss = 0.00180247\n",
      "Iteration 16, loss = 0.00075302\n",
      "Iteration 16, loss = 0.00174834\n",
      "Iteration 16, loss = 0.00174278\n",
      "Iteration 17, loss = 0.00439052\n",
      "Iteration 15, loss = 0.00409254\n",
      "Iteration 15, loss = 0.00318315\n",
      "Iteration 16, loss = 0.00099456\n",
      "Iteration 16, loss = 0.00177182\n",
      "Iteration 16, loss = 0.00284502\n",
      "Iteration 17, loss = 0.00163757\n",
      "Iteration 16, loss = 0.00091836\n",
      "Iteration 17, loss = 0.00138234\n",
      "Iteration 17, loss = 0.00055304\n",
      "Iteration 15, loss = 0.00133241\n",
      "Iteration 17, loss = 0.00147250\n",
      "Iteration 18, loss = 0.00460641\n",
      "Iteration 16, loss = 0.00342095\n",
      "Iteration 16, loss = 0.00107018\n",
      "Iteration 17, loss = 0.00159326\n",
      "Iteration 18, loss = 0.00153418\n",
      "Iteration 16, loss = 0.00315493\n",
      "Iteration 17, loss = 0.00094756\n",
      "Iteration 19, loss = 0.00449773\n",
      "Iteration 18, loss = 0.00141025\n",
      "Iteration 18, loss = 0.00043136\n",
      "Iteration 17, loss = 0.00344468\n",
      "Iteration 18, loss = 0.00128671\n",
      "Iteration 17, loss = 0.00084559\n",
      "Iteration 17, loss = 0.00084469\n",
      "Iteration 17, loss = 0.00327464\n",
      "Iteration 20, loss = 0.00455615\n",
      "Iteration 19, loss = 0.00036946\n",
      "Iteration 17, loss = 0.00313639\n",
      "Iteration 18, loss = 0.00113248\n",
      "Iteration 19, loss = 0.00101573\n",
      "Iteration 18, loss = 0.00269093\n",
      "Iteration 18, loss = 0.00310738\n",
      "Iteration 19, loss = 0.00134279\n",
      "Iteration 18, loss = 0.00086043\n",
      "Iteration 19, loss = 0.00116888\n",
      "Iteration 18, loss = 0.00086303\n",
      "Iteration 21, loss = 0.00421615\n",
      "Iteration 20, loss = 0.00032611\n",
      "Iteration 18, loss = 0.00074375\n",
      "Iteration 20, loss = 0.00090203\n",
      "Iteration 19, loss = 0.00379366\n",
      "Iteration 18, loss = 0.00460641\n",
      "Iteration 16, loss = 0.00342095\n",
      "Iteration 16, loss = 0.00107018\n",
      "Iteration 17, loss = 0.00159326\n",
      "Iteration 18, loss = 0.00153418\n",
      "Iteration 16, loss = 0.00315493\n",
      "Iteration 17, loss = 0.00094756\n",
      "Iteration 19, loss = 0.00449773\n",
      "Iteration 18, loss = 0.00141025\n",
      "Iteration 18, loss = 0.00043136\n",
      "Iteration 17, loss = 0.00344468\n",
      "Iteration 18, loss = 0.00128671\n",
      "Iteration 17, loss = 0.00084559\n",
      "Iteration 17, loss = 0.00084469\n",
      "Iteration 17, loss = 0.00327464\n",
      "Iteration 20, loss = 0.00455615\n",
      "Iteration 19, loss = 0.00036946\n",
      "Iteration 17, loss = 0.00313639\n",
      "Iteration 18, loss = 0.00113248\n",
      "Iteration 19, loss = 0.00101573\n",
      "Iteration 18, loss = 0.00269093\n",
      "Iteration 18, loss = 0.00310738\n",
      "Iteration 19, loss = 0.00134279\n",
      "Iteration 18, loss = 0.00086043\n",
      "Iteration 19, loss = 0.00116888\n",
      "Iteration 18, loss = 0.00086303\n",
      "Iteration 21, loss = 0.00421615\n",
      "Iteration 20, loss = 0.00032611\n",
      "Iteration 18, loss = 0.00074375\n",
      "Iteration 20, loss = 0.00090203\n",
      "Iteration 19, loss = 0.00379366\n",
      "Iteration 18, loss = 0.00266927\n",
      "Iteration 19, loss = 0.00282811\n",
      "Iteration 19, loss = 0.00078616\n",
      "Iteration 19, loss = 0.00120152\n",
      "Iteration 20, loss = 0.00097481\n",
      "Iteration 20, loss = 0.00130723\n",
      "Iteration 22, loss = 0.00460534\n",
      "Iteration 19, loss = 0.00072668\n",
      "Iteration 21, loss = 0.00029803\n",
      "Iteration 19, loss = 0.00068654\n",
      "Iteration 21, loss = 0.00086882\n",
      "Iteration 19, loss = 0.00230433\n",
      "Iteration 20, loss = 0.00082202\n",
      "Iteration 20, loss = 0.00277755\n",
      "Iteration 20, loss = 0.00322281\n",
      "Iteration 21, loss = 0.00083451\n",
      "Iteration 21, loss = 0.00112053\n",
      "Iteration 20, loss = 0.00096953\n",
      "Iteration 22, loss = 0.00027788\n",
      "Iteration 20, loss = 0.00070956\n",
      "Iteration 23, loss = 0.00450559\n",
      "Iteration 20, loss = 0.00081374\n",
      "Iteration 22, loss = 0.00098354\n",
      "Iteration 20, loss = 0.00282960\n",
      "Iteration 21, loss = 0.00324212\n",
      "Iteration 21, loss = 0.00077736\n",
      "Iteration 21, loss = 0.00345922\n",
      "Iteration 22, loss = 0.00086059\n",
      "Iteration 23, loss = 0.00026290\n",
      "Iteration 21, loss = 0.00101513\n",
      "Iteration 24, loss = 0.00419166\n",
      "Iteration 21, loss = 0.00148686\n",
      "Iteration 22, loss = 0.00097525\n",
      "Iteration 18, loss = 0.00266927\n",
      "Iteration 19, loss = 0.00282811\n",
      "Iteration 19, loss = 0.00078616\n",
      "Iteration 19, loss = 0.00120152\n",
      "Iteration 20, loss = 0.00097481\n",
      "Iteration 20, loss = 0.00130723\n",
      "Iteration 22, loss = 0.00460534\n",
      "Iteration 19, loss = 0.00072668\n",
      "Iteration 21, loss = 0.00029803\n",
      "Iteration 19, loss = 0.00068654\n",
      "Iteration 21, loss = 0.00086882\n",
      "Iteration 19, loss = 0.00230433\n",
      "Iteration 20, loss = 0.00082202\n",
      "Iteration 20, loss = 0.00277755\n",
      "Iteration 20, loss = 0.00322281\n",
      "Iteration 21, loss = 0.00083451\n",
      "Iteration 21, loss = 0.00112053\n",
      "Iteration 20, loss = 0.00096953\n",
      "Iteration 22, loss = 0.00027788\n",
      "Iteration 20, loss = 0.00070956\n",
      "Iteration 23, loss = 0.00450559\n",
      "Iteration 20, loss = 0.00081374\n",
      "Iteration 22, loss = 0.00098354\n",
      "Iteration 20, loss = 0.00282960\n",
      "Iteration 21, loss = 0.00324212\n",
      "Iteration 21, loss = 0.00077736\n",
      "Iteration 21, loss = 0.00345922\n",
      "Iteration 22, loss = 0.00086059\n",
      "Iteration 23, loss = 0.00026290\n",
      "Iteration 21, loss = 0.00101513\n",
      "Iteration 24, loss = 0.00419166\n",
      "Iteration 21, loss = 0.00148686\n",
      "Iteration 22, loss = 0.00097525\n",
      "Iteration 23, loss = 0.00056391\n",
      "Iteration 22, loss = 0.00080501\n",
      "Iteration 22, loss = 0.00360282\n",
      "Iteration 21, loss = 0.00064699\n",
      "Iteration 22, loss = 0.00281319\n",
      "Iteration 24, loss = 0.00025002\n",
      "Iteration 23, loss = 0.00098080\n",
      "Iteration 21, loss = 0.00259261\n",
      "Iteration 25, loss = 0.00539082\n",
      "Iteration 22, loss = 0.00076644\n",
      "Iteration 22, loss = 0.00086787\n",
      "Iteration 23, loss = 0.00110966\n",
      "Iteration 23, loss = 0.00100251\n",
      "Iteration 22, loss = 0.00054435\n",
      "Iteration 23, loss = 0.00313981\n",
      "Iteration 24, loss = 0.00084826\n",
      "Iteration 26, loss = 0.00545842\n",
      "Iteration 25, loss = 0.00024090\n",
      "Iteration 22, loss = 0.00278354\n",
      "Iteration 23, loss = 0.00062374\n",
      "Iteration 24, loss = 0.00075056\n",
      "Iteration 24, loss = 0.00112111\n",
      "Iteration 23, loss = 0.00093876\n",
      "Iteration 23, loss = 0.00419292\n",
      "Iteration 24, loss = 0.00252297\n",
      "Iteration 24, loss = 0.00077541\n",
      "Iteration 27, loss = 0.00401153\n",
      "Iteration 25, loss = 0.00055006\n",
      "Iteration 23, loss = 0.00061719\n",
      "Iteration 24, loss = 0.00074864\n",
      "Iteration 25, loss = 0.00270309\n",
      "Iteration 25, loss = 0.00076612\n",
      "Iteration 24, loss = 0.00370872\n",
      "Iteration 26, loss = 0.00023235\n",
      "Iteration 24, loss = 0.00063518\n",
      "Iteration 23, loss = 0.00056391\n",
      "Iteration 22, loss = 0.00080501\n",
      "Iteration 22, loss = 0.00360282\n",
      "Iteration 21, loss = 0.00064699\n",
      "Iteration 22, loss = 0.00281319\n",
      "Iteration 24, loss = 0.00025002\n",
      "Iteration 23, loss = 0.00098080\n",
      "Iteration 21, loss = 0.00259261\n",
      "Iteration 25, loss = 0.00539082\n",
      "Iteration 22, loss = 0.00076644\n",
      "Iteration 22, loss = 0.00086787\n",
      "Iteration 23, loss = 0.00110966\n",
      "Iteration 23, loss = 0.00100251\n",
      "Iteration 22, loss = 0.00054435\n",
      "Iteration 23, loss = 0.00313981\n",
      "Iteration 24, loss = 0.00084826\n",
      "Iteration 26, loss = 0.00545842\n",
      "Iteration 25, loss = 0.00024090\n",
      "Iteration 22, loss = 0.00278354\n",
      "Iteration 23, loss = 0.00062374\n",
      "Iteration 24, loss = 0.00075056\n",
      "Iteration 24, loss = 0.00112111\n",
      "Iteration 23, loss = 0.00093876\n",
      "Iteration 23, loss = 0.00419292\n",
      "Iteration 24, loss = 0.00252297\n",
      "Iteration 24, loss = 0.00077541\n",
      "Iteration 27, loss = 0.00401153\n",
      "Iteration 25, loss = 0.00055006\n",
      "Iteration 23, loss = 0.00061719\n",
      "Iteration 24, loss = 0.00074864\n",
      "Iteration 25, loss = 0.00270309\n",
      "Iteration 25, loss = 0.00076612\n",
      "Iteration 24, loss = 0.00370872\n",
      "Iteration 26, loss = 0.00023235\n",
      "Iteration 24, loss = 0.00063518\n",
      "Iteration 23, loss = 0.00274731\n",
      "Iteration 25, loss = 0.00123038\n",
      "Iteration 26, loss = 0.00066526\n",
      "Iteration 25, loss = 0.00080210\n",
      "Iteration 28, loss = 0.00431929\n",
      "Iteration 24, loss = 0.00060784\n",
      "Iteration 25, loss = 0.00090495\n",
      "Iteration 26, loss = 0.00083024\n",
      "Iteration 26, loss = 0.00295321\n",
      "Iteration 25, loss = 0.00073269\n",
      "Iteration 24, loss = 0.00255914\n",
      "Iteration 27, loss = 0.00022600\n",
      "Iteration 25, loss = 0.00291078\n",
      "Iteration 26, loss = 0.00102610\n",
      "Iteration 26, loss = 0.00083528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.00067960\n",
      "Iteration 25, loss = 0.00070749\n",
      "Iteration 29, loss = 0.00533056\n",
      "Iteration 28, loss = 0.00022094\n",
      "Iteration 25, loss = 0.00252769\n",
      "Iteration 26, loss = 0.00069300\n",
      "Iteration 26, loss = 0.00265055\n",
      "Iteration 27, loss = 0.00251845\n",
      "Iteration 27, loss = 0.00127825\n",
      "Iteration 26, loss = 0.00119208\n",
      "Iteration 27, loss = 0.00101600\n",
      "Iteration 28, loss = 0.00071359\n",
      "Iteration 23, loss = 0.00274731\n",
      "Iteration 25, loss = 0.00123038\n",
      "Iteration 26, loss = 0.00066526\n",
      "Iteration 25, loss = 0.00080210\n",
      "Iteration 28, loss = 0.00431929\n",
      "Iteration 24, loss = 0.00060784\n",
      "Iteration 25, loss = 0.00090495\n",
      "Iteration 26, loss = 0.00083024\n",
      "Iteration 26, loss = 0.00295321\n",
      "Iteration 25, loss = 0.00073269\n",
      "Iteration 24, loss = 0.00255914\n",
      "Iteration 27, loss = 0.00022600\n",
      "Iteration 25, loss = 0.00291078\n",
      "Iteration 26, loss = 0.00102610\n",
      "Iteration 26, loss = 0.00083528\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.00067960\n",
      "Iteration 25, loss = 0.00070749\n",
      "Iteration 29, loss = 0.00533056\n",
      "Iteration 28, loss = 0.00022094\n",
      "Iteration 25, loss = 0.00252769\n",
      "Iteration 26, loss = 0.00069300\n",
      "Iteration 26, loss = 0.00265055\n",
      "Iteration 27, loss = 0.00251845\n",
      "Iteration 27, loss = 0.00127825\n",
      "Iteration 26, loss = 0.00119208\n",
      "Iteration 27, loss = 0.00101600\n",
      "Iteration 28, loss = 0.00071359\n",
      "Iteration 26, loss = 0.00258418\n",
      "Iteration 29, loss = 0.00021495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.00504568\n",
      "Iteration 27, loss = 0.00070239\n",
      "Iteration 26, loss = 0.00053523\n",
      "Iteration 27, loss = 0.00088196\n",
      "Iteration 28, loss = 0.00201262\n",
      "Iteration 28, loss = 0.00081286\n",
      "Iteration 28, loss = 0.00136358\n",
      "Iteration 27, loss = 0.00282169\n",
      "Iteration 1, loss = 0.62692732\n",
      "Iteration 28, loss = 0.00079370\n",
      "Iteration 29, loss = 0.00053204\n",
      "Iteration 31, loss = 0.00448611\n",
      "Iteration 27, loss = 0.00229360\n",
      "Iteration 27, loss = 0.00052045\n",
      "Iteration 28, loss = 0.00058203\n",
      "Iteration 29, loss = 0.00218634\n",
      "Iteration 29, loss = 0.00076321\n",
      "Iteration 29, loss = 0.00098648\n",
      "Iteration 28, loss = 0.00255748\n",
      "Iteration 28, loss = 0.00245916\n",
      "Iteration 30, loss = 0.00250825\n",
      "Iteration 30, loss = 0.00064072\n",
      "Iteration 29, loss = 0.00058279\n",
      "Iteration 29, loss = 0.00066773\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.00370395\n",
      "Iteration 2, loss = 0.49330487\n",
      "Iteration 1, loss = 0.47339668\n",
      "Iteration 28, loss = 0.00069901\n",
      "Iteration 30, loss = 0.00071873\n",
      "Iteration 30, loss = 0.00107020\n",
      "Iteration 29, loss = 0.00233969\n",
      "Iteration 26, loss = 0.00258418\n",
      "Iteration 29, loss = 0.00021495\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.00504568\n",
      "Iteration 27, loss = 0.00070239\n",
      "Iteration 26, loss = 0.00053523\n",
      "Iteration 27, loss = 0.00088196\n",
      "Iteration 28, loss = 0.00201262\n",
      "Iteration 28, loss = 0.00081286\n",
      "Iteration 28, loss = 0.00136358\n",
      "Iteration 27, loss = 0.00282169\n",
      "Iteration 1, loss = 0.62692732\n",
      "Iteration 28, loss = 0.00079370\n",
      "Iteration 29, loss = 0.00053204\n",
      "Iteration 31, loss = 0.00448611\n",
      "Iteration 27, loss = 0.00229360\n",
      "Iteration 27, loss = 0.00052045\n",
      "Iteration 28, loss = 0.00058203\n",
      "Iteration 29, loss = 0.00218634\n",
      "Iteration 29, loss = 0.00076321\n",
      "Iteration 29, loss = 0.00098648\n",
      "Iteration 28, loss = 0.00255748\n",
      "Iteration 28, loss = 0.00245916\n",
      "Iteration 30, loss = 0.00250825\n",
      "Iteration 30, loss = 0.00064072\n",
      "Iteration 29, loss = 0.00058279\n",
      "Iteration 29, loss = 0.00066773\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.00370395\n",
      "Iteration 2, loss = 0.49330487\n",
      "Iteration 1, loss = 0.47339668\n",
      "Iteration 28, loss = 0.00069901\n",
      "Iteration 30, loss = 0.00071873\n",
      "Iteration 30, loss = 0.00107020\n",
      "Iteration 29, loss = 0.00233969\n",
      "Iteration 29, loss = 0.00270386\n",
      "Iteration 31, loss = 0.00291375\n",
      "Iteration 31, loss = 0.00058767\n",
      "Iteration 30, loss = 0.00082951\n",
      "Iteration 33, loss = 0.00358955\n",
      "Iteration 29, loss = 0.00054517Iteration 3, loss = 0.31885318\n",
      "\n",
      "Iteration 31, loss = 0.00079591\n",
      "Iteration 31, loss = 0.00063518\n",
      "Iteration 30, loss = 0.00252173\n",
      "Iteration 2, loss = 0.17439714\n",
      "Iteration 30, loss = 0.00284811\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.00048165\n",
      "Iteration 32, loss = 0.00222343\n",
      "Iteration 34, loss = 0.00369801\n",
      "Iteration 31, loss = 0.00051649\n",
      "Iteration 4, loss = 0.23051074\n",
      "Iteration 32, loss = 0.00130120\n",
      "Iteration 32, loss = 0.00077151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.47461423\n",
      "Iteration 30, loss = 0.00063256\n",
      "Iteration 33, loss = 0.00046082\n",
      "Iteration 3, loss = 0.14931629\n",
      "Iteration 31, loss = 0.00283496\n",
      "Iteration 33, loss = 0.00204106\n",
      "Iteration 5, loss = 0.18088868\n",
      "Iteration 35, loss = 0.00391307\n",
      "Iteration 32, loss = 0.00098300\n",
      "Iteration 33, loss = 0.00102276\n",
      "Iteration 29, loss = 0.00270386\n",
      "Iteration 31, loss = 0.00291375\n",
      "Iteration 31, loss = 0.00058767\n",
      "Iteration 30, loss = 0.00082951\n",
      "Iteration 33, loss = 0.00358955\n",
      "Iteration 29, loss = 0.00054517Iteration 3, loss = 0.31885318\n",
      "\n",
      "Iteration 31, loss = 0.00079591\n",
      "Iteration 31, loss = 0.00063518\n",
      "Iteration 30, loss = 0.00252173\n",
      "Iteration 2, loss = 0.17439714\n",
      "Iteration 30, loss = 0.00284811\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.00048165\n",
      "Iteration 32, loss = 0.00222343\n",
      "Iteration 34, loss = 0.00369801\n",
      "Iteration 31, loss = 0.00051649\n",
      "Iteration 4, loss = 0.23051074\n",
      "Iteration 32, loss = 0.00130120\n",
      "Iteration 32, loss = 0.00077151\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.47461423\n",
      "Iteration 30, loss = 0.00063256\n",
      "Iteration 33, loss = 0.00046082\n",
      "Iteration 3, loss = 0.14931629\n",
      "Iteration 31, loss = 0.00283496\n",
      "Iteration 33, loss = 0.00204106\n",
      "Iteration 5, loss = 0.18088868\n",
      "Iteration 35, loss = 0.00391307\n",
      "Iteration 32, loss = 0.00098300\n",
      "Iteration 33, loss = 0.00102276\n",
      "Iteration 31, loss = 0.00037046\n",
      "Iteration 2, loss = 0.16575665\n",
      "Iteration 34, loss = 0.00055609\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.12816906\n",
      "Iteration 34, loss = 0.00249094\n",
      "Iteration 32, loss = 0.00290296\n",
      "Iteration 36, loss = 0.00372973\n",
      "Iteration 33, loss = 0.00119598\n",
      "Iteration 1, loss = 0.47487048\n",
      "Iteration 6, loss = 0.12888996\n",
      "Iteration 32, loss = 0.00082401\n",
      "Iteration 34, loss = 0.00099159\n",
      "Iteration 3, loss = 0.13259255\n",
      "Iteration 1, loss = 0.61010358\n",
      "Iteration 5, loss = 0.10583719\n",
      "Iteration 37, loss = 0.00380447\n",
      "Iteration 33, loss = 0.00311240\n",
      "Iteration 35, loss = 0.00290534\n",
      "Iteration 34, loss = 0.00051904\n",
      "Iteration 2, loss = 0.17681126\n",
      "Iteration 4, loss = 0.10571691\n",
      "Iteration 7, loss = 0.07489608\n",
      "Iteration 35, loss = 0.00093164\n",
      "Iteration 33, loss = 0.00059256\n",
      "Iteration 6, loss = 0.08457955\n",
      "Iteration 34, loss = 0.00285455\n",
      "Iteration 2, loss = 0.42797573\n",
      "Iteration 1, loss = 0.45347773\n",
      "Iteration 38, loss = 0.00350025\n",
      "Iteration 31, loss = 0.00037046\n",
      "Iteration 2, loss = 0.16575665\n",
      "Iteration 34, loss = 0.00055609\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 4, loss = 0.12816906\n",
      "Iteration 34, loss = 0.00249094\n",
      "Iteration 32, loss = 0.00290296\n",
      "Iteration 36, loss = 0.00372973\n",
      "Iteration 33, loss = 0.00119598\n",
      "Iteration 1, loss = 0.47487048\n",
      "Iteration 6, loss = 0.12888996\n",
      "Iteration 32, loss = 0.00082401\n",
      "Iteration 34, loss = 0.00099159\n",
      "Iteration 3, loss = 0.13259255\n",
      "Iteration 1, loss = 0.61010358\n",
      "Iteration 5, loss = 0.10583719\n",
      "Iteration 37, loss = 0.00380447\n",
      "Iteration 33, loss = 0.00311240\n",
      "Iteration 35, loss = 0.00290534\n",
      "Iteration 34, loss = 0.00051904\n",
      "Iteration 2, loss = 0.17681126\n",
      "Iteration 4, loss = 0.10571691\n",
      "Iteration 7, loss = 0.07489608\n",
      "Iteration 35, loss = 0.00093164\n",
      "Iteration 33, loss = 0.00059256\n",
      "Iteration 6, loss = 0.08457955\n",
      "Iteration 34, loss = 0.00285455\n",
      "Iteration 2, loss = 0.42797573\n",
      "Iteration 1, loss = 0.45347773\n",
      "Iteration 38, loss = 0.00350025\n",
      "Iteration 35, loss = 0.00076872\n",
      "Iteration 5, loss = 0.08256551\n",
      "Iteration 3, loss = 0.14328695\n",
      "Iteration 34, loss = 0.00056312\n",
      "Iteration 36, loss = 0.00238608\n",
      "Iteration 8, loss = 0.03841876\n",
      "Iteration 35, loss = 0.00264865\n",
      "Iteration 7, loss = 0.06654256\n",
      "Iteration 36, loss = 0.00095231\n",
      "Iteration 4, loss = 0.11351740\n",
      "Iteration 3, loss = 0.19640309\n",
      "Iteration 6, loss = 0.06417937\n",
      "Iteration 39, loss = 0.00334502\n",
      "Iteration 2, loss = 0.09376341\n",
      "Iteration 37, loss = 0.00193494\n",
      "Iteration 36, loss = 0.00287018\n",
      "Iteration 9, loss = 0.01879503\n",
      "Iteration 36, loss = 0.00057620\n",
      "Iteration 4, loss = 0.12227009\n",
      "Iteration 37, loss = 0.00092309\n",
      "Iteration 5, loss = 0.08709410\n",
      "Iteration 8, loss = 0.05017294\n",
      "Iteration 35, loss = 0.00048690\n",
      "Iteration 40, loss = 0.00400348\n",
      "Iteration 38, loss = 0.00229855\n",
      "Iteration 3, loss = 0.07295658\n",
      "Iteration 37, loss = 0.00217161\n",
      "Iteration 7, loss = 0.04717802\n",
      "Iteration 10, loss = 0.01062611\n",
      "Iteration 35, loss = 0.00076872\n",
      "Iteration 5, loss = 0.08256551\n",
      "Iteration 3, loss = 0.14328695\n",
      "Iteration 34, loss = 0.00056312\n",
      "Iteration 36, loss = 0.00238608\n",
      "Iteration 8, loss = 0.03841876\n",
      "Iteration 35, loss = 0.00264865\n",
      "Iteration 7, loss = 0.06654256\n",
      "Iteration 36, loss = 0.00095231\n",
      "Iteration 4, loss = 0.11351740\n",
      "Iteration 3, loss = 0.19640309\n",
      "Iteration 6, loss = 0.06417937\n",
      "Iteration 39, loss = 0.00334502\n",
      "Iteration 2, loss = 0.09376341\n",
      "Iteration 37, loss = 0.00193494\n",
      "Iteration 36, loss = 0.00287018\n",
      "Iteration 9, loss = 0.01879503\n",
      "Iteration 36, loss = 0.00057620\n",
      "Iteration 4, loss = 0.12227009\n",
      "Iteration 37, loss = 0.00092309\n",
      "Iteration 5, loss = 0.08709410\n",
      "Iteration 8, loss = 0.05017294\n",
      "Iteration 35, loss = 0.00048690\n",
      "Iteration 40, loss = 0.00400348\n",
      "Iteration 38, loss = 0.00229855\n",
      "Iteration 3, loss = 0.07295658\n",
      "Iteration 37, loss = 0.00217161\n",
      "Iteration 7, loss = 0.04717802\n",
      "Iteration 10, loss = 0.01062611\n",
      "Iteration 6, loss = 0.06704226\n",
      "Iteration 37, loss = 0.00066199\n",
      "Iteration 38, loss = 0.00099765\n",
      "Iteration 41, loss = 0.00390747\n",
      "Iteration 5, loss = 0.08840949\n",
      "Iteration 36, loss = 0.00053447\n",
      "Iteration 4, loss = 0.06235728\n",
      "Iteration 39, loss = 0.00347514\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.00293323\n",
      "Iteration 9, loss = 0.03438678\n",
      "Iteration 11, loss = 0.00857906\n",
      "Iteration 8, loss = 0.03158085\n",
      "Iteration 7, loss = 0.04880385\n",
      "Iteration 38, loss = 0.00056862\n",
      "Iteration 39, loss = 0.00090077\n",
      "Iteration 42, loss = 0.00333490\n",
      "Iteration 5, loss = 0.05033268\n",
      "Iteration 6, loss = 0.05740973\n",
      "Iteration 39, loss = 0.00532945\n",
      "Iteration 37, loss = 0.00051449\n",
      "Iteration 6, loss = 0.06704226\n",
      "Iteration 37, loss = 0.00066199\n",
      "Iteration 38, loss = 0.00099765\n",
      "Iteration 41, loss = 0.00390747\n",
      "Iteration 5, loss = 0.08840949\n",
      "Iteration 36, loss = 0.00053447\n",
      "Iteration 4, loss = 0.06235728\n",
      "Iteration 39, loss = 0.00347514\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.00293323\n",
      "Iteration 9, loss = 0.03438678\n",
      "Iteration 11, loss = 0.00857906\n",
      "Iteration 8, loss = 0.03158085\n",
      "Iteration 7, loss = 0.04880385\n",
      "Iteration 38, loss = 0.00056862\n",
      "Iteration 39, loss = 0.00090077\n",
      "Iteration 42, loss = 0.00333490\n",
      "Iteration 5, loss = 0.05033268\n",
      "Iteration 6, loss = 0.05740973\n",
      "Iteration 39, loss = 0.00532945\n",
      "Iteration 37, loss = 0.00051449\n",
      "Iteration 10, loss = 0.02071038\n",
      "Iteration 12, loss = 0.00707409\n",
      "Iteration 9, loss = 0.01979298\n",
      "Iteration 39, loss = 0.00057548\n",
      "Iteration 8, loss = 0.03054109\n",
      "Iteration 43, loss = 0.00373577\n",
      "Iteration 6, loss = 0.03932238\n",
      "Iteration 40, loss = 0.00084397\n",
      "Iteration 7, loss = 0.03228017\n",
      "Iteration 38, loss = 0.00058316\n",
      "Iteration 1, loss = 0.45177601\n",
      "Iteration 40, loss = 0.00262057\n",
      "Iteration 11, loss = 0.01250327\n",
      "Iteration 13, loss = 0.00597185\n",
      "Iteration 10, loss = 0.01155391\n",
      "Iteration 40, loss = 0.00047024\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 9, loss = 0.01901380\n",
      "Iteration 7, loss = 0.03034656\n",
      "Iteration 39, loss = 0.00046386\n",
      "Iteration 8, loss = 0.01841158\n",
      "Iteration 41, loss = 0.00098229\n",
      "Iteration 41, loss = 0.00302526\n",
      "Iteration 2, loss = 0.08562600\n",
      "Iteration 44, loss = 0.00417032\n",
      "Iteration 10, loss = 0.02071038\n",
      "Iteration 12, loss = 0.00707409\n",
      "Iteration 9, loss = 0.01979298\n",
      "Iteration 39, loss = 0.00057548\n",
      "Iteration 8, loss = 0.03054109\n",
      "Iteration 43, loss = 0.00373577\n",
      "Iteration 6, loss = 0.03932238\n",
      "Iteration 40, loss = 0.00084397\n",
      "Iteration 7, loss = 0.03228017\n",
      "Iteration 38, loss = 0.00058316\n",
      "Iteration 1, loss = 0.45177601\n",
      "Iteration 40, loss = 0.00262057\n",
      "Iteration 11, loss = 0.01250327\n",
      "Iteration 13, loss = 0.00597185\n",
      "Iteration 10, loss = 0.01155391\n",
      "Iteration 40, loss = 0.00047024\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 9, loss = 0.01901380\n",
      "Iteration 7, loss = 0.03034656\n",
      "Iteration 39, loss = 0.00046386\n",
      "Iteration 8, loss = 0.01841158\n",
      "Iteration 41, loss = 0.00098229\n",
      "Iteration 41, loss = 0.00302526\n",
      "Iteration 2, loss = 0.08562600\n",
      "Iteration 44, loss = 0.00417032\n",
      "Iteration 12, loss = 0.00724562\n",
      "Iteration 14, loss = 0.00579858\n",
      "Iteration 11, loss = 0.00719214\n",
      "Iteration 10, loss = 0.01194647\n",
      "Iteration 8, loss = 0.02296741\n",
      "Iteration 42, loss = 0.00283879\n",
      "Iteration 40, loss = 0.00046857\n",
      "Iteration 45, loss = 0.00435287\n",
      "Iteration 9, loss = 0.00875725\n",
      "Iteration 42, loss = 0.00121601\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.00448752\n",
      "Iteration 3, loss = 0.06557000\n",
      "Iteration 11, loss = 0.00716571\n",
      "Iteration 15, loss = 0.00519250\n",
      "Iteration 12, loss = 0.00521579\n",
      "Iteration 9, loss = 0.01708716\n",
      "Iteration 43, loss = 0.00310286\n",
      "Iteration 46, loss = 0.00381548\n",
      "Iteration 14, loss = 0.00319689\n",
      "Iteration 10, loss = 0.00469684\n",
      "Iteration 41, loss = 0.00054905\n",
      "Iteration 12, loss = 0.00453388\n",
      "Iteration 16, loss = 0.00420321\n",
      "Iteration 4, loss = 0.05480677\n",
      "Iteration 13, loss = 0.00371850\n",
      "Iteration 44, loss = 0.00291630\n",
      "Iteration 10, loss = 0.01112384\n",
      "Iteration 12, loss = 0.00724562\n",
      "Iteration 14, loss = 0.00579858\n",
      "Iteration 11, loss = 0.00719214\n",
      "Iteration 10, loss = 0.01194647\n",
      "Iteration 8, loss = 0.02296741\n",
      "Iteration 42, loss = 0.00283879\n",
      "Iteration 40, loss = 0.00046857\n",
      "Iteration 45, loss = 0.00435287\n",
      "Iteration 9, loss = 0.00875725\n",
      "Iteration 42, loss = 0.00121601\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 0.00448752\n",
      "Iteration 3, loss = 0.06557000\n",
      "Iteration 11, loss = 0.00716571\n",
      "Iteration 15, loss = 0.00519250\n",
      "Iteration 12, loss = 0.00521579\n",
      "Iteration 9, loss = 0.01708716\n",
      "Iteration 43, loss = 0.00310286\n",
      "Iteration 46, loss = 0.00381548\n",
      "Iteration 14, loss = 0.00319689\n",
      "Iteration 10, loss = 0.00469684\n",
      "Iteration 41, loss = 0.00054905\n",
      "Iteration 12, loss = 0.00453388\n",
      "Iteration 16, loss = 0.00420321\n",
      "Iteration 4, loss = 0.05480677\n",
      "Iteration 13, loss = 0.00371850\n",
      "Iteration 44, loss = 0.00291630\n",
      "Iteration 10, loss = 0.01112384\n",
      "Iteration 47, loss = 0.00336320\n",
      "Iteration 15, loss = 0.00258200\n",
      "Iteration 13, loss = 0.00292784\n",
      "Iteration 11, loss = 0.00336341\n",
      "Iteration 42, loss = 0.00073381\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.04566248\n",
      "Iteration 14, loss = 0.00273374\n",
      "Iteration 17, loss = 0.00415023\n",
      "Iteration 11, loss = 0.00610937\n",
      "Iteration 45, loss = 0.00266788\n",
      "Iteration 48, loss = 0.00361622\n",
      "Iteration 14, loss = 0.00211122\n",
      "Iteration 15, loss = 0.00245889\n",
      "Iteration 16, loss = 0.00222203\n",
      "Iteration 6, loss = 0.03736531\n",
      "Iteration 18, loss = 0.00468809\n",
      "Iteration 12, loss = 0.00274308\n",
      "Iteration 12, loss = 0.00271512\n",
      "Iteration 46, loss = 0.00210353\n",
      "Iteration 15, loss = 0.00183053\n",
      "Iteration 17, loss = 0.00160444\n",
      "Iteration 7, loss = 0.03061591\n",
      "Iteration 49, loss = 0.00373626\n",
      "Iteration 16, loss = 0.00203688\n",
      "Iteration 19, loss = 0.00453610\n",
      "Iteration 47, loss = 0.00336320\n",
      "Iteration 15, loss = 0.00258200\n",
      "Iteration 13, loss = 0.00292784\n",
      "Iteration 11, loss = 0.00336341\n",
      "Iteration 42, loss = 0.00073381\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 0.04566248\n",
      "Iteration 14, loss = 0.00273374\n",
      "Iteration 17, loss = 0.00415023\n",
      "Iteration 11, loss = 0.00610937\n",
      "Iteration 45, loss = 0.00266788\n",
      "Iteration 48, loss = 0.00361622\n",
      "Iteration 14, loss = 0.00211122\n",
      "Iteration 15, loss = 0.00245889\n",
      "Iteration 16, loss = 0.00222203\n",
      "Iteration 6, loss = 0.03736531\n",
      "Iteration 18, loss = 0.00468809\n",
      "Iteration 12, loss = 0.00274308\n",
      "Iteration 12, loss = 0.00271512\n",
      "Iteration 46, loss = 0.00210353\n",
      "Iteration 15, loss = 0.00183053\n",
      "Iteration 17, loss = 0.00160444\n",
      "Iteration 7, loss = 0.03061591\n",
      "Iteration 49, loss = 0.00373626\n",
      "Iteration 16, loss = 0.00203688\n",
      "Iteration 19, loss = 0.00453610\n",
      "Iteration 13, loss = 0.00284045\n",
      "Iteration 13, loss = 0.00124721\n",
      "Iteration 47, loss = 0.00271292\n",
      "Iteration 8, loss = 0.02477699\n",
      "Iteration 16, loss = 0.00154514\n",
      "Iteration 17, loss = 0.00167839\n",
      "Iteration 50, loss = 0.00392797\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.00172708\n",
      "Iteration 20, loss = 0.00417807\n",
      "Iteration 14, loss = 0.00216908\n",
      "Iteration 14, loss = 0.00066938\n",
      "Iteration 9, loss = 0.01909320\n",
      "Iteration 48, loss = 0.00258231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.00139457\n",
      "Iteration 17, loss = 0.00132686\n",
      "Iteration 19, loss = 0.00170074\n",
      "Iteration 21, loss = 0.00453147\n",
      "Iteration 15, loss = 0.00046160\n",
      "Iteration 15, loss = 0.00160779\n",
      "Iteration 10, loss = 0.01397725\n",
      "Iteration 19, loss = 0.00122389\n",
      "Iteration 18, loss = 0.00127522\n",
      "Iteration 20, loss = 0.00140428\n",
      "Iteration 22, loss = 0.00417303\n",
      "Iteration 13, loss = 0.00284045\n",
      "Iteration 13, loss = 0.00124721\n",
      "Iteration 47, loss = 0.00271292\n",
      "Iteration 8, loss = 0.02477699\n",
      "Iteration 16, loss = 0.00154514\n",
      "Iteration 17, loss = 0.00167839\n",
      "Iteration 50, loss = 0.00392797\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.00172708\n",
      "Iteration 20, loss = 0.00417807\n",
      "Iteration 14, loss = 0.00216908\n",
      "Iteration 14, loss = 0.00066938\n",
      "Iteration 9, loss = 0.01909320\n",
      "Iteration 48, loss = 0.00258231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.00139457\n",
      "Iteration 17, loss = 0.00132686\n",
      "Iteration 19, loss = 0.00170074\n",
      "Iteration 21, loss = 0.00453147\n",
      "Iteration 15, loss = 0.00046160\n",
      "Iteration 15, loss = 0.00160779\n",
      "Iteration 10, loss = 0.01397725\n",
      "Iteration 19, loss = 0.00122389\n",
      "Iteration 18, loss = 0.00127522\n",
      "Iteration 20, loss = 0.00140428\n",
      "Iteration 22, loss = 0.00417303\n",
      "Iteration 16, loss = 0.00036778\n",
      "Iteration 11, loss = 0.00945694Iteration 16, loss = 0.00218050\n",
      "\n",
      "Iteration 20, loss = 0.00087739\n",
      "Iteration 21, loss = 0.00161110\n",
      "Iteration 19, loss = 0.00111664\n",
      "Iteration 23, loss = 0.00392745\n",
      "Iteration 17, loss = 0.00031157\n",
      "Iteration 17, loss = 0.00170742\n",
      "Iteration 12, loss = 0.00566627\n",
      "Iteration 21, loss = 0.00090831\n",
      "Iteration 22, loss = 0.00152552\n",
      "Iteration 20, loss = 0.00145698\n",
      "Iteration 24, loss = 0.00473200\n",
      "Iteration 18, loss = 0.00027825\n",
      "Iteration 13, loss = 0.00267175\n",
      "Iteration 18, loss = 0.00243172\n",
      "Iteration 22, loss = 0.00102200\n",
      "Iteration 23, loss = 0.00138787\n",
      "Iteration 21, loss = 0.00150440\n",
      "Iteration 25, loss = 0.00408663\n",
      "Iteration 19, loss = 0.00025411\n",
      "Iteration 14, loss = 0.00127874\n",
      "Iteration 19, loss = 0.00162636\n",
      "Iteration 23, loss = 0.00073508\n",
      "Iteration 24, loss = 0.00131631\n",
      "Iteration 16, loss = 0.00036778\n",
      "Iteration 11, loss = 0.00945694Iteration 16, loss = 0.00218050\n",
      "\n",
      "Iteration 20, loss = 0.00087739\n",
      "Iteration 21, loss = 0.00161110\n",
      "Iteration 19, loss = 0.00111664\n",
      "Iteration 23, loss = 0.00392745\n",
      "Iteration 17, loss = 0.00031157\n",
      "Iteration 17, loss = 0.00170742\n",
      "Iteration 12, loss = 0.00566627\n",
      "Iteration 21, loss = 0.00090831\n",
      "Iteration 22, loss = 0.00152552\n",
      "Iteration 20, loss = 0.00145698\n",
      "Iteration 24, loss = 0.00473200\n",
      "Iteration 18, loss = 0.00027825\n",
      "Iteration 13, loss = 0.00267175\n",
      "Iteration 18, loss = 0.00243172\n",
      "Iteration 22, loss = 0.00102200\n",
      "Iteration 23, loss = 0.00138787\n",
      "Iteration 21, loss = 0.00150440\n",
      "Iteration 25, loss = 0.00408663\n",
      "Iteration 19, loss = 0.00025411\n",
      "Iteration 14, loss = 0.00127874\n",
      "Iteration 19, loss = 0.00162636\n",
      "Iteration 23, loss = 0.00073508\n",
      "Iteration 24, loss = 0.00131631\n",
      "Iteration 22, loss = 0.00133697\n",
      "Iteration 26, loss = 0.00448030\n",
      "Iteration 20, loss = 0.00023776\n",
      "Iteration 15, loss = 0.00070950\n",
      "Iteration 20, loss = 0.00135798\n",
      "Iteration 24, loss = 0.00077589\n",
      "Iteration 25, loss = 0.00156753\n",
      "Iteration 27, loss = 0.00477305\n",
      "Iteration 23, loss = 0.00088494\n",
      "Iteration 16, loss = 0.00047372\n",
      "Iteration 21, loss = 0.00022475\n",
      "Iteration 21, loss = 0.00188307\n",
      "Iteration 25, loss = 0.00083071\n",
      "Iteration 26, loss = 0.00136661\n",
      "Iteration 24, loss = 0.00110794\n",
      "Iteration 28, loss = 0.00388910\n",
      "Iteration 17, loss = 0.00037109\n",
      "Iteration 22, loss = 0.00021515\n",
      "Iteration 22, loss = 0.00156065\n",
      "Iteration 26, loss = 0.00084622\n",
      "Iteration 27, loss = 0.00163720\n",
      "Iteration 29, loss = 0.00430849\n",
      "Iteration 25, loss = 0.00088572\n",
      "Iteration 18, loss = 0.00031242\n",
      "Iteration 23, loss = 0.00020707\n",
      "Iteration 23, loss = 0.00150760\n",
      "Iteration 27, loss = 0.00074446\n",
      "Iteration 26, loss = 0.00101517\n",
      "Iteration 28, loss = 0.00143291\n",
      "Iteration 22, loss = 0.00133697\n",
      "Iteration 26, loss = 0.00448030\n",
      "Iteration 20, loss = 0.00023776\n",
      "Iteration 15, loss = 0.00070950\n",
      "Iteration 20, loss = 0.00135798\n",
      "Iteration 24, loss = 0.00077589\n",
      "Iteration 25, loss = 0.00156753\n",
      "Iteration 27, loss = 0.00477305\n",
      "Iteration 23, loss = 0.00088494\n",
      "Iteration 16, loss = 0.00047372\n",
      "Iteration 21, loss = 0.00022475\n",
      "Iteration 21, loss = 0.00188307\n",
      "Iteration 25, loss = 0.00083071\n",
      "Iteration 26, loss = 0.00136661\n",
      "Iteration 24, loss = 0.00110794\n",
      "Iteration 28, loss = 0.00388910\n",
      "Iteration 17, loss = 0.00037109\n",
      "Iteration 22, loss = 0.00021515\n",
      "Iteration 22, loss = 0.00156065\n",
      "Iteration 26, loss = 0.00084622\n",
      "Iteration 27, loss = 0.00163720\n",
      "Iteration 29, loss = 0.00430849\n",
      "Iteration 25, loss = 0.00088572\n",
      "Iteration 18, loss = 0.00031242\n",
      "Iteration 23, loss = 0.00020707\n",
      "Iteration 23, loss = 0.00150760\n",
      "Iteration 27, loss = 0.00074446\n",
      "Iteration 26, loss = 0.00101517\n",
      "Iteration 28, loss = 0.00143291\n",
      "Iteration 30, loss = 0.00465651\n",
      "Iteration 19, loss = 0.00027575\n",
      "Iteration 24, loss = 0.00020032\n",
      "Iteration 24, loss = 0.00144175\n",
      "Iteration 28, loss = 0.00072046\n",
      "Iteration 27, loss = 0.00116335\n",
      "Iteration 29, loss = 0.00122356\n",
      "Iteration 20, loss = 0.00025154\n",
      "Iteration 31, loss = 0.00313952\n",
      "Iteration 25, loss = 0.00019455\n",
      "Iteration 25, loss = 0.00146851\n",
      "Iteration 29, loss = 0.00058365\n",
      "Iteration 28, loss = 0.00132175\n",
      "Iteration 30, loss = 0.00131931\n",
      "Iteration 21, loss = 0.00023465\n",
      "Iteration 32, loss = 0.00354692\n",
      "Iteration 26, loss = 0.00018971\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 0.00200570\n",
      "Iteration 30, loss = 0.00058409\n",
      "Iteration 29, loss = 0.00097531\n",
      "Iteration 22, loss = 0.00022114\n",
      "Iteration 31, loss = 0.00175096\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.00380968\n",
      "Iteration 27, loss = 0.00173968\n",
      "Iteration 31, loss = 0.00067870\n",
      "Iteration 30, loss = 0.00465651\n",
      "Iteration 19, loss = 0.00027575\n",
      "Iteration 24, loss = 0.00020032\n",
      "Iteration 24, loss = 0.00144175\n",
      "Iteration 28, loss = 0.00072046\n",
      "Iteration 27, loss = 0.00116335\n",
      "Iteration 29, loss = 0.00122356\n",
      "Iteration 20, loss = 0.00025154\n",
      "Iteration 31, loss = 0.00313952\n",
      "Iteration 25, loss = 0.00019455\n",
      "Iteration 25, loss = 0.00146851\n",
      "Iteration 29, loss = 0.00058365\n",
      "Iteration 28, loss = 0.00132175\n",
      "Iteration 30, loss = 0.00131931\n",
      "Iteration 21, loss = 0.00023465\n",
      "Iteration 32, loss = 0.00354692\n",
      "Iteration 26, loss = 0.00018971\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 0.00200570\n",
      "Iteration 30, loss = 0.00058409\n",
      "Iteration 29, loss = 0.00097531\n",
      "Iteration 22, loss = 0.00022114\n",
      "Iteration 31, loss = 0.00175096\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.00380968\n",
      "Iteration 27, loss = 0.00173968\n",
      "Iteration 31, loss = 0.00067870\n",
      "Iteration 30, loss = 0.00098693\n",
      "Iteration 23, loss = 0.00021085\n",
      "Iteration 34, loss = 0.00332385\n",
      "Iteration 32, loss = 0.00081450\n",
      "Iteration 28, loss = 0.00191230\n",
      "Iteration 31, loss = 0.00085436\n",
      "Iteration 24, loss = 0.00020329\n",
      "Iteration 35, loss = 0.00375199\n",
      "Iteration 33, loss = 0.00050983\n",
      "Iteration 29, loss = 0.00143176\n",
      "Iteration 25, loss = 0.00019661\n",
      "Iteration 32, loss = 0.00098359\n",
      "Iteration 36, loss = 0.00378019\n",
      "Iteration 34, loss = 0.00064838\n",
      "Iteration 30, loss = 0.00145504\n",
      "Iteration 26, loss = 0.00019140\n",
      "Iteration 33, loss = 0.00091898\n",
      "Iteration 37, loss = 0.00426701\n",
      "Iteration 35, loss = 0.00063814\n",
      "Iteration 31, loss = 0.00123834\n",
      "Iteration 27, loss = 0.00018694\n",
      "Iteration 34, loss = 0.00118345\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.00408658\n",
      "Iteration 30, loss = 0.00098693\n",
      "Iteration 23, loss = 0.00021085\n",
      "Iteration 34, loss = 0.00332385\n",
      "Iteration 32, loss = 0.00081450\n",
      "Iteration 28, loss = 0.00191230\n",
      "Iteration 31, loss = 0.00085436\n",
      "Iteration 24, loss = 0.00020329\n",
      "Iteration 35, loss = 0.00375199\n",
      "Iteration 33, loss = 0.00050983\n",
      "Iteration 29, loss = 0.00143176\n",
      "Iteration 25, loss = 0.00019661\n",
      "Iteration 32, loss = 0.00098359\n",
      "Iteration 36, loss = 0.00378019\n",
      "Iteration 34, loss = 0.00064838\n",
      "Iteration 30, loss = 0.00145504\n",
      "Iteration 26, loss = 0.00019140\n",
      "Iteration 33, loss = 0.00091898\n",
      "Iteration 37, loss = 0.00426701\n",
      "Iteration 35, loss = 0.00063814\n",
      "Iteration 31, loss = 0.00123834\n",
      "Iteration 27, loss = 0.00018694\n",
      "Iteration 34, loss = 0.00118345\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.00408658\n",
      "Iteration 36, loss = 0.00056417\n",
      "Iteration 28, loss = 0.00018299\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.00132239\n",
      "Iteration 39, loss = 0.00388884\n",
      "Iteration 37, loss = 0.00051333\n",
      "Iteration 33, loss = 0.00128426\n",
      "Iteration 40, loss = 0.00345518\n",
      "Iteration 38, loss = 0.00063905\n",
      "Iteration 34, loss = 0.00126712\n",
      "Iteration 41, loss = 0.00402211\n",
      "Iteration 39, loss = 0.00073330\n",
      "Iteration 35, loss = 0.00107558\n",
      "Iteration 42, loss = 0.00396227\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.00054735\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 0.00137960\n",
      "Iteration 36, loss = 0.00056417\n",
      "Iteration 28, loss = 0.00018299\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.00132239\n",
      "Iteration 39, loss = 0.00388884\n",
      "Iteration 37, loss = 0.00051333\n",
      "Iteration 33, loss = 0.00128426\n",
      "Iteration 40, loss = 0.00345518\n",
      "Iteration 38, loss = 0.00063905\n",
      "Iteration 34, loss = 0.00126712\n",
      "Iteration 41, loss = 0.00402211\n",
      "Iteration 39, loss = 0.00073330\n",
      "Iteration 35, loss = 0.00107558\n",
      "Iteration 42, loss = 0.00396227\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.00054735\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 0.00137960\n",
      "Iteration 37, loss = 0.00127665\n",
      "Iteration 38, loss = 0.00146651\n",
      "Iteration 39, loss = 0.00098054\n",
      "Iteration 40, loss = 0.00145363\n",
      "Iteration 41, loss = 0.00102338\n",
      "Iteration 37, loss = 0.00127665\n",
      "Iteration 38, loss = 0.00146651\n",
      "Iteration 39, loss = 0.00098054\n",
      "Iteration 40, loss = 0.00145363\n",
      "Iteration 41, loss = 0.00102338\n",
      "Iteration 42, loss = 0.00133458\n",
      "Iteration 43, loss = 0.00125722\n",
      "Iteration 44, loss = 0.00101503\n",
      "Iteration 45, loss = 0.00179748\n",
      "Iteration 46, loss = 0.00137720\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "✓ Training completed in 7.35 seconds\n",
      "✓ 19/19 classifiers converged before max_iter\n",
      "Iteration 42, loss = 0.00133458\n",
      "Iteration 43, loss = 0.00125722\n",
      "Iteration 44, loss = 0.00101503\n",
      "Iteration 45, loss = 0.00179748\n",
      "Iteration 46, loss = 0.00137720\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "✓ Training completed in 7.35 seconds\n",
      "✓ 19/19 classifiers converged before max_iter\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "training_time = time. time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Check convergence\n",
    "converged = sum(1 for est in mlp_classifier.estimators_ if est.n_iter_ < est.max_iter)\n",
    "print(f\"✓ {converged}/{NUM_CLASSES} classifiers converged before max_iter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.  Model Evaluation\n",
    "\n",
    "Evaluate on both validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATION SET METRICS\n",
      "============================================================\n",
      "Subset Accuracy     : 0.3670\n",
      "Hamming Loss        : 0.0591\n",
      "Micro F1            : 0.5703\n",
      "Macro F1            : 0.1952\n",
      "Weighted F1         : 0.5257\n",
      "Micro Precision     : 0.6863\n",
      "Micro Recall        : 0.4878\n",
      "\n",
      "============================================================\n",
      "TEST SET METRICS\n",
      "============================================================\n",
      "Subset Accuracy     : 0.3258\n",
      "Hamming Loss        : 0.0662\n",
      "Micro F1            : 0.5222\n",
      "Macro F1            : 0.2797\n",
      "Weighted F1         : 0.4941\n",
      "Micro Precision     : 0.6355\n",
      "Micro Recall        : 0.4432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    hamming_loss, classification_report\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_val = mlp_classifier.predict(X_val)\n",
    "y_pred_test = mlp_classifier.predict(X_test)\n",
    "\n",
    "def evaluate(y_true, y_pred, split_name):\n",
    "    \"\"\"Print evaluation metrics for a given split.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{split_name. upper()} SET METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Subset Accuracy':<20}: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"{'Hamming Loss':<20}: {hamming_loss(y_true, y_pred):.4f}\")\n",
    "    print(f\"{'Micro F1':<20}: {f1_score(y_true, y_pred, average='micro', zero_division=0):.4f}\")\n",
    "    print(f\"{'Macro F1':<20}: {f1_score(y_true, y_pred, average='macro', zero_division=0):.4f}\")\n",
    "    print(f\"{'Weighted F1':<20}: {f1_score(y_true, y_pred, average='weighted', zero_division=0):.4f}\")\n",
    "    print(f\"{'Micro Precision':<20}: {precision_score(y_true, y_pred, average='micro', zero_division=0):.4f}\")\n",
    "    print(f\"{'Micro Recall':<20}: {recall_score(y_true, y_pred, average='micro', zero_division=0):.4f}\")\n",
    "\n",
    "# Evaluate on validation set (for model selection)\n",
    "evaluate(y_val, y_pred_val, \"Validation\")\n",
    "\n",
    "# Evaluate on test set (final performance)\n",
    "evaluate(y_test, y_pred_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PER-CLASS PERFORMANCE (Test Set)\n",
      "============================================================\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "          arts_&_culture       0.33      0.08      0.13        48\n",
      "business_&_entrepreneurs       0.45      0.29      0.36        78\n",
      " celebrity_&_pop_culture       0.35      0.27      0.30       245\n",
      "    diaries_&_daily_life       0.26      0.10      0.14       149\n",
      "                  family       0.67      0.31      0.43        32\n",
      "         fashion_&_style       0.28      0.16      0.20        32\n",
      "         film_tv_&_video       0.63      0.36      0.45       298\n",
      "        fitness_&_health       0.45      0.25      0.32        56\n",
      "           food_&_dining       0.00      0.00      0.00        15\n",
      "                  gaming       0.33      0.18      0.24        77\n",
      "  learning_&_educational       0.14      0.03      0.06        29\n",
      "                   music       0.82      0.71      0.76       380\n",
      "   news_&_social_concern       0.59      0.44      0.50       327\n",
      "           other_hobbies       0.25      0.14      0.18        81\n",
      "           relationships       0.17      0.03      0.05        61\n",
      "    science_&_technology       0.54      0.17      0.26        88\n",
      "                  sports       0.83      0.78      0.80       582\n",
      "      travel_&_adventure       0.00      0.00      0.00        15\n",
      "    youth_&_student_life       0.20      0.09      0.12        11\n",
      "\n",
      "               micro avg       0.64      0.44      0.52      2604\n",
      "               macro avg       0.38      0.23      0.28      2604\n",
      "            weighted avg       0.58      0.44      0.49      2604\n",
      "             samples avg       0.56      0.51      0.51      2604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Per-class performance on test set\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PER-CLASS PERFORMANCE (Test Set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, y_pred_test,\n",
    "    target_names=TOPIC_LABELS,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize per-class F1 scores\n",
    "per_class_f1 = f1_score(y_test, y_pred_test, average=None, zero_division=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bars = ax.barh(TOPIC_LABELS, per_class_f1, color='steelblue')\n",
    "ax.set_xlabel('F1 Score')\n",
    "ax.set_title('Per-Class F1 Scores (Test Set)')\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "for bar, score in zip(bars, per_class_f1):\n",
    "    ax.text(bar. get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
    "            f'{score:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt. tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Architecture Comparison\n",
    "\n",
    "Compare different hidden layer configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARCHITECTURE COMPARISON\n",
      "============================================================\n",
      "\n",
      "Training: (64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Micro F1: 0.5547, Macro F1: 0.2164, Time: 4.6s\n",
      "\n",
      "Training: (128, 64)\n",
      "  Val Micro F1: 0.5703, Macro F1: 0.1978, Time: 6.2s\n",
      "\n",
      "Training: (128, 64, 128)\n",
      "  Val Micro F1: 0.5703, Macro F1: 0.1952, Time: 5.9s\n",
      "\n",
      "Training: (256, 128, 64)\n",
      "  Val Micro F1: 0.5527, Macro F1: 0.1866, Time: 16.3s\n",
      "\n",
      "============================================================\n",
      "SUMMARY (Validation Set)\n",
      "============================================================\n",
      "  Architecture  Micro F1  Macro F1  Train Time (s)\n",
      "         (64,)  0.554745  0.216378        4.629758\n",
      "     (128, 64)  0.570265  0.197755        6.219684\n",
      "(128, 64, 128)  0.570265  0.195167        5.919004\n",
      "(256, 128, 64)  0.552743  0.186636       16.253324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1102698a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10a4618a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x110eb98a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1092718a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10603d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10876d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1057d58a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1118318a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1076158a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106e158a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1080d58a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1051c98a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "architectures = [\n",
    "    (64,),               # Single layer\n",
    "    (128, 64),           # Two layers\n",
    "    (128, 64, 128),      # Three layers (baseline)\n",
    "    (256, 128, 64),      # Wider first layer\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHITECTURE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for arch in architectures:\n",
    "    print(f\"\\nTraining: {arch}\")\n",
    "    \n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=arch,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        alpha=0.0001,\n",
    "        learning_rate='adaptive',\n",
    "        max_iter=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    clf = MultiOutputClassifier(mlp, n_jobs=-1)\n",
    "    \n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time. time() - start\n",
    "    \n",
    "    # Evaluate on VALIDATION set (for model selection)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    f1_micro = f1_score(y_val, y_pred, average='micro', zero_division=0)\n",
    "    f1_macro = f1_score(y_val, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    results.append({\n",
    "        'Architecture': str(arch),\n",
    "        'Micro F1': f1_micro,\n",
    "        'Macro F1': f1_macro,\n",
    "        'Train Time (s)': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"  Val Micro F1: {f1_micro:.4f}, Macro F1: {f1_macro:.4f}, Time: {train_time:.1f}s\")\n",
    "\n",
    "results_df = pd. DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY (Validation Set)\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x = range(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "axes[0]. bar([i - width/2 for i in x], results_df['Micro F1'], width, label='Micro F1', color='steelblue')\n",
    "axes[0].bar([i + width/2 for i in x], results_df['Macro F1'], width, label='Macro F1', color='coral')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(results_df['Architecture'], rotation=45, ha='right')\n",
    "axes[0].set_ylabel('F1 Score')\n",
    "axes[0].set_title('F1 Scores by Architecture (Validation Set)')\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "axes[1].bar(x, results_df['Train Time (s)'], color='seagreen')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1]. set_xticklabels(results_df['Architecture'], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Training Time (seconds)')\n",
    "axes[1].set_title('Training Time by Architecture')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_to_labels(binary_vec):\n",
    "    \"\"\"Convert binary vector to label names.\"\"\"\n",
    "    return [TOPIC_LABELS[i] for i, val in enumerate(binary_vec) if val == 1] or ['[none]']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAMPLE PREDICTIONS (Test Set)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "sample_idx = np.random. choice(len(df_test), size=10, replace=False)\n",
    "\n",
    "for idx in sample_idx:\n",
    "    text = df_test['text'].iloc[idx]\n",
    "    true = binary_to_labels(y_test[idx])\n",
    "    pred = binary_to_labels(y_pred_test[idx])\n",
    "    \n",
    "    match = \"✓\" if set(true) == set(pred) else \"✗\"\n",
    "    \n",
    "    print(f\"\\n{match} Sample {idx}:\")\n",
    "    print(f\"   Text: {str(text)[:80]}...\")\n",
    "    print(f\"   True: {true}\")\n",
    "    print(f\"   Pred: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Conclusion\n",
    "\n",
    "### 8.1 Summary\n",
    "We built an MLP neural network with the specified 128-64-128 architecture for multi-label tweet classification.\n",
    "\n",
    "### 8.2 Key Design Decisions\n",
    "- **Top 1000 Vocabulary from Lab 4**: Reusing the vocabulary ensures consistency across the pipeline\n",
    "- **No early_stopping**: We use HuggingFace's `validation_2021` split for model selection and `test_2021` for final evaluation\n",
    "- **MultiOutputClassifier wrapper**: Handles multi-label by training 19 independent binary classifiers\n",
    "- **TF-IDF features**: Captures term importance relative to the corpus\n",
    "\n",
    "### 8.3 Pipeline Overview\n",
    "```\n",
    "Lab 2: Raw tweets → Preprocessing → tweets_preprocessed_train. parquet\n",
    "Lab 3: Preprocessed tweets → Language Models (Unigram/Bigram)\n",
    "Lab 4: Preprocessed tweets → Top 1000 Vocabulary → top_1000_vocabulary.json\n",
    "Lab 5: Preprocessed tweets + Top 1000 Vocabulary → Neural Network → Predictions\n",
    "```\n",
    "\n",
    "### 8.4 Limitations of scikit-learn's MLP\n",
    "- No GPU acceleration\n",
    "- No dropout or batch normalization\n",
    "- Limited to fully-connected layers\n",
    "\n",
    "### 8.5 Next Steps\n",
    "- Tune regularization (alpha parameter)\n",
    "- Try different activation functions\n",
    "- Consider deep learning frameworks (PyTorch/TensorFlow) for more flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "test_f1_micro = f1_score(y_test, y_pred_test, average='micro', zero_division=0)\n",
    "test_f1_macro = f1_score(y_test, y_pred_test, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Vocabulary: {VOCABULARY_PATH} ({len(TOP_VOCABULARY)} tokens from Lab 4)\")\n",
    "print(f\"Architecture: Input({X_train.shape[1]}) → 128 → 64 → 128 → Output({NUM_CLASSES})\")\n",
    "print(f\"Training samples: {len(y_train):,}\")\n",
    "print(f\"Validation samples: {len(y_val):,}\")\n",
    "print(f\"Test samples: {len(y_test):,}\")\n",
    "print(f\"Test Micro F1: {test_f1_micro:.4f}\")\n",
    "print(f\"Test Macro F1: {test_f1_macro:. 4f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}