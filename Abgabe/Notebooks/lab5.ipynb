{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e50a659",
   "metadata": {},
   "source": [
    "# Lab 5: Neural Network Classification with scikit-learn\n",
    "\n",
    "---\n",
    "## 1. Notebook Overview\n",
    "\n",
    "### 1.1 Objective\n",
    "- Re-use the most frequent words (optional: per class) you found for\n",
    "your Naive Bayes classifier last week.\n",
    "\n",
    "- Construct binary vectors for your whole dataset. Each dimension states\n",
    "whether the word is part of the sample or not.\n",
    "\n",
    "- Create a small neural network using scikit-learn: https://scikit-learn.org/\n",
    "stable/modules/neural_networks_supervised.html. Start with three\n",
    "hidden layers of 128/64/128 neurons. Consider what your input and\n",
    "output layers should look like.\n",
    "\n",
    "- Train your network on your training set and test it on your test set.\n",
    "Calculate evaluation measures and compare with your previous\n",
    "classifier.\n",
    "\n",
    "- Optional: Experiment with different network sizes.\n",
    "\n",
    "### 1.2 Prerequisites\n",
    "This notebook assumes you have already executed:\n",
    "- **Lab 2**: Data preprocessing ‚Üí `../Data/multi_label/tweets_preprocessed_*.parquet`\n",
    "- **Lab 3**: Language modeling\n",
    "- **Lab 4**: Feature extraction ‚Üí `../Data/top_1000_vocabulary.json`\n",
    "- **Single-Label**: `../Data/single_label/tweets_single_label_*.parquet`\n",
    "\n",
    "### 1.3 Architecture\n",
    "We implement neural networks with:\n",
    "- **Input layer**: 1000 features (Top 1000 vocabulary from Lab 4)\n",
    "- **Hidden layers**: 128 ‚Üí 64 ‚Üí 128 neurons (as specified)\n",
    "- **Output layer**: \n",
    "  - Multi-label: 14 binary classifiers (one per topic class, using OneVsRestClassifier)\n",
    "  - Single-label: 14 classes with Softmax activation\n",
    "\n",
    "### 1.4 Neural Network Fundamentals (From Lecture)\n",
    "- A single neuron computes: ≈∑ = g(w‚ÇÄ + Œ£ x·µ¢w·µ¢) where g is a non-linear activation function\n",
    "- **Activation functions are critical** - they introduce non-linearities that make multi-layer networks powerful (universal approximators)\n",
    "- Common activations: ReLU (g(z) = max(0,z)), Sigmoid, Tanh\n",
    "- For multi-class (single-label): use **Softmax** to convert outputs to probabilities\n",
    "- For multi-label: use **Sigmoid** per class via OneVsRestClassifier\n",
    "- **Loss function for classification**: Cross-entropy loss\n",
    "- Weights should NOT be initialized to all zeros (breaks symmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Task 1: Establish Context\n",
    "\n",
    "### 2.1 Review Preprocessing from Lab 2\n",
    "In Lab 2, we preprocessed tweets with the following pipeline:\n",
    "- Remove RT indicators, URLs, usernames, and mentions\n",
    "- Convert emojis to text descriptions\n",
    "- Extract hashtag text and segment CamelCase words\n",
    "- Normalize whitespace and lowercase\n",
    "- Tokenize with SpaCy and filter/lemmatize tokens\n",
    "\n",
    "The output is stored in parquet files with columns: `text`, `label_name`, `label`\n",
    "\n",
    "Two approaches for label handling are supported:\n",
    "- Parse `label_name` (string list format) into Python lists\n",
    "- Use `label` column directly (pre-computed binary vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import hashlib\n",
    "import time\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    hamming_loss,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants - Updated paths to new folder structure\n",
    "TRAIN_DATA_PATH = \"../Data/multi_label/tweets_preprocessed_train.parquet\"\n",
    "TEST_DATA_PATH = \"../Data/multi_label/tweets_preprocessed_test.parquet\"\n",
    "VALIDATION_DATA_PATH = \"../Data/multi_label/tweets_preprocessed_validation.parquet\"\n",
    "VOCABULARY_PATH = \"../Data/top_1000_vocabulary.json\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_vocab_section",
   "metadata": {},
   "source": [
    "### 2.2 Load and Verify Vocabulary from Lab 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "load_vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded vocabulary from: ../Data/top_1000_vocabulary.json\n",
      "‚úì Description: Top 1000 most frequent tokens from preprocessed tweets (Lab 4)\n",
      "‚úì Vocabulary size: 1000\n",
      "‚úì First 20 tokens: ['new', 'game', 'day', 'good', 'year', 'love', 'time', 'win', 'come', 'happy', 'like', 'watch', 'go', 'world', 'live', 'today', 'red', 'team', 'great', 'heart']\n",
      "‚úì Last 10 tokens: ['straight', 'google', 'december', 'thankful', 'oklahoma', 'donald', 'army', 'beverage', 'education', 'titan']\n"
     ]
    }
   ],
   "source": [
    "# Load the top 1000 vocabulary from Lab 4\n",
    "with open(VOCABULARY_PATH, 'r', encoding='utf-8') as f:\n",
    "    vocab_data = json.load(f)\n",
    "\n",
    "VOCABULARY = vocab_data['tokens']\n",
    "vocab_set = set(VOCABULARY)\n",
    "\n",
    "print(f\"‚úì Loaded vocabulary from: {VOCABULARY_PATH}\")\n",
    "print(f\"‚úì Description: {vocab_data['description']}\")\n",
    "print(f\"‚úì Vocabulary size: {len(VOCABULARY)}\")\n",
    "print(f\"‚úì First 20 tokens: {VOCABULARY[:20]}\")\n",
    "print(f\"‚úì Last 10 tokens: {VOCABULARY[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data_section",
   "metadata": {},
   "source": [
    "### 2.3 Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "load_datasets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MULTI-LABEL DATASETS LADEN\n",
      "======================================================================\n",
      "‚úì Training set: 5,465 samples\n",
      "‚úì Test set: 1,511 samples\n",
      "‚úì Validation set: 178 samples\n",
      "\n",
      "Sample preprocessed text:\n",
      "  lumber beat rapid game western division final evan edwards hit hr wp josh robers...\n",
      "  Labels: ['sports']\n"
     ]
    }
   ],
   "source": [
    "def parse_labels(value) -> List[str]:\n",
    "    \"\"\"Parse label_name column into consistent Python lists.\"\"\"\n",
    "    if isinstance(value, (list, np.ndarray)):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, tuple):\n",
    "        return [str(v) for v in value]\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        if value.startswith('[') and value.endswith(']'):\n",
    "            # Remove brackets\n",
    "            inner = value[1:-1].strip()\n",
    "            if not inner:\n",
    "                return []\n",
    "            # Remove quotes and split by whitespace (handles both formats)\n",
    "            inner = inner.replace(\"'\", \"\").replace('\"', '')\n",
    "            labels = [l.strip() for l in inner.split() if l.strip()]\n",
    "            return labels\n",
    "        try:\n",
    "            parsed = ast.literal_eval(value)\n",
    "            if isinstance(parsed, (list, tuple)):\n",
    "                return [str(v) for v in parsed]\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass\n",
    "        return [value] if value else []\n",
    "    return [str(value)] if value else []\n",
    "\n",
    "def parse_binary_label(value) -> np.ndarray:\n",
    "    \"\"\"Parse binary label array from string representation.\"\"\"\n",
    "    if isinstance(value, np.ndarray):\n",
    "        return value\n",
    "    if isinstance(value, str):\n",
    "        # Parse \"[0 0 1 0 ...]\" format\n",
    "        inner = value.strip()[1:-1]\n",
    "        return np.array([int(x) for x in inner.split()])\n",
    "    return np.array(value)\n",
    "\n",
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load tweets from parquet and normalize the label columns.\"\"\"\n",
    "    df = pd.read_parquet(path)\n",
    "    df = df.copy()\n",
    "    df[\"labels\"] = df[\"label_name\"].apply(parse_labels)\n",
    "    df[\"label_binary\"] = df[\"label\"].apply(parse_binary_label)\n",
    "    return df\n",
    "\n",
    "# ============================================================\n",
    "# MULTI-LABEL DATASETS LADEN\n",
    "# ============================================================\n",
    "# Diese werden f√ºr Multi-Label NN, Naive Bayes Training und f√ºr\n",
    "# die Multi-Label Evaluation ALLER Modelle verwendet.\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MULTI-LABEL DATASETS LADEN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df_train_multi = load_dataset(TRAIN_DATA_PATH)\n",
    "df_test_multi = load_dataset(TEST_DATA_PATH)\n",
    "df_validation_multi = load_dataset(VALIDATION_DATA_PATH)\n",
    "\n",
    "print(f\"‚úì Training set: {len(df_train_multi):,} samples\")\n",
    "print(f\"‚úì Test set: {len(df_test_multi):,} samples\")\n",
    "print(f\"‚úì Validation set: {len(df_validation_multi):,} samples\")\n",
    "print(f\"\\nSample preprocessed text:\")\n",
    "print(f\"  {df_train_multi['text'].iloc[0][:80]}...\")\n",
    "print(f\"  Labels: {df_train_multi['labels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "b3de7689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AUTOMATISCHE KLASSEN-ERKENNUNG\n",
      "============================================================\n",
      "\n",
      "‚úì Anzahl Klassen (aus label_binary): 6\n",
      "‚úì Klassennamen aus Daten extrahiert: 6\n",
      "‚úì Klassen: ['celebrity_&_pop_culture', 'diaries_&_daily_life', 'film_tv_&_video', 'music', 'news_&_social_concern', 'sports']\n",
      "\n",
      "‚úì Beispiel-Daten:\n",
      "  Text: lumber beat rapid game western division final evan edwards h...\n",
      "  Labels (Namen): ['sports']\n",
      "  Labels (Bin√§r): [0 0 0 0 0 1]\n",
      "\n",
      "‚úì Dataset-Statistiken:\n",
      "  Training: 5,465 Samples\n",
      "  Test: 1,511 Samples\n",
      "  Validation: 178 Samples\n",
      "  Gesamt: 7,154 Samples\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# DYNAMISCHE KLASSEN-ERKENNUNG AUS DEN MULTI-LABEL DATEN\n",
    "# ============================================================\n",
    "# Diese Zelle passt sich automatisch an die Daten an, \n",
    "# unabh√§ngig davon wie viele Klassen nach dem Preprocessing √ºbrig sind.\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"AUTOMATISCHE KLASSEN-ERKENNUNG\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Bestimme die Anzahl der Klassen aus den bin√§ren Label-Vektoren\n",
    "num_classes = len(df_train_multi['label_binary'].iloc[0])\n",
    "print(f\"\\n‚úì Anzahl Klassen (aus label_binary): {num_classes}\")\n",
    "\n",
    "# 2. Extrahiere alle einzigartigen Klassennamen aus label_name\n",
    "all_class_names = set()\n",
    "for df in [df_train_multi, df_test_multi, df_validation_multi]:\n",
    "    for labels in df['labels']:\n",
    "        all_class_names.update(labels)\n",
    "\n",
    "TOPIC_CLASSES = sorted(list(all_class_names))\n",
    "print(f\"‚úì Klassennamen aus Daten extrahiert: {len(TOPIC_CLASSES)}\")\n",
    "print(f\"‚úì Klassen: {TOPIC_CLASSES}\")\n",
    "\n",
    "# 3. Verifiziere Konsistenz\n",
    "if len(TOPIC_CLASSES) != num_classes:\n",
    "    print(f\"\\n‚ö†Ô∏è WARNUNG: Anzahl Klassennamen ({len(TOPIC_CLASSES)}) != Anzahl Spalten in label_binary ({num_classes})\")\n",
    "    print(\"   Das kann passieren wenn label_name und label nicht synchron sind.\")\n",
    "    print(\"   Verwende Anzahl aus label_binary als ma√ügeblich.\")\n",
    "    \n",
    "# 4. Zeige Beispiel-Daten\n",
    "print(f\"\\n‚úì Beispiel-Daten:\")\n",
    "print(f\"  Text: {df_train_multi['text'].iloc[0][:60]}...\")\n",
    "print(f\"  Labels (Namen): {df_train_multi['labels'].iloc[0]}\")\n",
    "print(f\"  Labels (Bin√§r): {df_train_multi['label_binary'].iloc[0]}\")\n",
    "\n",
    "# 5. Statistiken\n",
    "print(f\"\\n‚úì Dataset-Statistiken:\")\n",
    "print(f\"  Training: {len(df_train_multi):,} Samples\")\n",
    "print(f\"  Test: {len(df_test_multi):,} Samples\")\n",
    "print(f\"  Validation: {len(df_validation_multi):,} Samples\")\n",
    "print(f\"  Gesamt: {len(df_train_multi) + len(df_test_multi) + len(df_validation_multi):,} Samples\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_conversion_section",
   "metadata": {},
   "source": [
    "### 2.4 Load Single-Label Datasets (from Lab 2)\n",
    "\n",
    "The single-label datasets were created in **Lab 2** using Claude Haiku for intelligent label assignment.\n",
    "We simply load them here for use in the Single-Label Neural Network classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "c604b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SINGLE-LABEL DATEN LADEN (aus Lab 2)\n",
      "======================================================================\n",
      "\n",
      "üìÇ Lade Single-Label Dateien...\n",
      "‚úì Training Set: 5,465 Samples\n",
      "‚úì Test Set: 1,511 Samples\n",
      "‚úì Validation Set: 178 Samples\n",
      "\n",
      "‚úì Single-Label Verteilung (Training):\n",
      "single_label\n",
      "sports                      1587\n",
      "news_&_social_concern       1487\n",
      "music                       1000\n",
      "diaries_&_daily_life         553\n",
      "film_tv_&_video              502\n",
      "celebrity_&_pop_culture      281\n",
      "family                         9\n",
      "arts_&_culture                 9\n",
      "gaming                         7\n",
      "business_&_entrepreneurs       6\n",
      "science_&_technology           5\n",
      "relationships                  5\n",
      "food_&_dining                  4\n",
      "youth_&_student_life           3\n",
      "other_hobbies                  3\n",
      "fitness_&_health               2\n",
      "learning_&_educational         1\n",
      "fashion_&_style                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "‚úì Single-Label Daten geladen!\n",
      "======================================================================\n",
      "\n",
      "üìä Datenstruktur-√úbersicht:\n",
      "  MULTI-LABEL Daten (f√ºr Multi-Label NN, Naive Bayes, Testing):\n",
      "    df_train_multi:      5,465 Samples\n",
      "    df_test_multi:       1,511 Samples\n",
      "    df_validation_multi: 178 Samples\n",
      "\n",
      "  SINGLE-LABEL Daten (NUR f√ºr Single-Label NN Training):\n",
      "    df_train_single:      5,465 Samples\n",
      "    df_test_single:       1,511 Samples\n",
      "    df_validation_single: 178 Samples\n",
      "\n",
      "üí° Die Single-Label Zuweisung erfolgte in Lab 2 mit Claude Haiku\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL DATEN LADEN (aus Lab 2)\n",
    "# ============================================================\n",
    "# Die Single-Label Datasets wurden in Lab 2 mit Claude Haiku erstellt.\n",
    "# Diese werden NUR f√ºr das Training des Single-Label NN verwendet.\n",
    "# Zum TESTEN werden Multi-Label UND Single-Label Test-Sets verwendet.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Definiere Pfade\n",
    "SINGLE_LABEL_TRAIN_PATH = \"../Data/single_label/tweets_single_label_train.parquet\"\n",
    "SINGLE_LABEL_TEST_PATH = \"../Data/single_label/tweets_single_label_test.parquet\"\n",
    "SINGLE_LABEL_VALIDATION_PATH = \"../Data/single_label/tweets_single_label_validation.parquet\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SINGLE-LABEL DATEN LADEN (aus Lab 2)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Pr√ºfe ob alle Dateien existieren\n",
    "train_exists = Path(SINGLE_LABEL_TRAIN_PATH).exists()\n",
    "test_exists = Path(SINGLE_LABEL_TEST_PATH).exists()\n",
    "val_exists = Path(SINGLE_LABEL_VALIDATION_PATH).exists()\n",
    "\n",
    "if not (train_exists and test_exists and val_exists):\n",
    "    missing = []\n",
    "    if not train_exists: missing.append(\"train\")\n",
    "    if not test_exists: missing.append(\"test\")\n",
    "    if not val_exists: missing.append(\"validation\")\n",
    "    print(f\"\\n‚ùå FEHLER: Single-Label Dateien nicht gefunden: {missing}\")\n",
    "    print(\"   Bitte zuerst Lab 2 ausf√ºhren um die Single-Label Datasets zu erstellen!\")\n",
    "    raise FileNotFoundError(\"Single-Label Datasets m√ºssen zuerst in Lab 2 erstellt werden.\")\n",
    "\n",
    "# Lade Single-Label Datasets (SEPARATE Variablen - nicht √ºberschreiben!)\n",
    "print(\"\\nüìÇ Lade Single-Label Dateien...\")\n",
    "\n",
    "df_train_single = pd.read_parquet(SINGLE_LABEL_TRAIN_PATH)\n",
    "df_test_single = pd.read_parquet(SINGLE_LABEL_TEST_PATH)\n",
    "df_validation_single = pd.read_parquet(SINGLE_LABEL_VALIDATION_PATH)\n",
    "\n",
    "# Parse labels falls n√∂tig (f√ºr Kompatibilit√§t mit bestehendem Code)\n",
    "for df in [df_train_single, df_test_single, df_validation_single]:\n",
    "    if 'labels' not in df.columns and 'label_name' in df.columns:\n",
    "        df['labels'] = df['label_name'].apply(parse_labels)\n",
    "\n",
    "print(f\"‚úì Training Set: {len(df_train_single):,} Samples\")\n",
    "print(f\"‚úì Test Set: {len(df_test_single):,} Samples\")\n",
    "print(f\"‚úì Validation Set: {len(df_validation_single):,} Samples\")\n",
    "\n",
    "# Zeige Single-Label Verteilung\n",
    "print(f\"\\n‚úì Single-Label Verteilung (Training):\")\n",
    "print(df_train_single['single_label'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úì Single-Label Daten geladen!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Datenstruktur-√úbersicht:\")\n",
    "print(f\"  MULTI-LABEL Daten (f√ºr Multi-Label NN, Naive Bayes, Testing):\")\n",
    "print(f\"    df_train_multi:      {len(df_train_multi):,} Samples\")\n",
    "print(f\"    df_test_multi:       {len(df_test_multi):,} Samples\")\n",
    "print(f\"    df_validation_multi: {len(df_validation_multi):,} Samples\")\n",
    "print(f\"\\n  SINGLE-LABEL Daten (NUR f√ºr Single-Label NN Training):\")\n",
    "print(f\"    df_train_single:      {len(df_train_single):,} Samples\")\n",
    "print(f\"    df_test_single:       {len(df_test_single):,} Samples\")\n",
    "print(f\"    df_validation_single: {len(df_validation_single):,} Samples\")\n",
    "print(f\"\\nüí° Die Single-Label Zuweisung erfolgte in Lab 2 mit Claude Haiku\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plan_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Task 2: Implementation Plan\n",
    "\n",
    "### 3.1 Binary Feature Vector Construction\n",
    "For each sample, we create a binary vector of size 1000 (vocabulary size):\n",
    "- For each word in the vocabulary, set dimension to 1 if word is present in sample, 0 otherwise\n",
    "- This is a Bag-of-Words style encoding (word order is lost)\n",
    "\n",
    "### 3.2 MLPClassifier Configuration\n",
    "- **hidden_layer_sizes**: (128, 64, 128) - three hidden layers as specified\n",
    "- **activation**: 'relu' - ReLU activation (most commonly used)\n",
    "- **solver**: 'adam' - Adam optimizer (handles mini-batch gradient descent)\n",
    "- **max_iter**: 300 - sufficient iterations for convergence\n",
    "- **random_state**: 42 - for reproducibility\n",
    "- **early_stopping**: Disabled for multi-label (some classes have few samples), enabled for single-label\n",
    "\n",
    "### 3.3 Evaluation Metrics\n",
    "For multi-label classification:\n",
    "- Subset Accuracy (exact match)\n",
    "- Hamming Loss\n",
    "- Micro/Macro F1-Score\n",
    "\n",
    "For single-label classification:\n",
    "- Accuracy\n",
    "- Macro/Weighted F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementation_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Task 3: Multi-Label Classification\n",
    "\n",
    "### 4.1 Feature Engineering: Binary Vector Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE EXTRACTION\n",
      "======================================================================\n",
      "\n",
      "üìä MULTI-LABEL Features (aus df_train_multi, df_test_multi, df_validation_multi):\n",
      "  X_train_multi: (5465, 1000)\n",
      "  X_test_multi: (1511, 1000)\n",
      "  X_validation_multi: (178, 1000)\n",
      "  Average features per sample: 7.71\n",
      "\n",
      "  X_train_bow_multi (Count): (5465, 1000)\n",
      "  X_test_bow_multi (Count): (1511, 1000)\n",
      "\n",
      "üìä SINGLE-LABEL Features (aus df_train_single, df_test_single, df_validation_single):\n",
      "  X_train_single: (5465, 1000)\n",
      "  X_test_single: (1511, 1000)\n",
      "  X_validation_single: (178, 1000)\n",
      "  Average features per sample: 7.71\n",
      "\n",
      "======================================================================\n",
      "‚úì Feature Extraction abgeschlossen!\n",
      "======================================================================\n",
      "\n",
      "üìã √úbersicht:\n",
      "  Multi-Label NN:    X_train_multi (bin√§r)     ‚Üí Training\n",
      "  Naive Bayes:       X_train_bow_multi (count) ‚Üí Training\n",
      "  Single-Label NN:   X_train_single (bin√§r)    ‚Üí Training\n",
      "\n",
      "  Testing (Multi-Label):  X_test_multi\n",
      "  Testing (Single-Label): X_test_single\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_binary_features(texts: pd.Series, vocabulary: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create binary feature vectors for text samples.\n",
    "    \n",
    "    Each dimension represents whether a word from the vocabulary\n",
    "    is present (1) or absent (0) in the sample.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    texts : pd.Series\n",
    "        Series of preprocessed text strings (whitespace-tokenized)\n",
    "    vocabulary : List[str]\n",
    "        List of vocabulary words (top 1000 from Lab 4)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Binary feature matrix of shape (n_samples, vocab_size)\n",
    "    \"\"\"\n",
    "    vocab_set = set(vocabulary)\n",
    "    vocab_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "    \n",
    "    n_samples = len(texts)\n",
    "    n_features = len(vocabulary)\n",
    "    \n",
    "    # Initialize feature matrix with zeros\n",
    "    features = np.zeros((n_samples, n_features), dtype=np.int8)\n",
    "    \n",
    "    # Fill in binary features\n",
    "    for i, text in enumerate(texts):\n",
    "        if isinstance(text, str):\n",
    "            words = set(text.split())\n",
    "            for word in words:\n",
    "                if word in vocab_to_idx:\n",
    "                    features[i, vocab_to_idx[word]] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE EXTRACTION: Separate Feature-Sets f√ºr Multi-Label und Single-Label\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE EXTRACTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================\n",
    "# 1. MULTI-LABEL Features (f√ºr Multi-Label NN, Naive Bayes, Testing)\n",
    "# ============================================================\n",
    "print(\"\\nüìä MULTI-LABEL Features (aus df_train_multi, df_test_multi, df_validation_multi):\")\n",
    "\n",
    "# Bin√§re Features f√ºr Multi-Label Neural Network\n",
    "X_train_multi = create_binary_features(df_train_multi['text'], VOCABULARY)\n",
    "X_test_multi = create_binary_features(df_test_multi['text'], VOCABULARY)\n",
    "X_validation_multi = create_binary_features(df_validation_multi['text'], VOCABULARY)\n",
    "\n",
    "print(f\"  X_train_multi: {X_train_multi.shape}\")\n",
    "print(f\"  X_test_multi: {X_test_multi.shape}\")\n",
    "print(f\"  X_validation_multi: {X_validation_multi.shape}\")\n",
    "print(f\"  Average features per sample: {X_train_multi.sum(axis=1).mean():.2f}\")\n",
    "\n",
    "# Count Features f√ºr Naive Bayes (wie in Lab 4)\n",
    "vectorizer_multi = CountVectorizer(\n",
    "    vocabulary=VOCABULARY,\n",
    "    lowercase=True,\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\"\n",
    ")\n",
    "\n",
    "X_train_bow_multi = vectorizer_multi.fit_transform(df_train_multi['text'])\n",
    "X_test_bow_multi = vectorizer_multi.transform(df_test_multi['text'])\n",
    "X_validation_bow_multi = vectorizer_multi.transform(df_validation_multi['text'])\n",
    "\n",
    "print(f\"\\n  X_train_bow_multi (Count): {X_train_bow_multi.shape}\")\n",
    "print(f\"  X_test_bow_multi (Count): {X_test_bow_multi.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. SINGLE-LABEL Features (NUR f√ºr Single-Label NN Training)\n",
    "# ============================================================\n",
    "print(\"\\nüìä SINGLE-LABEL Features (aus df_train_single, df_test_single, df_validation_single):\")\n",
    "\n",
    "# Bin√§re Features f√ºr Single-Label Neural Network\n",
    "X_train_single = create_binary_features(df_train_single['text'], VOCABULARY)\n",
    "X_test_single = create_binary_features(df_test_single['text'], VOCABULARY)\n",
    "X_validation_single = create_binary_features(df_validation_single['text'], VOCABULARY)\n",
    "\n",
    "print(f\"  X_train_single: {X_train_single.shape}\")\n",
    "print(f\"  X_test_single: {X_test_single.shape}\")\n",
    "print(f\"  X_validation_single: {X_validation_single.shape}\")\n",
    "print(f\"  Average features per sample: {X_train_single.sum(axis=1).mean():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì Feature Extraction abgeschlossen!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìã √úbersicht:\")\n",
    "print(\"  Multi-Label NN:    X_train_multi (bin√§r)     ‚Üí Training\")\n",
    "print(\"  Naive Bayes:       X_train_bow_multi (count) ‚Üí Training\")\n",
    "print(\"  Single-Label NN:   X_train_single (bin√§r)    ‚Üí Training\")\n",
    "print(\"\\n  Testing (Multi-Label):  X_test_multi\")\n",
    "print(\"  Testing (Single-Label): X_test_single\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "label_encoding_section",
   "metadata": {},
   "source": [
    "### 4.2 Label Encoding (Multi-Label Binarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "label_encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Anzahl Klassen: 6\n",
      "‚úì Klassennamen: ['celebrity_&_pop_culture', 'diaries_&_daily_life', 'film_tv_&_video', 'music', 'news_&_social_concern', 'sports']\n",
      "\n",
      "‚úì Multi-Label Matrix Shapes (aus Multi-Label Daten):\n",
      "  y_train_multi: (5465, 6)\n",
      "  y_test_multi: (1511, 6)\n",
      "  y_validation_multi: (178, 6)\n",
      "\n",
      "‚úì Label-Verteilung (Training Multi-Label):\n",
      "  Durchschnitt Labels pro Sample: 1.34\n",
      "  Samples pro Klasse:\n",
      "    celebrity_&_pop_culture: 924\n",
      "    diaries_&_daily_life: 866\n",
      "    film_tv_&_video: 953\n",
      "    music: 1131\n",
      "    news_&_social_concern: 1782\n",
      "    sports: 1683\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MULTI-LABEL ENCODING (aus Multi-Label Daten)\n",
    "# ============================================================\n",
    "\n",
    "# Verwende die vorbereiteten bin√§ren Labels aus Multi-Label Daten\n",
    "y_train_multi = np.vstack(df_train_multi['label_binary'].values)\n",
    "y_test_multi = np.vstack(df_test_multi['label_binary'].values)\n",
    "y_validation_multi = np.vstack(df_validation_multi['label_binary'].values)\n",
    "\n",
    "# Bestimme die tats√§chliche Anzahl der Klassen aus den Daten\n",
    "NUM_CLASSES = y_train_multi.shape[1]\n",
    "\n",
    "# Erstelle MultiLabelBinarizer f√ºr inverse_transform\n",
    "# Wenn TOPIC_CLASSES nicht die richtige L√§nge hat, erstelle generische Namen\n",
    "if len(TOPIC_CLASSES) != NUM_CLASSES:\n",
    "    print(f\"‚ö†Ô∏è TOPIC_CLASSES hat {len(TOPIC_CLASSES)} Eintr√§ge, aber Daten haben {NUM_CLASSES} Klassen\")\n",
    "    print(\"   Erstelle generische Klassennamen...\")\n",
    "    TOPIC_CLASSES = [f\"class_{i}\" for i in range(NUM_CLASSES)]\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=TOPIC_CLASSES)\n",
    "mlb.fit([TOPIC_CLASSES])\n",
    "\n",
    "print(f\"‚úì Anzahl Klassen: {NUM_CLASSES}\")\n",
    "print(f\"‚úì Klassennamen: {TOPIC_CLASSES}\")\n",
    "print(f\"\\n‚úì Multi-Label Matrix Shapes (aus Multi-Label Daten):\")\n",
    "print(f\"  y_train_multi: {y_train_multi.shape}\")\n",
    "print(f\"  y_test_multi: {y_test_multi.shape}\")\n",
    "print(f\"  y_validation_multi: {y_validation_multi.shape}\")\n",
    "\n",
    "# Label-Verteilung\n",
    "print(f\"\\n‚úì Label-Verteilung (Training Multi-Label):\")\n",
    "print(f\"  Durchschnitt Labels pro Sample: {y_train_multi.sum(axis=1).mean():.2f}\")\n",
    "print(f\"  Samples pro Klasse:\")\n",
    "for i, class_name in enumerate(TOPIC_CLASSES):\n",
    "    count = y_train_multi[:, i].sum()\n",
    "    print(f\"    {class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f92f1e1",
   "metadata": {},
   "source": [
    "### 4.2.1 Single-Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b8e05ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Unbekannte Labels gefunden: {'arts_&_culture', 'youth_&_student_life', 'science_&_technology', 'fitness_&_health', 'family', 'learning_&_educational', 'fashion_&_style', 'gaming', 'food_&_dining', 'business_&_entrepreneurs', 'relationships', 'other_hobbies'}\n",
      "   F√ºge sie zu TOPIC_CLASSES hinzu...\n",
      "‚úì Single-label encoding complete (aus Single-Label Daten)\n",
      "\n",
      "‚úì Label shapes:\n",
      "  y_train_single_enc: (5465,)\n",
      "  y_test_single_enc: (1511,)\n",
      "  y_validation_single_enc: (178,)\n",
      "\n",
      "‚úì Class mapping (dynamisch erkannt):\n",
      "  0: arts_&_culture (9 samples)\n",
      "  1: business_&_entrepreneurs (6 samples)\n",
      "  2: celebrity_&_pop_culture (281 samples)\n",
      "  3: diaries_&_daily_life (553 samples)\n",
      "  4: family (9 samples)\n",
      "  5: fashion_&_style (1 samples)\n",
      "  6: film_tv_&_video (502 samples)\n",
      "  7: fitness_&_health (2 samples)\n",
      "  8: food_&_dining (4 samples)\n",
      "  9: gaming (7 samples)\n",
      "  10: learning_&_educational (1 samples)\n",
      "  11: music (1000 samples)\n",
      "  12: news_&_social_concern (1487 samples)\n",
      "  13: other_hobbies (3 samples)\n",
      "  14: relationships (5 samples)\n",
      "  15: science_&_technology (5 samples)\n",
      "  16: sports (1587 samples)\n",
      "  17: youth_&_student_life (3 samples)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL ENCODING (aus Single-Label Daten f√ºr Single-Label NN)\n",
    "# ============================================================\n",
    "# Verwende die in Lab 2 mit Claude Haiku erstellten Single-Labels\n",
    "\n",
    "# Verwende die dynamisch erkannten TOPIC_CLASSES\n",
    "# Stelle sicher, dass alle Labels in TOPIC_CLASSES vorkommen\n",
    "unique_single_labels = set(df_train_single['single_label'].unique()) | \\\n",
    "                       set(df_test_single['single_label'].unique()) | \\\n",
    "                       set(df_validation_single['single_label'].unique())\n",
    "\n",
    "# Pr√ºfe ob alle Labels bekannt sind\n",
    "unknown_labels = unique_single_labels - set(TOPIC_CLASSES)\n",
    "if unknown_labels:\n",
    "    print(f\"‚ö†Ô∏è Unbekannte Labels gefunden: {unknown_labels}\")\n",
    "    print(f\"   F√ºge sie zu TOPIC_CLASSES hinzu...\")\n",
    "    TOPIC_CLASSES = sorted(list(set(TOPIC_CLASSES) | unknown_labels))\n",
    "\n",
    "# Create label encoder for single-label classification\n",
    "le = LabelEncoder()\n",
    "le.fit(TOPIC_CLASSES)\n",
    "\n",
    "# Encode single labels as integers (aus Single-Label Daten)\n",
    "y_train_single_enc = le.transform(df_train_single['single_label'])\n",
    "y_test_single_enc = le.transform(df_test_single['single_label'])\n",
    "y_validation_single_enc = le.transform(df_validation_single['single_label'])\n",
    "\n",
    "print(f\"‚úì Single-label encoding complete (aus Single-Label Daten)\")\n",
    "print(f\"\\n‚úì Label shapes:\")\n",
    "print(f\"  y_train_single_enc: {y_train_single_enc.shape}\")\n",
    "print(f\"  y_test_single_enc: {y_test_single_enc.shape}\")\n",
    "print(f\"  y_validation_single_enc: {y_validation_single_enc.shape}\")\n",
    "\n",
    "print(f\"\\n‚úì Class mapping (dynamisch erkannt):\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    count = (y_train_single_enc == i).sum()\n",
    "    print(f\"  {i}: {cls} ({count} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_training_section",
   "metadata": {},
   "source": [
    "### 4.3 Multi-Label Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "train_neural_network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MULTI-LABEL NEURAL NETWORK ARCHITECTURE\n",
      "============================================================\n",
      "Input layer:  1000 neurons (vocabulary size)\n",
      "Hidden layer 1: 128 neurons (ReLU activation)\n",
      "Hidden layer 2: 64 neurons (ReLU activation)\n",
      "Hidden layer 3: 128 neurons (ReLU activation)\n",
      "Output layer: 18 neurons (18 binary classifiers)\n",
      "============================================================\n",
      "\n",
      "üìä Training auf MULTI-LABEL Daten:\n",
      "   X_train_multi: (5465, 1000)\n",
      "   y_train_multi: (5465, 6)\n",
      "\n",
      "Training Multi-Label Neural Network...\n",
      "Iteration 1, loss = 0.53642916\n",
      "Iteration 1, loss = 0.55208228\n",
      "Iteration 1, loss = 0.63143498\n",
      "Iteration 1, loss = 0.54292549\n",
      "Iteration 1, loss = 0.60748537\n",
      "Iteration 1, loss = 0.53747628\n",
      "Iteration 2, loss = 0.38432390\n",
      "Iteration 2, loss = 0.42907287\n",
      "Iteration 2, loss = 0.35055481\n",
      "Iteration 2, loss = 0.40901103\n",
      "Iteration 2, loss = 0.38086755\n",
      "Iteration 2, loss = 0.32566156\n",
      "Iteration 3, loss = 0.29974619\n",
      "Iteration 3, loss = 0.21221044\n",
      "Iteration 3, loss = 0.25179557\n",
      "Iteration 3, loss = 0.30495521\n",
      "Iteration 3, loss = 0.35494303\n",
      "Iteration 3, loss = 0.13805326\n",
      "Iteration 4, loss = 0.23095439\n",
      "Iteration 4, loss = 0.12212557\n",
      "Iteration 4, loss = 0.16645057\n",
      "Iteration 4, loss = 0.23111976\n",
      "Iteration 4, loss = 0.07519624\n",
      "Iteration 4, loss = 0.29963092\n",
      "Iteration 5, loss = 0.15707695\n",
      "Iteration 5, loss = 0.07153667\n",
      "Iteration 5, loss = 0.10835669\n",
      "Iteration 5, loss = 0.23361070\n",
      "Iteration 5, loss = 0.15612054\n",
      "Iteration 5, loss = 0.04401920\n",
      "Iteration 6, loss = 0.09902838\n",
      "Iteration 6, loss = 0.04000113\n",
      "Iteration 6, loss = 0.06124100\n",
      "Iteration 6, loss = 0.15794983\n",
      "Iteration 6, loss = 0.08963353\n",
      "Iteration 6, loss = 0.02293293\n",
      "Iteration 7, loss = 0.05678483\n",
      "Iteration 7, loss = 0.02254005\n",
      "Iteration 7, loss = 0.03283718\n",
      "Iteration 7, loss = 0.09121425\n",
      "Iteration 7, loss = 0.04301037\n",
      "Iteration 7, loss = 0.01257358\n",
      "Iteration 8, loss = 0.01421779\n",
      "Iteration 8, loss = 0.03213472\n",
      "Iteration 8, loss = 0.01999757\n",
      "Iteration 8, loss = 0.04873702\n",
      "Iteration 8, loss = 0.02134561\n",
      "Iteration 8, loss = 0.00713051\n",
      "Iteration 9, loss = 0.01003356\n",
      "Iteration 9, loss = 0.02019666\n",
      "Iteration 9, loss = 0.01205974\n",
      "Iteration 9, loss = 0.01283946\n",
      "Iteration 9, loss = 0.02530764\n",
      "Iteration 9, loss = 0.00433006\n",
      "Iteration 10, loss = 0.00767154\n",
      "Iteration 10, loss = 0.01444450\n",
      "Iteration 10, loss = 0.00674643\n",
      "Iteration 10, loss = 0.00981629\n",
      "Iteration 10, loss = 0.01534809\n",
      "Iteration 10, loss = 0.00304410\n",
      "Iteration 11, loss = 0.00618656\n",
      "Iteration 11, loss = 0.01112167\n",
      "Iteration 11, loss = 0.00697522\n",
      "Iteration 11, loss = 0.00527866\n",
      "Iteration 11, loss = 0.01213663\n",
      "Iteration 11, loss = 0.00273568\n",
      "Iteration 12, loss = 0.00553972\n",
      "Iteration 12, loss = 0.00716521\n",
      "Iteration 12, loss = 0.00623889\n",
      "Iteration 12, loss = 0.00437313\n",
      "Iteration 12, loss = 0.00996435\n",
      "Iteration 12, loss = 0.00272165\n",
      "Iteration 13, loss = 0.00504773\n",
      "Iteration 13, loss = 0.00558577\n",
      "Iteration 13, loss = 0.00505192\n",
      "Iteration 13, loss = 0.00361515\n",
      "Iteration 13, loss = 0.00838808\n",
      "Iteration 13, loss = 0.00215508\n",
      "Iteration 14, loss = 0.00461463\n",
      "Iteration 14, loss = 0.00622238\n",
      "Iteration 14, loss = 0.00549540\n",
      "Iteration 14, loss = 0.00690570\n",
      "Iteration 14, loss = 0.00412744\n",
      "Iteration 14, loss = 0.00235846\n",
      "Iteration 15, loss = 0.00401524\n",
      "Iteration 15, loss = 0.00507896\n",
      "Iteration 15, loss = 0.00478205\n",
      "Iteration 15, loss = 0.00402061\n",
      "Iteration 15, loss = 0.00642331\n",
      "Iteration 15, loss = 0.00222703\n",
      "Iteration 16, loss = 0.00374594\n",
      "Iteration 16, loss = 0.00488023\n",
      "Iteration 16, loss = 0.00451816\n",
      "Iteration 16, loss = 0.00304105\n",
      "Iteration 16, loss = 0.00774320\n",
      "Iteration 16, loss = 0.00346733\n",
      "Iteration 17, loss = 0.00407038\n",
      "Iteration 17, loss = 0.00432574\n",
      "Iteration 17, loss = 0.00327073\n",
      "Iteration 17, loss = 0.00461762\n",
      "Iteration 17, loss = 0.00672782\n",
      "Iteration 17, loss = 0.00227428\n",
      "Iteration 18, loss = 0.00334601\n",
      "Iteration 18, loss = 0.00384680\n",
      "Iteration 18, loss = 0.00500191\n",
      "Iteration 18, loss = 0.00671027\n",
      "Iteration 18, loss = 0.00722505\n",
      "Iteration 18, loss = 0.00164601\n",
      "Iteration 19, loss = 0.00321880\n",
      "Iteration 19, loss = 0.00451384\n",
      "Iteration 19, loss = 0.00283068\n",
      "Iteration 19, loss = 0.00688004\n",
      "Iteration 19, loss = 0.00804374\n",
      "Iteration 19, loss = 0.00170124\n",
      "Iteration 20, loss = 0.00294591\n",
      "Iteration 20, loss = 0.00377803\n",
      "Iteration 20, loss = 0.00247722\n",
      "Iteration 20, loss = 0.00675413\n",
      "Iteration 20, loss = 0.00448957\n",
      "Iteration 20, loss = 0.00131627\n",
      "Iteration 21, loss = 0.00284044\n",
      "Iteration 21, loss = 0.00371400\n",
      "Iteration 21, loss = 0.00374427\n",
      "Iteration 21, loss = 0.00584027\n",
      "Iteration 21, loss = 0.00414857\n",
      "Iteration 21, loss = 0.00165368\n",
      "Iteration 22, loss = 0.00276537\n",
      "Iteration 22, loss = 0.00235396\n",
      "Iteration 22, loss = 0.00399317\n",
      "Iteration 22, loss = 0.00176804\n",
      "Iteration 22, loss = 0.00518579\n",
      "Iteration 22, loss = 0.00595366\n",
      "Iteration 23, loss = 0.00333662\n",
      "Iteration 23, loss = 0.00311468\n",
      "Iteration 23, loss = 0.00415808\n",
      "Iteration 23, loss = 0.00161525\n",
      "Iteration 23, loss = 0.00391060\n",
      "Iteration 23, loss = 0.00618279\n",
      "Iteration 24, loss = 0.00271485\n",
      "Iteration 24, loss = 0.00272232\n",
      "Iteration 24, loss = 0.00338793\n",
      "Iteration 24, loss = 0.00171476\n",
      "Iteration 24, loss = 0.00550094\n",
      "Iteration 24, loss = 0.00403553\n",
      "Iteration 25, loss = 0.00254704\n",
      "Iteration 25, loss = 0.00273257\n",
      "Iteration 25, loss = 0.00141692\n",
      "Iteration 25, loss = 0.00345691\n",
      "Iteration 25, loss = 0.00560953\n",
      "Iteration 25, loss = 0.00385277\n",
      "Iteration 26, loss = 0.00293632\n",
      "Iteration 26, loss = 0.00300513\n",
      "Iteration 26, loss = 0.00171114\n",
      "Iteration 26, loss = 0.00343781\n",
      "Iteration 26, loss = 0.00463537\n",
      "Iteration 26, loss = 0.00511996\n",
      "Iteration 27, loss = 0.00250766\n",
      "Iteration 27, loss = 0.00256463\n",
      "Iteration 27, loss = 0.00253852\n",
      "Iteration 27, loss = 0.00347227\n",
      "Iteration 27, loss = 0.00436733\n",
      "Iteration 27, loss = 0.00559249\n",
      "Iteration 28, loss = 0.00246955\n",
      "Iteration 28, loss = 0.00244334\n",
      "Iteration 28, loss = 0.00180554\n",
      "Iteration 28, loss = 0.00426518\n",
      "Iteration 28, loss = 0.00414929\n",
      "Iteration 28, loss = 0.00523395\n",
      "Iteration 29, loss = 0.00247912\n",
      "Iteration 29, loss = 0.00306535\n",
      "Iteration 29, loss = 0.00187316\n",
      "Iteration 29, loss = 0.00373935\n",
      "Iteration 29, loss = 0.00314835\n",
      "Iteration 29, loss = 0.00548025\n",
      "Iteration 30, loss = 0.00260255\n",
      "Iteration 30, loss = 0.00268535\n",
      "Iteration 30, loss = 0.00139226\n",
      "Iteration 30, loss = 0.00328527\n",
      "Iteration 30, loss = 0.00389394\n",
      "Iteration 30, loss = 0.00580614\n",
      "Iteration 31, loss = 0.00386290\n",
      "Iteration 31, loss = 0.00384630\n",
      "Iteration 31, loss = 0.00301500\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 31, loss = 0.00350200\n",
      "Iteration 31, loss = 0.00332489\n",
      "Iteration 31, loss = 0.00542726\n",
      "Iteration 32, loss = 0.00322583\n",
      "Iteration 32, loss = 0.00290457\n",
      "Iteration 32, loss = 0.00344849\n",
      "Iteration 32, loss = 0.00384031\n",
      "Iteration 32, loss = 0.00534412\n",
      "Iteration 33, loss = 0.00345351\n",
      "Iteration 33, loss = 0.00240511\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.00335986\n",
      "Iteration 33, loss = 0.00318710\n",
      "Iteration 33, loss = 0.00545369\n",
      "Iteration 34, loss = 0.00250423\n",
      "Iteration 34, loss = 0.00350832\n",
      "Iteration 34, loss = 0.00342495\n",
      "Iteration 34, loss = 0.00743361\n",
      "Iteration 35, loss = 0.00279819\n",
      "Iteration 35, loss = 0.00503783\n",
      "Iteration 35, loss = 0.00429154\n",
      "Iteration 35, loss = 0.00651106\n",
      "Iteration 36, loss = 0.00256209\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 0.00439501\n",
      "Iteration 36, loss = 0.00288635\n",
      "Iteration 36, loss = 0.00540154\n",
      "Iteration 37, loss = 0.00327304\n",
      "Iteration 37, loss = 0.00313203\n",
      "Iteration 37, loss = 0.00540280\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.00348347\n",
      "Iteration 38, loss = 0.00352250\n",
      "Iteration 39, loss = 0.00314348\n",
      "Iteration 39, loss = 0.00316409\n",
      "Iteration 40, loss = 0.00357167\n",
      "Iteration 40, loss = 0.00321525\n",
      "Iteration 41, loss = 0.00359264\n",
      "Iteration 41, loss = 0.00353764\n",
      "Iteration 42, loss = 0.00345707\n",
      "Iteration 42, loss = 0.00358867\n",
      "Iteration 43, loss = 0.00351306\n",
      "Iteration 43, loss = 0.00366560\n",
      "Iteration 44, loss = 0.00344155\n",
      "Iteration 44, loss = 0.00301244\n",
      "Iteration 45, loss = 0.00324470\n",
      "Iteration 45, loss = 0.00342613\n",
      "Iteration 46, loss = 0.00301216\n",
      "Iteration 46, loss = 0.00305668\n",
      "Iteration 47, loss = 0.00325541\n",
      "Iteration 47, loss = 0.00315788\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 48, loss = 0.00326947\n",
      "Iteration 49, loss = 0.00338554\n",
      "Iteration 50, loss = 0.00305819\n",
      "Iteration 51, loss = 0.00354807\n",
      "Iteration 52, loss = 0.00294543\n",
      "Iteration 53, loss = 0.00281890\n",
      "Iteration 54, loss = 0.00283660\n",
      "Iteration 55, loss = 0.00295871\n",
      "Iteration 56, loss = 0.00317178\n",
      "Iteration 57, loss = 0.00302263\n",
      "Iteration 58, loss = 0.00305698\n",
      "Iteration 59, loss = 0.00286024\n",
      "Iteration 60, loss = 0.00306107\n",
      "Iteration 61, loss = 0.00276303\n",
      "Iteration 62, loss = 0.00306738\n",
      "Iteration 63, loss = 0.00283186\n",
      "Iteration 64, loss = 0.00277652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "‚úì Multi-Label Neural Network training complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MULTI-LABEL NEURAL NETWORK TRAINING\n",
    "# ============================================================\n",
    "# Trainiert auf Multi-Label Daten (X_train_multi, y_train_multi)\n",
    "\n",
    "# Create MLPClassifier with specified architecture\n",
    "# Using OneVsRestClassifier for multi-label classification\n",
    "mlp_base = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Three hidden layers as specified\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer (mini-batch gradient descent)\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=False,                # Disabled for multi-label compatibility\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "# Wrap with OneVsRestClassifier for multi-label support\n",
    "mlp_clf_multi = OneVsRestClassifier(mlp_base, n_jobs=-1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-LABEL NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train_multi.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(TOPIC_CLASSES)} neurons ({len(TOPIC_CLASSES)} binary classifiers)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Training auf MULTI-LABEL Daten:\")\n",
    "print(f\"   X_train_multi: {X_train_multi.shape}\")\n",
    "print(f\"   y_train_multi: {y_train_multi.shape}\")\n",
    "\n",
    "print(\"\\nTraining Multi-Label Neural Network...\")\n",
    "mlp_clf_multi.fit(X_train_multi, y_train_multi)\n",
    "print(\"\\n‚úì Multi-Label Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 4.4 Multi-Label Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "evaluate_neural_network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MULTI-LABEL NEURAL NETWORK EVALUATION\n",
      "(Test auf Multi-Label Test-Set: X_test_multi, y_test_multi)\n",
      "============================================================\n",
      "Subset Accuracy     : 0.4527\n",
      "Hamming Loss        : 0.1442\n",
      "Micro F1            : 0.6447\n",
      "Macro F1            : 0.5636\n",
      "Micro Precision     : 0.6985\n",
      "Micro Recall        : 0.5987\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MULTI-LABEL NEURAL NETWORK EVALUATION (auf Multi-Label Test-Set)\n",
    "# ============================================================\n",
    "\n",
    "# Make predictions auf Multi-Label Test-Set\n",
    "y_pred_nn_multi = mlp_clf_multi.predict(X_test_multi)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_multi_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_nn_multi),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_nn_multi),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_nn_multi, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_nn_multi, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MULTI-LABEL NEURAL NETWORK EVALUATION\")\n",
    "print(\"(Test auf Multi-Label Test-Set: X_test_multi, y_test_multi)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_multi_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "nn_sample_predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Multi-Label Neural Network Predictions:\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úó Sample 1:\n",
      "   Text: philadelphia clearly page game playbook fire net oppose goal...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n",
      "\n",
      "‚úó Sample 2:\n",
      "   Text: sure bay face flyer man experience versus blue jacket year h...\n",
      "   True: ('sports',)\n",
      "   Pred: ('none',)\n",
      "\n",
      "‚úó Sample 3:\n",
      "   Text: tizamagician put cherry kentucky derby day winner pie take d...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n",
      "\n",
      "‚úó Sample 4:\n",
      "   Text: flyer give false hope absolutely destroy islander go to dest...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n",
      "\n",
      "‚úó Sample 5:\n",
      "   Text: flyer tremendous season face excited season go to well thank...\n",
      "   True: ('news_&_social_concern', 'sports')\n",
      "   Pred: ('sports',)\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions\n",
    "y_pred_labels = mlb.inverse_transform(y_pred_nn_multi)\n",
    "y_true_labels = mlb.inverse_transform(y_test_multi)\n",
    "\n",
    "print(\"\\nSample Multi-Label Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test_multi['text'].iloc[i][:60]\n",
    "    true = y_true_labels[i] if y_true_labels[i] else ('none',)\n",
    "    pred = y_pred_labels[i] if y_pred_labels[i] else ('none',)\n",
    "    match = \"‚úì\" if set(true) == set(pred) else \"‚úó\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   True: {true}\")\n",
    "    print(f\"   Pred: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nb_training_section",
   "metadata": {},
   "source": [
    "### 4.5 Naive Bayes Classifier (for Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2ccdb0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NAIVE BAYES (Multi-Label) - wie Lab 4\n",
      "============================================================\n",
      "\n",
      "üìä Training auf MULTI-LABEL Daten:\n",
      "   X_train_bow_multi: (5465, 1000)\n",
      "   y_train_nb: (5465, 6)\n",
      "   Classes: 6\n",
      "\n",
      "============================================================\n",
      "NAIVE BAYES EVALUATION\n",
      "(Test auf Multi-Label Test-Set)\n",
      "============================================================\n",
      "Subset Accuracy     : 0.4818\n",
      "Hamming Loss        : 0.1370\n",
      "Micro F1            : 0.6802\n",
      "Macro F1            : 0.6237\n",
      "Micro Precision     : 0.6942\n",
      "Micro Recall        : 0.6668\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NAIVE BAYES TRAINING UND EVALUATION\n",
    "# ============================================================\n",
    "# Trainiert auf Multi-Label Daten (wie in Lab 4)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV_LAB4\n",
    "from sklearn.preprocessing import MultiLabelBinarizer as MLB_LAB4\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAIVE BAYES (Multi-Label) - wie Lab 4\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Training auf MULTI-LABEL Daten:\")\n",
    "print(f\"   X_train_bow_multi: {X_train_bow_multi.shape}\")\n",
    "\n",
    "# Multi-Label Binarizer (f√ºr Labels)\n",
    "mlb_nb = MLB_LAB4()\n",
    "y_train_nb = mlb_nb.fit_transform(df_train_multi[\"labels\"])\n",
    "y_test_nb = mlb_nb.transform(df_test_multi[\"labels\"])\n",
    "\n",
    "print(f\"   y_train_nb: {y_train_nb.shape}\")\n",
    "print(f\"   Classes: {len(mlb_nb.classes_)}\")\n",
    "\n",
    "# Train Naive Bayes\n",
    "nb_clf = OneVsRestClassifier(MultinomialNB(alpha=1.0))\n",
    "nb_clf.fit(X_train_bow_multi, y_train_nb)\n",
    "\n",
    "# Predictions auf Multi-Label Test-Set\n",
    "y_pred_nb = nb_clf.predict(X_test_bow_multi)\n",
    "\n",
    "# Metrics\n",
    "nb_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_nb, y_pred_nb),\n",
    "    'Hamming Loss': hamming_loss(y_test_nb, y_pred_nb),\n",
    "    'Micro F1': f1_score(y_test_nb, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_nb, y_pred_nb, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_nb, y_pred_nb, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_nb, y_pred_nb, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NAIVE BAYES EVALUATION\")\n",
    "print(\"(Test auf Multi-Label Test-Set)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nb_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Task 4: Single-Label Classification\n",
    "\n",
    "For comparison, we train a neural network using single-label classification. Each tweet is assigned only its primary (first) label, converting the multi-label problem to a standard multi-class classification problem.\n",
    "\n",
    "### 5.1 Single-Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "single_label_encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SINGLE-LABEL DATEN ZUSAMMENFASSUNG\n",
      "============================================================\n",
      "\n",
      "üìä Single-Label Features (f√ºr Training):\n",
      "  X_train_single: (5465, 1000)\n",
      "  y_train_single_enc: (5465,)\n",
      "\n",
      "üìä Single-Label Features (f√ºr Testing):\n",
      "  X_test_single: (1511, 1000)\n",
      "  y_test_single_enc: (1511,)\n",
      "\n",
      "‚úì Class mapping:\n",
      "  0: arts_&_culture (train: 9, test: 0)\n",
      "  1: business_&_entrepreneurs (train: 6, test: 0)\n",
      "  2: celebrity_&_pop_culture (train: 281, test: 81)\n",
      "  3: diaries_&_daily_life (train: 553, test: 111)\n",
      "  4: family (train: 9, test: 0)\n",
      "  5: fashion_&_style (train: 1, test: 4)\n",
      "  6: film_tv_&_video (train: 502, test: 164)\n",
      "  7: fitness_&_health (train: 2, test: 1)\n",
      "  8: food_&_dining (train: 4, test: 1)\n",
      "  9: gaming (train: 7, test: 0)\n",
      "  10: learning_&_educational (train: 1, test: 0)\n",
      "  11: music (train: 1000, test: 340)\n",
      "  12: news_&_social_concern (train: 1487, test: 241)\n",
      "  13: other_hobbies (train: 3, test: 2)\n",
      "  14: relationships (train: 5, test: 1)\n",
      "  15: science_&_technology (train: 5, test: 0)\n",
      "  16: sports (train: 1587, test: 565)\n",
      "  17: youth_&_student_life (train: 3, test: 0)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL ENCODING - Vorbereitung f√ºr Single-Label NN\n",
    "# ============================================================\n",
    "# Die Labels wurden bereits in Zelle 17 encodiert (y_train_single_enc, etc.)\n",
    "# Hier nur Zusammenfassung f√ºr Klarheit\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL DATEN ZUSAMMENFASSUNG\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Single-Label Features (f√ºr Training):\")\n",
    "print(f\"  X_train_single: {X_train_single.shape}\")\n",
    "print(f\"  y_train_single_enc: {y_train_single_enc.shape}\")\n",
    "\n",
    "print(f\"\\nüìä Single-Label Features (f√ºr Testing):\")\n",
    "print(f\"  X_test_single: {X_test_single.shape}\")\n",
    "print(f\"  y_test_single_enc: {y_test_single_enc.shape}\")\n",
    "\n",
    "print(f\"\\n‚úì Class mapping:\")\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    train_count = (y_train_single_enc == i).sum()\n",
    "    test_count = (y_test_single_enc == i).sum()\n",
    "    print(f\"  {i}: {cls} (train: {train_count}, test: {test_count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_nn_training_section",
   "metadata": {},
   "source": [
    "### 5.2 Single-Label Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "train_single_label_nn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SINGLE-LABEL NEURAL NETWORK ARCHITECTURE\n",
      "============================================================\n",
      "Input layer:  1000 neurons (vocabulary size)\n",
      "Hidden layer 1: 128 neurons (ReLU activation)\n",
      "Hidden layer 2: 64 neurons (ReLU activation)\n",
      "Hidden layer 3: 128 neurons (ReLU activation)\n",
      "Output layer: 18 neurons (Softmax activation)\n",
      "============================================================\n",
      "\n",
      "üìä Training auf SINGLE-LABEL Daten:\n",
      "   X_train_single: (5465, 1000)\n",
      "   y_train_single_enc: (5465,)\n",
      "\n",
      "Training Single-Label Neural Network...\n",
      "Iteration 1, loss = 2.41015208\n",
      "Validation score: 0.323583\n",
      "Iteration 2, loss = 1.52025911\n",
      "Validation score: 0.627057\n",
      "Iteration 3, loss = 0.97154871\n",
      "Validation score: 0.702011\n",
      "Iteration 4, loss = 0.67134946\n",
      "Validation score: 0.727605\n",
      "Iteration 5, loss = 0.52192845\n",
      "Validation score: 0.742230\n",
      "Iteration 6, loss = 0.42555599\n",
      "Validation score: 0.733090\n",
      "Iteration 7, loss = 0.34532969\n",
      "Validation score: 0.733090\n",
      "Iteration 8, loss = 0.28407572\n",
      "Validation score: 0.723949\n",
      "Iteration 9, loss = 0.22955961\n",
      "Validation score: 0.729433\n",
      "Iteration 10, loss = 0.18512835\n",
      "Validation score: 0.727605\n",
      "Iteration 11, loss = 0.14918065\n",
      "Validation score: 0.718464\n",
      "Iteration 12, loss = 0.12315902\n",
      "Validation score: 0.716636\n",
      "Iteration 13, loss = 0.10190251\n",
      "Validation score: 0.705667\n",
      "Iteration 14, loss = 0.08581644\n",
      "Validation score: 0.705667\n",
      "Iteration 15, loss = 0.07354048\n",
      "Validation score: 0.700183\n",
      "Iteration 16, loss = 0.06380997\n",
      "Validation score: 0.698355\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "‚úì Single-Label Neural Network training complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL NEURAL NETWORK TRAINING\n",
    "# ============================================================\n",
    "# Trainiert auf SINGLE-LABEL Daten (X_train_single, y_train_single_enc)\n",
    "\n",
    "# Create MLPClassifier for single-label classification\n",
    "mlp_clf_single = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 128),  # Same architecture as multi-label\n",
    "    activation='relu',                   # ReLU activation function\n",
    "    solver='adam',                       # Adam optimizer\n",
    "    max_iter=300,                        # Maximum iterations\n",
    "    random_state=RANDOM_STATE,           # For reproducibility\n",
    "    early_stopping=True,                 # Enable early stopping for single-label\n",
    "    validation_fraction=0.1,             # Use 10% for validation\n",
    "    verbose=True                         # Show training progress\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Input layer:  {X_train_single.shape[1]} neurons (vocabulary size)\")\n",
    "print(f\"Hidden layer 1: 128 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 2: 64 neurons (ReLU activation)\")\n",
    "print(f\"Hidden layer 3: 128 neurons (ReLU activation)\")\n",
    "print(f\"Output layer: {len(le.classes_)} neurons (Softmax activation)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Training auf SINGLE-LABEL Daten:\")\n",
    "print(f\"   X_train_single: {X_train_single.shape}\")\n",
    "print(f\"   y_train_single_enc: {y_train_single_enc.shape}\")\n",
    "\n",
    "print(\"\\nTraining Single-Label Neural Network...\")\n",
    "mlp_clf_single.fit(X_train_single, y_train_single_enc)\n",
    "print(\"\\n‚úì Single-Label Neural Network training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_label_nn_evaluation_section",
   "metadata": {},
   "source": [
    "### 5.3 Single-Label Neural Network Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "evaluate_single_label_nn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SINGLE-LABEL NEURAL NETWORK EVALUATION\n",
      "(Test auf Single-Label Test-Set: X_test_single, y_test_single_enc)\n",
      "============================================================\n",
      "Accuracy            : 0.7101\n",
      "Macro F1            : 0.3004\n",
      "Weighted F1         : 0.6906\n",
      "Macro Precision     : 0.2962\n",
      "Macro Recall        : 0.3091\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SINGLE-LABEL NEURAL NETWORK EVALUATION (auf Single-Label Test-Set)\n",
    "# ============================================================\n",
    "\n",
    "# Make predictions auf Single-Label Test-Set\n",
    "y_pred_nn_single = mlp_clf_single.predict(X_test_single)\n",
    "\n",
    "# Calculate metrics\n",
    "nn_single_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_single_enc, y_pred_nn_single),\n",
    "    'Macro F1': f1_score(y_test_single_enc, y_pred_nn_single, average='macro', zero_division=0),\n",
    "    'Weighted F1': f1_score(y_test_single_enc, y_pred_nn_single, average='weighted', zero_division=0),\n",
    "    'Macro Precision': precision_score(y_test_single_enc, y_pred_nn_single, average='macro', zero_division=0),\n",
    "    'Macro Recall': recall_score(y_test_single_enc, y_pred_nn_single, average='macro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SINGLE-LABEL NEURAL NETWORK EVALUATION\")\n",
    "print(\"(Test auf Single-Label Test-Set: X_test_single, y_test_single_enc)\")\n",
    "print(\"=\"*60)\n",
    "for metric, value in nn_single_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "4412a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PARTIAL MATCH EVALUATION: Single-Label NN vs Original Multi-Labels\n",
      "======================================================================\n",
      "\n",
      "A 'hit' occurs when the predicted single label matches ANY of the\n",
      "original multi-labels (not just the first/primary label).\n",
      "----------------------------------------------------------------------\n",
      "Total test samples:         1,511\n",
      "Hits (partial matches):     1,138\n",
      "Misses:                     373\n",
      "\n",
      "Partial Match Accuracy:     0.7531 (75.31%)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Comparison:\n",
      "  Exact Single-Label Accuracy:    0.7101\n",
      "  Partial Match Accuracy:         0.7531\n",
      "  Improvement:                    +0.0430\n",
      "======================================================================\n",
      "\n",
      "Examples of Partial Matches (pred matches non-primary label):\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚úì Sample 11:\n",
      "   Text: min st belt plenty positive thank have finish litt...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Primary label: sports\n",
      "   Predicted: news_&_social_concern (matches secondary label!)\n",
      "\n",
      "‚úì Sample 40:\n",
      "   Text: go pic new keychain gorgeous smoke fire wa air qua...\n",
      "   Original labels: ['diaries_&_daily_life' 'news_&_social_concern']\n",
      "   Primary label: diaries_&_daily_life\n",
      "   Predicted: news_&_social_concern (matches secondary label!)\n",
      "\n",
      "‚úì Sample 48:\n",
      "   Text: green bay packer fan strong divided feeling player...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Primary label: news_&_social_concern\n",
      "   Predicted: sports (matches secondary label!)\n",
      "\n",
      "‚úì Sample 54:\n",
      "   Text: flaw simple agenda leadership example talk example...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Primary label: news_&_social_concern\n",
      "   Predicted: sports (matches secondary label!)\n",
      "\n",
      "‚úì Sample 85:\n",
      "   Text: luvs help social reply fanchant separately...\n",
      "   Original labels: ['celebrity_&_pop_culture' 'film_tv_&_video' 'news_&_social_concern']\n",
      "   Primary label: celebrity_&_pop_culture\n",
      "   Predicted: news_&_social_concern (matches secondary label!)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Total samples where prediction matched a secondary label: 65\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PARTIAL MATCH EVALUATION: Single-Label NN vs Original Multi-Labels\n",
    "# ============================================================\n",
    "# Pr√ºft ob die Single-Label Vorhersage IRGENDEINEM der Original Multi-Labels entspricht\n",
    "\n",
    "def calculate_partial_match_accuracy(y_pred_single: np.ndarray, \n",
    "                                      original_labels_list: pd.Series,\n",
    "                                      label_encoder: LabelEncoder) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate partial match accuracy for single-label predictions.\n",
    "    \n",
    "    A prediction is considered a 'hit' if the predicted label matches\n",
    "    at least one of the original multi-labels.\n",
    "    \"\"\"\n",
    "    # Convert predictions to label names\n",
    "    pred_labels = label_encoder.inverse_transform(y_pred_single)\n",
    "    \n",
    "    # Count matches\n",
    "    total = len(pred_labels)\n",
    "    hits = 0\n",
    "    \n",
    "    for pred, original_labels in zip(pred_labels, original_labels_list):\n",
    "        # Check if prediction matches ANY of the original labels\n",
    "        if pred in original_labels:\n",
    "            hits += 1\n",
    "    \n",
    "    partial_match_accuracy = hits / total if total > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'total_samples': total,\n",
    "        'hits': hits,\n",
    "        'misses': total - hits,\n",
    "        'partial_match_accuracy': partial_match_accuracy\n",
    "    }\n",
    "\n",
    "# Calculate partial match accuracy for Single-Label NN (auf Single-Label Test-Set)\n",
    "partial_match_results = calculate_partial_match_accuracy(\n",
    "    y_pred_nn_single, \n",
    "    df_test_single['labels'],  # Original multi-labels aus Single-Label Test-Set\n",
    "    le\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PARTIAL MATCH EVALUATION: Single-Label NN vs Original Multi-Labels\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nA 'hit' occurs when the predicted single label matches ANY of the\")\n",
    "print(f\"original multi-labels (not just the first/primary label).\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Total test samples:         {partial_match_results['total_samples']:,}\")\n",
    "print(f\"Hits (partial matches):     {partial_match_results['hits']:,}\")\n",
    "print(f\"Misses:                     {partial_match_results['misses']:,}\")\n",
    "print(f\"\\nPartial Match Accuracy:     {partial_match_results['partial_match_accuracy']:.4f} ({partial_match_results['partial_match_accuracy']*100:.2f}%)\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Compare with exact single-label accuracy\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Exact Single-Label Accuracy:    {nn_single_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Partial Match Accuracy:         {partial_match_results['partial_match_accuracy']:.4f}\")\n",
    "print(f\"  Improvement:                    +{(partial_match_results['partial_match_accuracy'] - nn_single_metrics['Accuracy']):.4f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show examples of partial matches\n",
    "print(\"\\nExamples of Partial Matches (pred matches non-primary label):\")\n",
    "print(\"-\" * 70)\n",
    "example_count = 0\n",
    "for i in range(len(y_pred_nn_single)):\n",
    "    pred_label = le.inverse_transform([y_pred_nn_single[i]])[0]\n",
    "    true_primary = df_test_single['single_label'].iloc[i]\n",
    "    original_labels = df_test_single['labels'].iloc[i]\n",
    "    \n",
    "    # Show cases where prediction doesn't match primary but matches another label\n",
    "    if pred_label != true_primary and pred_label in original_labels:\n",
    "        example_count += 1\n",
    "        if example_count <= 5:\n",
    "            text = df_test_single['text'].iloc[i][:50]\n",
    "            print(f\"\\n‚úì Sample {i+1}:\")\n",
    "            print(f\"   Text: {text}...\")\n",
    "            print(f\"   Original labels: {original_labels}\")\n",
    "            print(f\"   Primary label: {true_primary}\")\n",
    "            print(f\"   Predicted: {pred_label} (matches secondary label!)\")\n",
    "\n",
    "print(f\"\\n\" + \"-\" * 70)\n",
    "print(f\"Total samples where prediction matched a secondary label: {example_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "single_label_sample_predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Single-Label Neural Network Predictions:\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úì Sample 1:\n",
      "   Text: philadelphia clearly page game playbook fire net oppose goal...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 2:\n",
      "   Text: sure bay face flyer man experience versus blue jacket year h...\n",
      "   Original labels: ['sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 3:\n",
      "   Text: tizamagician put cherry kentucky derby day winner pie take d...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 4:\n",
      "   Text: flyer give false hope absolutely destroy islander go to dest...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n",
      "\n",
      "‚úì Sample 5:\n",
      "   Text: flyer tremendous season face excited season go to well thank...\n",
      "   Original labels: ['news_&_social_concern' 'sports']\n",
      "   Single label (true): sports\n",
      "   Single label (pred): sports\n"
     ]
    }
   ],
   "source": [
    "# Show sample predictions for single-label\n",
    "print(\"\\nSample Single-Label Neural Network Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    text = df_test_single['text'].iloc[i][:60]\n",
    "    true_label = le.inverse_transform([y_test_single_enc[i]])[0]\n",
    "    pred_label = le.inverse_transform([y_pred_nn_single[i]])[0]\n",
    "    original_labels = df_test_single['labels'].iloc[i]\n",
    "    match = \"‚úì\" if true_label == pred_label else \"‚úó\"\n",
    "    print(f\"\\n{match} Sample {i+1}:\")\n",
    "    print(f\"   Text: {text}...\")\n",
    "    print(f\"   Original labels: {original_labels}\")\n",
    "    print(f\"   Single label (true): {true_label}\")\n",
    "    print(f\"   Single label (pred): {pred_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Model Comparison\n",
    "\n",
    "### 6.1 Multi-Label Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "model_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-LABEL MODEL COMPARISON: Neural Network vs Naive Bayes\n",
      "================================================================================\n",
      "         Metric  Neural Network (Multi-Label)  Naive Bayes (Multi-Label)  Difference   Better Model\n",
      "Subset Accuracy                      0.452680                   0.481800   -0.029120    Naive Bayes\n",
      "   Hamming Loss                      0.144165                   0.136995    0.007170    Naive Bayes\n",
      "       Micro F1                      0.644740                   0.680227   -0.035486    Naive Bayes\n",
      "       Macro F1                      0.563573                   0.623651   -0.060079    Naive Bayes\n",
      "Micro Precision                      0.698469                   0.694167    0.004302 Neural Network\n",
      "   Micro Recall                      0.598688                   0.666835   -0.068147    Naive Bayes\n",
      "================================================================================\n",
      "\n",
      "Note: For Hamming Loss, lower is better. For all other metrics, higher is better.\n"
     ]
    }
   ],
   "source": [
    "# Create comparison table for multi-label models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(nn_multi_metrics.keys()),\n",
    "    'Neural Network (Multi-Label)': list(nn_multi_metrics.values()),\n",
    "    'Naive Bayes (Multi-Label)': list(nb_metrics.values())\n",
    "})\n",
    "\n",
    "# Calculate improvement\n",
    "comparison_df['Difference'] = comparison_df['Neural Network (Multi-Label)'] - comparison_df['Naive Bayes (Multi-Label)']\n",
    "comparison_df['Better Model'] = comparison_df.apply(\n",
    "    lambda row: 'Neural Network' if (row['Difference'] > 0 and row['Metric'] != 'Hamming Loss') \n",
    "                or (row['Difference'] < 0 and row['Metric'] == 'Hamming Loss')\n",
    "                else 'Naive Bayes' if row['Difference'] != 0 else 'Tie',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-LABEL MODEL COMPARISON: Neural Network vs Naive Bayes\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: For Hamming Loss, lower is better. For all other metrics, higher is better.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single_vs_multi_section",
   "metadata": {},
   "source": [
    "### 6.2 Single-Label vs Multi-Label Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "single_vs_multi_comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CROSS-EVALUATION: Alle Modelle auf Multi-Label Test-Set\n",
      "================================================================================\n",
      "\n",
      "‚úì Multi-Label NN: bereits evaluiert (nn_multi_metrics)\n",
      "‚úì Naive Bayes: bereits evaluiert (nb_metrics)\n",
      "\n",
      "üìä Single-Label NN auf Multi-Label Test-Set:\n",
      "   Predicting auf X_test_multi mit Single-Label NN...\n",
      "   Klassen-Mapping: 6/18 Klassen gemappt\n",
      "\n",
      "================================================================================\n",
      "VERGLEICH AUF MULTI-LABEL TEST-SET\n",
      "================================================================================\n",
      "\n",
      "Metric               Multi-Label NN     Naive Bayes        Single-Label NN   \n",
      "----------------------------------------------------------------------------\n",
      "Subset Accuracy      0.4527             0.4818             0.5453            \n",
      "Hamming Loss         0.1442             0.1370             0.1341            \n",
      "Micro F1             0.6447             0.6802             0.6518            \n",
      "Macro F1             0.5636             0.6237             0.5257            \n",
      "\n",
      "üí° Interpretation:\n",
      "  - Single-Label NN kann nur EINE Klasse pro Sample vorhersagen\n",
      "  - Multi-Label Ground Truth kann MEHRERE Klassen pro Sample haben\n",
      "  - Daher sind Multi-Label NN und Naive Bayes bei Multi-Label Daten im Vorteil\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CROSS-EVALUATION: Alle Modelle auf Multi-Label Test-Set\n",
    "# ============================================================\n",
    "# Hier evaluieren wir ALLE Modelle auf dem Multi-Label Test-Set\n",
    "# f√ºr einen fairen Vergleich.\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CROSS-EVALUATION: Alle Modelle auf Multi-Label Test-Set\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Multi-Label NN auf Multi-Label Test-Set ‚Üí bereits in y_pred_nn_multi\n",
    "print(\"\\n‚úì Multi-Label NN: bereits evaluiert (nn_multi_metrics)\")\n",
    "\n",
    "# 2. Naive Bayes auf Multi-Label Test-Set ‚Üí bereits in y_pred_nb\n",
    "print(\"‚úì Naive Bayes: bereits evaluiert (nb_metrics)\")\n",
    "\n",
    "# 3. Single-Label NN auf Multi-Label Test-Set ‚Üí NEUE Predictions n√∂tig!\n",
    "print(\"\\nüìä Single-Label NN auf Multi-Label Test-Set:\")\n",
    "print(f\"   Predicting auf X_test_multi mit Single-Label NN...\")\n",
    "\n",
    "# Predictions des Single-Label NN auf Multi-Label Test-Features\n",
    "y_pred_single_on_multi = mlp_clf_single.predict(X_test_multi)\n",
    "\n",
    "# Konvertiere Single-Label Predictions zu Multi-Label Format\n",
    "num_multi_classes = y_test_multi.shape[1]\n",
    "num_single_classes = len(le.classes_)\n",
    "\n",
    "# Mapping: Single-Label Index ‚Üí Multi-Label Index\n",
    "single_to_multi_idx = {}\n",
    "for sl_idx, sl_class in enumerate(le.classes_):\n",
    "    if sl_class in mlb.classes_:\n",
    "        ml_idx = list(mlb.classes_).index(sl_class)\n",
    "        single_to_multi_idx[sl_idx] = ml_idx\n",
    "\n",
    "print(f\"   Klassen-Mapping: {len(single_to_multi_idx)}/{num_single_classes} Klassen gemappt\")\n",
    "\n",
    "# Konvertiere zu Multi-Label Format\n",
    "y_pred_single_as_multi = np.zeros((len(y_pred_single_on_multi), num_multi_classes), dtype=int)\n",
    "for i, pred in enumerate(y_pred_single_on_multi):\n",
    "    if pred in single_to_multi_idx:\n",
    "        y_pred_single_as_multi[i, single_to_multi_idx[pred]] = 1\n",
    "\n",
    "# Berechne Metriken f√ºr Single-Label NN auf Multi-Label Test-Set\n",
    "single_on_multi_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_single_as_multi),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_single_as_multi),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_single_as_multi, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_single_as_multi, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_single_as_multi, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_single_as_multi, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"VERGLEICH AUF MULTI-LABEL TEST-SET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Metric':<20} {'Multi-Label NN':<18} {'Naive Bayes':<18} {'Single-Label NN':<18}\")\n",
    "print(\"-\"*76)\n",
    "for metric in ['Subset Accuracy', 'Hamming Loss', 'Micro F1', 'Macro F1']:\n",
    "    multi = nn_multi_metrics[metric]\n",
    "    nb = nb_metrics[metric]\n",
    "    single = single_on_multi_metrics[metric]\n",
    "    print(f\"{metric:<20} {multi:<18.4f} {nb:<18.4f} {single:<18.4f}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"  - Single-Label NN kann nur EINE Klasse pro Sample vorhersagen\")\n",
    "print(\"  - Multi-Label Ground Truth kann MEHRERE Klassen pro Sample haben\")\n",
    "print(\"  - Daher sind Multi-Label NN und Naive Bayes bei Multi-Label Daten im Vorteil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f801925",
   "metadata": {},
   "source": [
    "### 6.3 Hybrid Model: Combining Single-Label and Multi-Label Networks\n",
    "\n",
    "**Idee:** Nutze das beste aus beiden Welten:\n",
    "- Tweets mit **genau 1 Label** ‚Üí Single-Label NN (optimiert f√ºr eindeutige Klassifikation)\n",
    "- Tweets mit **2+ Labels** ‚Üí Multi-Label NN (kann mehrere Labels vorhersagen)\n",
    "\n",
    "**Warum das sinnvoll ist:**\n",
    "- Single-Label NN ist spezialisiert auf eindeutige Entscheidungen\n",
    "- Multi-Label NN kann komplexe √úberlappungen von Themen erfassen\n",
    "- Kombiniert man beide, nutzt man die St√§rken beider Ans√§tze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3f29a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYBRID MODEL EVALUATION (nur Multi-Label Test-Set)\n",
      "================================================================================\n",
      "\n",
      "üìä Multi-Label Test-Set Zusammensetzung:\n",
      "  Single-Label Samples (1 Label):  1,104 (73.1%)\n",
      "  Multi-Label Samples (2+ Labels): 407 (26.9%)\n",
      "  Gesamt:                          1,511\n",
      "\n",
      "‚úì Hybrid-Predictions erstellt:\n",
      "  1104 Samples ‚Üí Single-Label NN\n",
      "  407 Samples ‚Üí Multi-Label NN\n",
      "\n",
      "================================================================================\n",
      "HYBRID MODEL METRICS (Multi-Label Test-Set)\n",
      "================================================================================\n",
      "Subset Accuracy     : 0.5758\n",
      "Hamming Loss        : 0.1296\n",
      "Micro F1            : 0.6741\n",
      "Macro F1            : 0.5896\n",
      "Micro Precision     : 0.7482\n",
      "Micro Recall        : 0.6133\n",
      "\n",
      "================================================================================\n",
      "VERGLEICH AUF MULTI-LABEL TEST-SET (alle Modelle)\n",
      "================================================================================\n",
      "\n",
      "Metric               Multi-Label NN   Hybrid           Naive Bayes      Single-Label NN \n",
      "------------------------------------------------------------------------------------\n",
      "Subset Accuracy      0.4527           0.5758 ‚òÖ         0.4818           0.5453          \n",
      "Hamming Loss         0.1442           0.1296 ‚òÖ         0.1370           0.1341          \n",
      "Micro F1             0.6447           0.6741           0.6802 ‚òÖ         0.6518          \n",
      "Macro F1             0.5636           0.5896           0.6237 ‚òÖ         0.5257          \n",
      "\n",
      "‚òÖ = Bestes Modell f√ºr diese Metrik\n",
      "(Bei Hamming Loss: niedriger ist besser)\n",
      "\n",
      "================================================================================\n",
      "DETAILANALYSE: Performance auf Single-Label vs Multi-Label Subsets\n",
      "================================================================================\n",
      "\n",
      "üìå Single-Label Subset (1104 Samples):\n",
      "  Hybrid Model (Single-Label NN):  Acc=0.7464, F1=0.7464\n",
      "  Multi-Label NN:                  Acc=0.5779, F1=0.6968\n",
      "  ‚Üí Hybrid ist besser um 0.1685\n",
      "\n",
      "üìå Multi-Label Subset (407 Samples):\n",
      "  Hybrid Model (Multi-Label NN):   Acc=0.1130, F1=0.5598\n",
      "  Single-Label NN:                 Acc=0.0000, F1=0.4891\n",
      "  ‚Üí Hybrid ist besser um 0.0707\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üí° Interpretation:\n",
      "  Das Hybrid-Modell kombiniert die St√§rken beider Ans√§tze:\n",
      "  - Single-Label NN f√ºr Tweets mit nur einem Topic\n",
      "  - Multi-Label NN f√ºr Tweets mit mehreren Topics\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# HYBRID MODEL: Single-Label NN + Multi-Label NN Kombination\n",
    "# ============================================================\n",
    "# Strategie:\n",
    "# - Tweets mit genau 1 Label ‚Üí Single-Label NN Prediction\n",
    "# - Tweets mit 2+ Labels ‚Üí Multi-Label NN Prediction\n",
    "# \n",
    "# HINWEIS: Hybrid Model wird NUR auf Multi-Label Test-Set evaluiert\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HYBRID MODEL EVALUATION (nur Multi-Label Test-Set)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Identifiziere Single-Label vs Multi-Label Samples im Multi-Label Test-Set\n",
    "num_labels_per_sample = y_test_multi.sum(axis=1)\n",
    "is_single_label = num_labels_per_sample == 1\n",
    "is_multi_label = num_labels_per_sample > 1\n",
    "\n",
    "n_single = is_single_label.sum()\n",
    "n_multi = is_multi_label.sum()\n",
    "n_total = len(y_test_multi)\n",
    "\n",
    "print(f\"\\nüìä Multi-Label Test-Set Zusammensetzung:\")\n",
    "print(f\"  Single-Label Samples (1 Label):  {n_single:,} ({100*n_single/n_total:.1f}%)\")\n",
    "print(f\"  Multi-Label Samples (2+ Labels): {n_multi:,} ({100*n_multi/n_total:.1f}%)\")\n",
    "print(f\"  Gesamt:                          {n_total:,}\")\n",
    "\n",
    "# 2. Erstelle Hybrid-Predictions\n",
    "# F√ºr Single-Label Samples: Verwende Single-Label NN (auf Multi-Label Test-Features)\n",
    "# F√ºr Multi-Label Samples: Verwende Multi-Label NN\n",
    "\n",
    "y_pred_hybrid = np.zeros_like(y_test_multi)\n",
    "\n",
    "# Single-Label Samples ‚Üí Single-Label NN Prediction (konvertiert zu Multi-Label Format)\n",
    "single_label_indices = np.where(is_single_label)[0]\n",
    "for idx in single_label_indices:\n",
    "    pred_class = y_pred_single_on_multi[idx]  # Predictions von Single-Label NN auf Multi-Label Test\n",
    "    # Mappe Single-Label Index zu Multi-Label Index\n",
    "    if pred_class in single_to_multi_idx:\n",
    "        y_pred_hybrid[idx, single_to_multi_idx[pred_class]] = 1\n",
    "\n",
    "# Multi-Label Samples ‚Üí Multi-Label NN Prediction\n",
    "multi_label_indices = np.where(is_multi_label)[0]\n",
    "y_pred_hybrid[multi_label_indices] = y_pred_nn_multi[multi_label_indices]\n",
    "\n",
    "print(f\"\\n‚úì Hybrid-Predictions erstellt:\")\n",
    "print(f\"  {n_single} Samples ‚Üí Single-Label NN\")\n",
    "print(f\"  {n_multi} Samples ‚Üí Multi-Label NN\")\n",
    "\n",
    "# 3. Evaluiere das Hybrid-Modell\n",
    "hybrid_metrics = {\n",
    "    'Subset Accuracy': accuracy_score(y_test_multi, y_pred_hybrid),\n",
    "    'Hamming Loss': hamming_loss(y_test_multi, y_pred_hybrid),\n",
    "    'Micro F1': f1_score(y_test_multi, y_pred_hybrid, average='micro', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_multi, y_pred_hybrid, average='macro', zero_division=0),\n",
    "    'Micro Precision': precision_score(y_test_multi, y_pred_hybrid, average='micro', zero_division=0),\n",
    "    'Micro Recall': recall_score(y_test_multi, y_pred_hybrid, average='micro', zero_division=0)\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"HYBRID MODEL METRICS (Multi-Label Test-Set)\")\n",
    "print(\"=\"*80)\n",
    "for metric, value in hybrid_metrics.items():\n",
    "    print(f\"{metric:<20}: {value:.4f}\")\n",
    "\n",
    "# 4. Vergleiche alle Modelle auf Multi-Label Test-Set\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"VERGLEICH AUF MULTI-LABEL TEST-SET (alle Modelle)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Metric':<20} {'Multi-Label NN':<16} {'Hybrid':<16} {'Naive Bayes':<16} {'Single-Label NN':<16}\")\n",
    "print(\"-\"*84)\n",
    "for metric in ['Subset Accuracy', 'Hamming Loss', 'Micro F1', 'Macro F1']:\n",
    "    multi = nn_multi_metrics[metric]\n",
    "    hybrid = hybrid_metrics[metric]\n",
    "    nb = nb_metrics[metric]\n",
    "    single = single_on_multi_metrics[metric]\n",
    "    \n",
    "    # Markiere das beste Modell\n",
    "    if metric == 'Hamming Loss':\n",
    "        best = min(multi, hybrid, nb, single)\n",
    "    else:\n",
    "        best = max(multi, hybrid, nb, single)\n",
    "    \n",
    "    multi_str = f\"{multi:.4f}\" + (\" ‚òÖ\" if multi == best else \"\")\n",
    "    hybrid_str = f\"{hybrid:.4f}\" + (\" ‚òÖ\" if hybrid == best else \"\")\n",
    "    nb_str = f\"{nb:.4f}\" + (\" ‚òÖ\" if nb == best else \"\")\n",
    "    single_str = f\"{single:.4f}\" + (\" ‚òÖ\" if single == best else \"\")\n",
    "    \n",
    "    print(f\"{metric:<20} {multi_str:<16} {hybrid_str:<16} {nb_str:<16} {single_str:<16}\")\n",
    "\n",
    "print(f\"\\n‚òÖ = Bestes Modell f√ºr diese Metrik\")\n",
    "print(f\"(Bei Hamming Loss: niedriger ist besser)\")\n",
    "\n",
    "# 5. Detaillierte Analyse: Performance auf Subsets\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DETAILANALYSE: Performance auf Single-Label vs Multi-Label Subsets\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Single-Label Subset\n",
    "if n_single > 0:\n",
    "    print(f\"\\nüìå Single-Label Subset ({n_single} Samples):\")\n",
    "    \n",
    "    # Hybrid auf Single-Label Subset\n",
    "    hybrid_single_acc = accuracy_score(y_test_multi[is_single_label], y_pred_hybrid[is_single_label])\n",
    "    hybrid_single_f1 = f1_score(y_test_multi[is_single_label], y_pred_hybrid[is_single_label], average='micro', zero_division=0)\n",
    "    \n",
    "    # Multi-Label NN auf Single-Label Subset\n",
    "    multi_single_acc = accuracy_score(y_test_multi[is_single_label], y_pred_nn_multi[is_single_label])\n",
    "    multi_single_f1 = f1_score(y_test_multi[is_single_label], y_pred_nn_multi[is_single_label], average='micro', zero_division=0)\n",
    "    \n",
    "    print(f\"  Hybrid Model (Single-Label NN):  Acc={hybrid_single_acc:.4f}, F1={hybrid_single_f1:.4f}\")\n",
    "    print(f\"  Multi-Label NN:                  Acc={multi_single_acc:.4f}, F1={multi_single_f1:.4f}\")\n",
    "    diff_acc = hybrid_single_acc - multi_single_acc\n",
    "    print(f\"  ‚Üí Hybrid ist {'besser' if diff_acc > 0 else 'schlechter'} um {abs(diff_acc):.4f}\")\n",
    "\n",
    "# Multi-Label Subset  \n",
    "if n_multi > 0:\n",
    "    print(f\"\\nüìå Multi-Label Subset ({n_multi} Samples):\")\n",
    "    \n",
    "    # Hybrid auf Multi-Label Subset (verwendet Multi-Label NN)\n",
    "    hybrid_multi_acc = accuracy_score(y_test_multi[is_multi_label], y_pred_hybrid[is_multi_label])\n",
    "    hybrid_multi_f1 = f1_score(y_test_multi[is_multi_label], y_pred_hybrid[is_multi_label], average='micro', zero_division=0)\n",
    "    \n",
    "    # Single-Label NN auf Multi-Label Subset\n",
    "    single_as_multi_subset = y_pred_single_as_multi[is_multi_label]\n",
    "    single_multi_acc = accuracy_score(y_test_multi[is_multi_label], single_as_multi_subset)\n",
    "    single_multi_f1 = f1_score(y_test_multi[is_multi_label], single_as_multi_subset, average='micro', zero_division=0)\n",
    "    \n",
    "    print(f\"  Hybrid Model (Multi-Label NN):   Acc={hybrid_multi_acc:.4f}, F1={hybrid_multi_f1:.4f}\")\n",
    "    print(f\"  Single-Label NN:                 Acc={single_multi_acc:.4f}, F1={single_multi_f1:.4f}\")\n",
    "    diff_f1 = hybrid_multi_f1 - single_multi_f1\n",
    "    print(f\"  ‚Üí Hybrid ist {'besser' if diff_f1 > 0 else 'schlechter'} um {abs(diff_f1):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"  Das Hybrid-Modell kombiniert die St√§rken beider Ans√§tze:\")\n",
    "print(\"  - Single-Label NN f√ºr Tweets mit nur einem Topic\")\n",
    "print(\"  - Multi-Label NN f√ºr Tweets mit mehreren Topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "all_models_summary_section",
   "metadata": {},
   "source": [
    "### 6.3 All Models Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "0784bbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "COMPREHENSIVE MODEL COMPARISON SUMMARY\n",
      "===============================================================================================\n",
      "\n",
      "üìä Cross-Evaluation: Multi-Label Modelle auf Single-Label Test-Set\n",
      "‚úì Cross-Evaluation abgeschlossen\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "MULTI-LABEL TEST-SET EVALUATION (Ground Truth hat 1 oder mehr Labels)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Model                               Subset Acc   Micro F1     Macro F1     Hamming Loss\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Naive Bayes (Multi-Label)           0.4818       0.6802       0.6237       0.1370      \n",
      "Hybrid Model (Single+Multi NN)      0.5758       0.6741       0.5896       0.1296      \n",
      "Single-Label NN                     0.5453       0.6518       0.5257       0.1341      \n",
      "Multi-Label Neural Network          0.4527       0.6447       0.5636       0.1442      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "(Sortiert nach Micro F1, absteigend)\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "SINGLE-LABEL TEST-SET EVALUATION (Ground Truth hat genau 1 Label)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Model                               Accuracy     Weighted F1  Macro F1    \n",
      "-----------------------------------------------------------------------------------------------\n",
      "Single-Label Neural Network         0.7101       0.6906       0.3004      \n",
      "Multi-Label Neural Network          0.0073       0.0048       0.0055      \n",
      "Naive Bayes (Multi-Label)           0.0026       0.0021       0.0026      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "(Sortiert nach Accuracy, absteigend)\n",
      "(Hinweis: Hybrid-Modell wird nur auf Multi-Label Test-Set evaluiert)\n",
      "\n",
      "===============================================================================================\n",
      "BEST MODEL PER METRIC\n",
      "===============================================================================================\n",
      "\n",
      "üìä Multi-Label Test-Set:\n",
      "  Subset Accuracy     : Hybrid Model (Single+Multi NN) (0.5758)\n",
      "  Micro F1            : Naive Bayes (Multi-Label) (0.6802)\n",
      "  Macro F1            : Naive Bayes (Multi-Label) (0.6237)\n",
      "  Hamming Loss        : Hybrid Model (Single+Multi NN) (0.1296) ‚Üê niedriger ist besser\n",
      "\n",
      "üìä Single-Label Test-Set:\n",
      "  Accuracy            : Single-Label Neural Network (0.7101)\n",
      "  Weighted F1         : Single-Label Neural Network (0.6906)\n",
      "  Macro F1            : Single-Label Neural Network (0.3004)\n",
      "\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# COMPREHENSIVE MODEL COMPARISON SUMMARY\n",
    "# ============================================================\n",
    "# Evaluiere ALLE Modelle auf BEIDEN Test-Sets f√ºr fairen Vergleich\n",
    "# (Hybrid Model nur auf Multi-Label Test-Set)\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*95)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Evaluiere Multi-Label NN und Naive Bayes auf Single-Label Test-Set\n",
    "# ============================================================\n",
    "# Daf√ºr m√ºssen wir Predictions auf Single-Label Test-Set machen und zu Single-Label konvertieren\n",
    "\n",
    "print(\"\\nüìä Cross-Evaluation: Multi-Label Modelle auf Single-Label Test-Set\")\n",
    "\n",
    "# Multi-Label NN auf Single-Label Test-Features predicten\n",
    "y_pred_multi_nn_on_single_test = mlp_clf_multi.predict(X_test_single)\n",
    "# Konvertiere zu Single-Label (argmax)\n",
    "y_pred_multi_nn_as_single = np.array([np.argmax(row) if row.sum() > 0 else 0 for row in y_pred_multi_nn_on_single_test])\n",
    "\n",
    "# Naive Bayes auf Single-Label Test-Features predicten\n",
    "vectorizer_single = CountVectorizer(vocabulary=VOCABULARY, lowercase=True, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X_test_single_bow = vectorizer_single.fit_transform(df_test_single['text'])\n",
    "y_pred_nb_on_single_test = nb_clf.predict(X_test_single_bow)\n",
    "# Konvertiere zu Single-Label (argmax)\n",
    "y_pred_nb_as_single = np.array([np.argmax(row) if row.sum() > 0 else 0 for row in y_pred_nb_on_single_test])\n",
    "\n",
    "# Berechne Single-Label Metriken f√ºr Multi-Label NN\n",
    "multi_nn_single_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_single_enc, y_pred_multi_nn_as_single),\n",
    "    'Weighted F1': f1_score(y_test_single_enc, y_pred_multi_nn_as_single, average='weighted', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_single_enc, y_pred_multi_nn_as_single, average='macro', zero_division=0),\n",
    "}\n",
    "\n",
    "# Berechne Single-Label Metriken f√ºr Naive Bayes\n",
    "nb_single_metrics = {\n",
    "    'Accuracy': accuracy_score(y_test_single_enc, y_pred_nb_as_single),\n",
    "    'Weighted F1': f1_score(y_test_single_enc, y_pred_nb_as_single, average='weighted', zero_division=0),\n",
    "    'Macro F1': f1_score(y_test_single_enc, y_pred_nb_as_single, average='macro', zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"‚úì Cross-Evaluation abgeschlossen\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. MULTI-LABEL TEST-SET ERGEBNISSE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"-\"*95)\n",
    "print(\"MULTI-LABEL TEST-SET EVALUATION (Ground Truth hat 1 oder mehr Labels)\")\n",
    "print(\"-\"*95)\n",
    "print(f\"{'Model':<35} {'Subset Acc':<12} {'Micro F1':<12} {'Macro F1':<12} {'Hamming Loss':<12}\")\n",
    "print(\"-\"*95)\n",
    "\n",
    "# Sortiere nach Micro F1 (absteigend)\n",
    "multi_results = [\n",
    "    ('Multi-Label Neural Network', nn_multi_metrics),\n",
    "    ('Hybrid Model (Single+Multi NN)', hybrid_metrics),\n",
    "    ('Naive Bayes (Multi-Label)', nb_metrics),\n",
    "    ('Single-Label NN', single_on_multi_metrics),\n",
    "]\n",
    "\n",
    "for name, metrics in sorted(multi_results, key=lambda x: x[1]['Micro F1'], reverse=True):\n",
    "    print(f\"{name:<35} {metrics['Subset Accuracy']:<12.4f} {metrics['Micro F1']:<12.4f} {metrics['Macro F1']:<12.4f} {metrics['Hamming Loss']:<12.4f}\")\n",
    "\n",
    "print(\"-\"*95)\n",
    "print(\"(Sortiert nach Micro F1, absteigend)\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. SINGLE-LABEL TEST-SET ERGEBNISSE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"-\"*95)\n",
    "print(\"SINGLE-LABEL TEST-SET EVALUATION (Ground Truth hat genau 1 Label)\")\n",
    "print(\"-\"*95)\n",
    "print(f\"{'Model':<35} {'Accuracy':<12} {'Weighted F1':<12} {'Macro F1':<12}\")\n",
    "print(\"-\"*95)\n",
    "\n",
    "# Sortiere nach Accuracy (absteigend)\n",
    "single_results = [\n",
    "    ('Single-Label Neural Network', nn_single_metrics),\n",
    "    ('Multi-Label Neural Network', multi_nn_single_metrics),\n",
    "    ('Naive Bayes (Multi-Label)', nb_single_metrics),\n",
    "]\n",
    "\n",
    "for name, metrics in sorted(single_results, key=lambda x: x[1]['Accuracy'], reverse=True):\n",
    "    print(f\"{name:<35} {metrics['Accuracy']:<12.4f} {metrics['Weighted F1']:<12.4f} {metrics['Macro F1']:<12.4f}\")\n",
    "\n",
    "print(\"-\"*95)\n",
    "print(\"(Sortiert nach Accuracy, absteigend)\")\n",
    "print(\"(Hinweis: Hybrid-Modell wird nur auf Multi-Label Test-Set evaluiert)\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ZUSAMMENFASSUNG: Bestes Modell pro Metrik\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*95)\n",
    "print(\"BEST MODEL PER METRIC\")\n",
    "print(\"=\"*95)\n",
    "\n",
    "print(\"\\nüìä Multi-Label Test-Set:\")\n",
    "metrics_multi = ['Subset Accuracy', 'Micro F1', 'Macro F1', 'Hamming Loss']\n",
    "for metric in metrics_multi:\n",
    "    if metric == 'Hamming Loss':\n",
    "        best_model = min(multi_results, key=lambda x: x[1][metric])\n",
    "        print(f\"  {metric:<20}: {best_model[0]} ({best_model[1][metric]:.4f}) ‚Üê niedriger ist besser\")\n",
    "    else:\n",
    "        best_model = max(multi_results, key=lambda x: x[1][metric])\n",
    "        print(f\"  {metric:<20}: {best_model[0]} ({best_model[1][metric]:.4f})\")\n",
    "\n",
    "print(\"\\nüìä Single-Label Test-Set:\")\n",
    "metrics_single = ['Accuracy', 'Weighted F1', 'Macro F1']\n",
    "for metric in metrics_single:\n",
    "    best_model = max(single_results, key=lambda x: x[1][metric])\n",
    "    print(f\"  {metric:<20}: {best_model[0]} ({best_model[1][metric]:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Optional: Experiment with Different Network Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "experiment_architectures",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with different network architectures (Multi-Label)...\n",
      "============================================================\n",
      "\n",
      "Training: Small (64-32-64)...\n",
      "  Accuracy: 0.4520, Micro F1: 0.6409\n",
      "\n",
      "Training: Medium (128-64-128)...\n",
      "  Accuracy: 0.4527, Micro F1: 0.6447\n",
      "\n",
      "Training: Large (256-128-256)...\n",
      "  Accuracy: 0.4573, Micro F1: 0.6455\n",
      "\n",
      "Training: Deep (128-128-64-64-128-128)...\n",
      "  Accuracy: 0.4725, Micro F1: 0.6535\n",
      "\n",
      "Training: Wide (512-256-512)...\n",
      "  Accuracy: 0.4626, Micro F1: 0.6485\n",
      "\n",
      "================================================================================\n",
      "ARCHITECTURE COMPARISON RESULTS (Multi-Label Test-Set)\n",
      "================================================================================\n",
      "                Architecture                       Layers  Accuracy  Micro F1  Macro F1\n",
      "            Small (64-32-64)                 (64, 32, 64)  0.452019  0.640916  0.569563\n",
      "         Medium (128-64-128)               (128, 64, 128)  0.452680  0.644740  0.563573\n",
      "         Large (256-128-256)              (256, 128, 256)  0.457313  0.645541  0.567340\n",
      "Deep (128-128-64-64-128-128) (128, 128, 64, 64, 128, 128)  0.472535  0.653532  0.573370\n",
      "          Wide (512-256-512)              (512, 256, 512)  0.462608  0.648470  0.567219\n"
     ]
    }
   ],
   "source": [
    "# Define different architectures to test\n",
    "architectures = {\n",
    "    'Small (64-32-64)': (64, 32, 64),\n",
    "    'Medium (128-64-128)': (128, 64, 128),  # Original\n",
    "    'Large (256-128-256)': (256, 128, 256),\n",
    "    'Deep (128-128-64-64-128-128)': (128, 128, 64, 64, 128, 128),\n",
    "    'Wide (512-256-512)': (512, 256, 512)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Experimenting with different network architectures (Multi-Label)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, layers in architectures.items():\n",
    "    print(f\"\\nTraining: {name}...\")\n",
    "    \n",
    "    # Create and train model\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=layers,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=200,\n",
    "        random_state=RANDOM_STATE,\n",
    "        early_stopping=False,  # Disabled for multi-label compatibility\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    clf = OneVsRestClassifier(mlp, n_jobs=-1)\n",
    "    clf.fit(X_train_multi, y_train_multi)  # Training auf Multi-Label Daten\n",
    "    \n",
    "    # Evaluate auf Multi-Label Test-Set\n",
    "    y_pred = clf.predict(X_test_multi)\n",
    "    \n",
    "    results.append({\n",
    "        'Architecture': name,\n",
    "        'Layers': str(layers),\n",
    "        'Accuracy': accuracy_score(y_test_multi, y_pred),\n",
    "        'Micro F1': f1_score(y_test_multi, y_pred, average='micro', zero_division=0),\n",
    "        'Macro F1': f1_score(y_test_multi, y_pred, average='macro', zero_division=0)\n",
    "    })\n",
    "    \n",
    "    print(f\"  Accuracy: {results[-1]['Accuracy']:.4f}, Micro F1: {results[-1]['Micro F1']:.4f}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARCHITECTURE COMPARISON RESULTS (Multi-Label Test-Set)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary\n",
    "\n",
    "### What was accomplished\n",
    "1. Loaded preprocessed data from Lab 2 and vocabulary from Lab 4\n",
    "2. Created binary feature vectors (Bag-of-Words encoding) for all samples\n",
    "3. Trained a Multi-Label Neural Network with 128‚Üí64‚Üí128 hidden layers using MLPClassifier and OneVsRestClassifier\n",
    "4. Converted multi-label data to single-label by keeping only the primary label\n",
    "5. Trained a Single-Label Neural Network with the same architecture\n",
    "6. Compared Multi-Label NN, Single-Label NN, and Naive Bayes classifiers\n",
    "7. Experimented with different network architectures\n",
    "\n",
    "### Key Findings\n",
    "- Multi-label classification allows predicting multiple topics per tweet\n",
    "- Single-label classification simplifies the problem but loses information about secondary topics\n",
    "- Neural networks can capture non-linear relationships in text classification\n",
    "- The MLPClassifier with ReLU activation and Adam optimizer provides good results\n",
    "- For multi-label tasks, OneVsRestClassifier trains separate binary classifiers per class\n",
    "- For single-label tasks, MLPClassifier uses softmax output for probability distribution\n",
    "- Network architecture affects performance, but larger isn't always better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "final_summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LAB 5 SUMMARY\n",
      "======================================================================\n",
      "Input vocabulary: ../Data/top_1000_vocabulary.json\n",
      "\n",
      "üìä DATENSTRUKTUR:\n",
      "  Multi-Label Training:  5,465 Samples\n",
      "  Multi-Label Test:      1,511 Samples\n",
      "  Single-Label Training: 5,465 Samples\n",
      "  Single-Label Test:     1,511 Samples\n",
      "  Feature vector size:   1000\n",
      "  Number of classes:     18\n",
      "\n",
      "üìä TRAINING:\n",
      "  Multi-Label NN:  trainiert auf Multi-Label Daten (5,465 Samples)\n",
      "  Naive Bayes:     trainiert auf Multi-Label Daten (5,465 Samples)\n",
      "  Single-Label NN: trainiert auf Single-Label Daten (5,465 Samples)\n",
      "\n",
      "üìä TESTING:\n",
      "  Multi-Label Test-Set:  alle Modelle (+ Hybrid)\n",
      "  Single-Label Test-Set: alle au√üer Hybrid\n",
      "\n",
      "üìä MULTI-LABEL NN METRICS (Multi-Label Test-Set):\n",
      "  Subset Accuracy: 0.4527\n",
      "  Micro F1: 0.6447\n",
      "  Macro F1: 0.5636\n",
      "\n",
      "üìä SINGLE-LABEL NN METRICS (Single-Label Test-Set):\n",
      "  Accuracy: 0.7101\n",
      "  Weighted F1: 0.6906\n",
      "  Macro F1: 0.3004\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1034dd8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106fd98a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1086f18a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x12106d8a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1042718a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1073718a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1058d98a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103ef18a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x103df18a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x106f418a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1142718a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x1050418a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 84, in __del__\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 93, in _stop\n",
      "  File \"/opt/anaconda3/lib/python3.13/multiprocessing/resource_tracker.py\", line 118, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"LAB 5 SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input vocabulary: {VOCABULARY_PATH}\")\n",
    "print(f\"\\nüìä DATENSTRUKTUR:\")\n",
    "print(f\"  Multi-Label Training:  {len(df_train_multi):,} Samples\")\n",
    "print(f\"  Multi-Label Test:      {len(df_test_multi):,} Samples\")\n",
    "print(f\"  Single-Label Training: {len(df_train_single):,} Samples\")\n",
    "print(f\"  Single-Label Test:     {len(df_test_single):,} Samples\")\n",
    "print(f\"  Feature vector size:   {X_train_multi.shape[1]}\")\n",
    "print(f\"  Number of classes:     {len(TOPIC_CLASSES)}\")\n",
    "\n",
    "print(f\"\\nüìä TRAINING:\")\n",
    "print(f\"  Multi-Label NN:  trainiert auf Multi-Label Daten ({len(df_train_multi):,} Samples)\")\n",
    "print(f\"  Naive Bayes:     trainiert auf Multi-Label Daten ({len(df_train_multi):,} Samples)\")\n",
    "print(f\"  Single-Label NN: trainiert auf Single-Label Daten ({len(df_train_single):,} Samples)\")\n",
    "\n",
    "print(f\"\\nüìä TESTING:\")\n",
    "print(f\"  Multi-Label Test-Set:  alle Modelle (+ Hybrid)\")\n",
    "print(f\"  Single-Label Test-Set: alle au√üer Hybrid\")\n",
    "\n",
    "print(f\"\\nüìä MULTI-LABEL NN METRICS (Multi-Label Test-Set):\")\n",
    "print(f\"  Subset Accuracy: {nn_multi_metrics['Subset Accuracy']:.4f}\")\n",
    "print(f\"  Micro F1: {nn_multi_metrics['Micro F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_multi_metrics['Macro F1']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä SINGLE-LABEL NN METRICS (Single-Label Test-Set):\")\n",
    "print(f\"  Accuracy: {nn_single_metrics['Accuracy']:.4f}\")\n",
    "print(f\"  Weighted F1: {nn_single_metrics['Weighted F1']:.4f}\")\n",
    "print(f\"  Macro F1: {nn_single_metrics['Macro F1']:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
