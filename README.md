# ğŸ§  Grundlagen des NLP â€“ WS25/26

## ğŸ“Œ Projektbeschreibung

Dieses Repository gehÃ¶rt zur Lehrveranstaltung **Grundlagen des Natural Language Processing** (WS 2025/26).  
Ziel ist es, anhand eines mehrthemenbezogenen Tweet-Datensatzes eine vollstÃ¤ndige NLP-Pipeline zu entwickeln: 

- ğŸ“¥ Datenanalyse
- ğŸ§¹ Vorverarbeitung (Text Cleaning)
- â˜ï¸ Visualisierung
- ğŸ§  Modellierung (Multi-Label & Single-Label Klassifikation)
- ğŸ“Š Evaluation

---

## ğŸ“‚ Projektstruktur

```bash
. 
â”œâ”€â”€ Abgabe/                   # Finale Abgaben
â”‚   â”œâ”€â”€ Data/                 # DatensÃ¤tze fÃ¼r Abgabe
â”‚   â””â”€â”€ Notebooks/            # Finalisierte Notebooks
â”œâ”€â”€ Hikmet/                   # PersÃ¶nlicher Projektordner
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ lab4_hikmet.ipynb     # Lab 4 Ãœbung
â”‚   â””â”€â”€ skizze
â”œâ”€â”€ Justus/
â”‚   â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ lab2.ipynb
â”‚   â”œâ”€â”€ lab2_justus.ipynb
â”‚   â”œâ”€â”€ lab2_single_label.ipynb
â”‚   â”œâ”€â”€ lab4_single_label.ipynb
â”‚   â”œâ”€â”€ lab5.ipynb
â”‚   â””â”€â”€ loading+textfilter+preprocessing_version2.ipynb
â”œâ”€â”€ Sunny/
â”‚   â”œâ”€â”€ lab3_sunny.ipynb
â”‚   â””â”€â”€ lab4_sunny.ipynb
â”œâ”€â”€ environment.yml           # Conda Environment Konfiguration
â””â”€â”€ README.md                 # Projektbeschreibung (diese Datei)
```

---

## âš™ï¸ Setup

### ğŸ“¦ Voraussetzungen

- Python 3.11+
- [Anaconda](https://www.anaconda.com/) oder `venv`

### ğŸ”§ Environment einrichten

```bash
# Environment erstellen
conda env create -f environment.yml

# Environment aktualisieren
conda env update -f environment.yml --prune

# Environment aktivieren
conda activate nlp_tweets
```

### ğŸ“¦ Enthaltene Pakete

- `pandas`, `matplotlib`, `seaborn` â€“ Datenanalyse & Visualisierung
- `scikit-learn` â€“ Machine Learning
- `nltk`, `spacy` â€“ NLP-Bibliotheken
- `datasets` â€“ Hugging Face Datasets
- `emoji` â€“ Emoji-Verarbeitung
- `jupyterlab` â€“ Notebook-Umgebung

### ğŸ“š Sprachmodelle / Ressourcen

```python
import nltk
nltk.download("stopwords")

import spacy
spacy.cli.download("en_core_web_sm")
```

---

## ğŸš€ Nutzung

1.  Umgebung aktivieren:
   ```bash
   conda activate nlp_tweets
   ```

2. Jupyter starten:
   ```bash
   jupyter lab
   ```

3. Notebook Ã¶ffnen und loslegen! 

---

## âœ… Bearbeitete Aufgaben

| Ãœbung | Inhalt                                         | Status         | Bearbeiter |
|-------|------------------------------------------------|----------------|------------|
| 2     | Datenanalyse, Preprocessing     | âœ… erledigt    | Justus     |
| 3     | Visualisierung & Exploration                   | âœ… erledigt    | Sunny      |
| 4     | Klassifikation (Single-Label)                  | âœ… erledigt    | Hikmet, Justus |
| 5     | Evaluation & Modellvergleich                   | in Arbeit    | Justus     |

---

## ğŸ‘¥ Team

- **Hikmet Acig** â€“ Lab 4
- **Sunny Wicklein** â€“ Lab 3, Lab 4
- **Justus Jochum** â€“ Lab 2, Lab 5, Preprocessing

---

## ğŸ”’ Lizenz

Dieses Projekt ist Teil einer universitÃ¤ren Lehrveranstaltung und nicht Ã¶ffentlich lizenziert.  
Verwendung ausschlieÃŸlich zu Lernzwecken im Rahmen des Kurses **Grundlagen des NLP**. 

---

## ğŸ“¬ Kontakt

FÃ¼r Fragen oder BeitrÃ¤ge:  bitte Ã¼ber GitHub Pull Requests oder direkt via E-Mail an das Team.